--BEGIN--22/11/2025--TIME COMPLEXITY--
1. Computational and asymptotic complexity
ğ–¦¹ A single problem can have many algorithms, each with different efficiency.
ğ–¦¹ For small data, these differences are small; for large data, the differences grow.
â€¢ Computational complexity
- Shows how much effort an algorithm needs in terms of time or space.
2. Time and space as efficiency measures
ğ–¦¹ Time is usually more important than space when judging an algorithm.
ğ–¦¹ Actual run time depends on the machine used.
â€¢ System dependence
- An inefficient algorithm on a very fast machine may still run faster than an efficient one on a slow machine.
- To compare many algorithms, all must be tested on the same machine.
â€¢ Language dependence
- Compiled programs run faster than interpreted ones.
- Some languages produce faster code than others.

3. Using logical units instead of real time
ğ–¦¹ Real-time units (microseconds, nanoseconds) should not be used for analysis.
ğ–¦¹ Use logical units that relate input size n to time t.
â€¢ Linear example
- If tâ‚ = cÂ·nâ‚, then increasing n by 5 times increases t by 5 times.
â€¢ Log example
- If tâ‚ = logâ‚‚(n), doubling n increases t by 1 unit.

4. Need for simplified functions
ğ–¦¹ The true relationship between n and t can be complex.
ğ–¦¹ For large data, small terms in the function do not change its overall growth.
ğ–¦¹ These small terms are removed to get a simpler approximate function.
â€¢ Asymptotic complexity
- Used when only the main growth of the function matters.
- Useful when exact calculation is hard or unnecessary.

5. Example: f(n) = nÂ² + 100n + logâ‚â‚€(n) + 1000
ğ–¦¹ For small n, the constant term 1000 is the biggest.
ğ–¦¹ At n = 10, the linear term 100n and constant term 1000 are similar in effect.
ğ–¦¹ At n = 100, the nÂ² and 100n terms have similar effects.
â€¢ For large n
- The nÂ² term grows much faster than other terms.
- 100n, logâ‚â‚€(n), and 1000 become very small in comparison.
- The function mainly depends on nÂ² when n is large.

6. Big-O notation
ğ–¦¹ Big-O is used to describe how fast a function grows for large n.
ğ–¦¹ It compares two functions f(n) and g(n) by checking if f grows no faster than g.
â€¢ Meaning of f(n) = O(g(n))
IMG_URL fnlessthancgn.png
- There exist positive numbers c and N such that f(n) â‰¤ cÂ·g(n) for all n â‰¥ N.
IMG_URL fnogn.png
- g(n) acts as an upper bound for the growth of f(n) when n is large.
IMG_URL rabbit-carrot-chase.gif

7. Limits of the basic definition
ğ–¦¹ The definition says constants c and N must exist but does not show how to find them.
ğ–¦¹ Many different pairs of c and N can satisfy the same f(n) and g(n).
â€¢ Example idea
- For f(n) = 2nÂ² + 3n + 1 and g(n) = nÂ², many c, N pairs work.
- These pairs come from solving: 2nÂ² + 3n + 1 â‰¤ cÂ·nÂ².

8. Finding useful constants
ğ–¦¹ To pick the best N, find when the largest term in f(n) stays the largest.
ğ–¦¹ For f(n) = 2nÂ² + 3n + 1, the biggest terms are 2nÂ² and 3n.
â€¢ Compare terms
- 2nÂ² > 3n when n > 1.
- So N = 2 is suitable, and c must be at least 33/4.

9. Meaning of different c and N
ğ–¦¹ Many pairs of c and N still describe the same relationship f = O(g).
ğ–¦¹ â€œAlmost alwaysâ€ means gÂ·c is â‰¥ f for all n â‰¥ N.
â€¢ Effect of choosing different N
- If N = 1, then c must be â‰¥ 6.
- If N = 2, c must be â‰¥ 3.75.
- If N = 3, c must be â‰¥ 31/9.
- c and N depend on each other.

10. Multiple possible upper bounds
ğ–¦¹ A function f can be O(nÂ²), O(nÂ³), O(nâ´), â€¦ for any power â‰¥ 2.
ğ–¦¹ To avoid too many choices, the smallest suitable g(n) is normally taken.
â€¢ Removing small terms
- Small terms in f(n) that do not affect growth are written using O( ).
- Example: f(n) = nÂ² + 100n + O(logâ‚â‚€(n))
â€¢ Another example
- f(n) = 2nÂ² + O(n)

11. Finding c and N
IMG_URL bigo.png
ğ–¦¹ We compare each part of f(n) with g(n) to show f(n) â‰¤ c Ã— g(n)
ğ–¦¹ We rewrite all parts of f(n) so they look like some_number Ã— g(n)
â€¢ This helps us show f(n) grows no faster than g(n)
- Explanation: If every part of f(n) can be written in terms of g(n), then the whole f(n) can also be written using g(n)

11.1 Making all terms look like g(n) = nÂ²
ğ–¦¹ For f(n) = 2nÂ² + 3n + 1, we try to rewrite each term as something Ã— nÂ²
ğ–¦¹ First term: 2nÂ² â‰¤ 2nÂ²
â€¢ It already matches nÂ², so no change needed

11.2 Converting 3n into something Ã— nÂ²
ğ–¦¹ We check if 3n can be compared with 3nÂ²
ğ–¦¹ Check if n â‰¤ nÂ² when n â‰¥ 1
â€¢ Divide both sides by n (n > 0) â†’ 1 â‰¤ n
- Explanation: This is true for all n â‰¥ 1, so 3n â‰¤ 3nÂ²

11.3 Converting constant 1 into something Ã— nÂ²
ğ–¦¹ We check if 1 â‰¤ nÂ² when n â‰¥ 1
ğ–¦¹ For n = 1,2,3,... this is always true
â€¢ So 1 â‰¤ nÂ² for all n â‰¥ 1

11.4 Putting all replacements together
ğ–¦¹ Now each part of f(n) is written in terms of nÂ²
ğ–¦¹ So:
â€¢ 2nÂ² + 3n + 1 â‰¤ 2nÂ² + 3nÂ² + nÂ²
- Explanation: Add them â†’ 6nÂ²

11.5 Final values
ğ–¦¹ f(n) â‰¤ 6nÂ²
ğ–¦¹ So c = 6
ğ–¦¹ And N = 1

12. Properties of Big-O notation
ğ–¦¹ Big-O has useful rules that help compare how fast functions grow
ğ–¦¹ These rules make it easier to estimate how fast algorithms run

12.1 Fact 1: Transitivity
IMG_URL transitive.png
ğ–¦¹ If f(n) is O(g(n)) and g(n) is O(h(n)), then f(n) is O(h(n))
ğ–¦¹ This means we can connect the two bounds into one
- Explanation: Since f(n) â‰¤ c1Â·g(n) for n â‰¥ N1 and g(n) â‰¤ c2Â·h(n) for n â‰¥ N2, we get f(n) â‰¤ (c1Â·c2)Â·h(n) for large enough n

12.2 Fact 2: Sum rule
IMG_URL sumrule.png
ğ–¦¹ If f(n) is O(h(n)) and g(n) is O(h(n)), then f(n) + g(n) is O(h(n))
- Explanation: If f(n) â‰¤ c1Â·h(n) and g(n) â‰¤ c2Â·h(n), then f(n)+g(n) â‰¤ (c1+c2)Â·h(n)

12.3 Fact 3: Constant times nk
IMG_URL constant.png
ğ–¦¹ The function aÂ·n^k is O(n^k)
- Explanation: aÂ·n^k â‰¤ cÂ·n^k if c â‰¥ a
An Example: Even though 5Â·nÂ³ is big for small n, as n â†’ âˆ, it becomes insignificant compared to nâ´. Multiplying by a constant (5) cannot change the exponent â€” nÂ³ will always grow slower than nâ´ in the long run

12.4 Fact 4: Smaller powers grow slower
IMG_URL smallpower.png
ğ–¦¹ n^k is O(n^(k+j)) for any positive j
- Explanation: This works for c = 1 and N = 1

12.5 Polynomial rule
IMG_URL highestpower.png
ğ–¦¹ A polynomial grows at the rate of its highest power
ğ–¦¹ Example: f(n) = akÂ·n^k + akâˆ’1Â·n^(kâˆ’1) + â€¦ + a1Â·n + a0 is O(n^k)
â€¢ Also, f(n) is O(n^(k+j)) for any positive j

12.6 Logarithmic functions grow very slowly
ğ–¦¹ Algorithms with logarithmic running time are considered very good
ğ–¦¹ Some even slower functions exist, like log log n or constant time O(1), but they are rarely used

12.7 Fact 5: Constant multiple rule
ğ–¦¹ If f(n) = cÂ·g(n), then f(n) is O(g(n))
- Explanation: Multiplying by a fixed constant does not change the growth rate

12.8 Fact 6: Logarithms with any base have the same growth
IMG_URL logdiffbases.png
ğ–¦¹ log_a(n) is O(log_b(n)) for any positive a and b â‰  1
ğ–¦¹ All logarithms grow at the same rate
- Explanation: Using log rules, log_a(n) can be written as a constant Ã— log_b(n)

12.9 Fact 7: Using base 2 for convenience
ğ–¦¹ log_a(n) is O(lg n) for any positive a â‰  1
ğ–¦¹ lg n means log base 2 of n

13. Î© and Î˜ notations
ğ–¦¹ Î© notation gives a lower bound for how fast a function grows
ğ–¦¹ f(n) is Î©(g(n)) when f(n) â‰¥ cÂ·g(n) for all n â‰¥ N
â€¢ Means f grows at least as fast as g in the long run
- Explanation: Only the direction of the inequality changes compared to big-O
In other words, f(n cannot grow slower than g(n) after some point N)

13.1 Relation between Î© and O
ğ–¦¹ f(n) is Î©(g(n)) exactly when g(n) is O(f(n))
ğ–¦¹ Both notations allow many choices of c and N
â€¢ Many different lower bounds are possible for the same f

13.2 Examples of many possible lower bounds
ğ–¦¹ If f(n) is Î©(nÂ²), it is also Î©(n), Î©(nÂ¹áŸÂ²), Î©(nÂ¹áŸÂ³), and so on
ğ–¦¹ Also Î©(log n), Î©(log log n), etc.
- Explanation: Only the largest lower bound is interesting in practice

13.3 Î˜ notation idea
ğ–¦¹ Î˜ notation gives both lower and upper bounds together
ğ–¦¹ f(n) is Î˜(g(n)) if c1Â·g(n) â‰¤ f(n) â‰¤ c2Â·g(n) for all n â‰¥ N
- Explanation: Means f and g grow at the same rate in the long run

13.4 Link between O, Î©, and Î˜
ğ–¦¹ f(n) is Î˜(g(n)) only if f(n) is both O(g(n)) and Î©(g(n))
ğ–¦¹ For the function 2nÂ² + 3n + 1, the simplest Î˜ bound is nÂ²

14. Possible problems with big-O
ğ–¦¹ Big-O hides constants; a large constant can mislead comparisons
ğ–¦¹ Some algorithms may look worse by big-O but are faster for small n
- Explanation: Big-O only cares about the long run and ignores small n

14.1 Example of misleading big-O
ğ–¦¹ Compare 108Â·n and 10Â·nÂ²
ğ–¦¹ First is O(n), second is O(nÂ²)
â€¢ For n â‰¤ 10â·, second one is actually faster
- Explanation: Big-O alone may cause rejecting a better algorithm

14.2 Double-O (OO) notation idea
ğ–¦¹ OO(g(n)) means O(g(n)) but with a constant too large to be useful
ğ–¦¹ Example: 108Â·n is OO(n)
- Explanation: â€œToo largeâ€ depends on the application

15. Examples of complexities
ğ–¦¹ Algorithms can be grouped by how fast their running time grows
ğ–¦¹ Common groups: constant, logarithmic, linear, nÂ·log n, quadratic, cubic, exponential
- Explanation: Growth patterns show which algorithms are practical

15.1 Real-time execution examples
ğ–¦¹ With 1 million operations per second, quadratic on 1M items takes 11+ days
ğ–¦¹ Cubic on 1M items takes thousands of years
â€¢ Even huge hardware improvements help only a little for high-complexity algorithms
- Explanation: Good algorithm design is more important than fast hardware

15.2 Importance of complexity study
ğ–¦¹ Even fast computers cannot save badly designed algorithms
ğ–¦¹ Understanding complexity is essential, especially in data structures

16. Asymptotic complexity idea
ğ–¦¹ Asymptotic bounds help us estimate time and memory needs of algorithms
ğ–¦¹ We mostly study time complexity by counting assignment steps
â€¢ Comparisons are also counted in some cases
- Explanation: We focus on how the total work grows when input size grows

16.1 Simple loop example
ğ–¦¹ Code:
[pink]for[/pink] [yellow](i = sum = 0; i < n; i++)[/yellow]
    [pink]sum[/pink] [yellow]+= a[i];[/yellow]
ğ–¦¹ Two initial assignments, then loop runs n times
â€¢ Each loop step has 2 assignments (sum update and i update)
- Explanation: Total steps = 2 + 2n, so complexity is O(n)

16.2 Nested loop example (sums of subarrays starting at 0)
ğ–¦¹ Code:
[pink]for[/pink] [yellow](i = 0; i < n; i++)[/yellow] {
    [pink]for[/pink] [yellow](j = 1, sum = a[0]; j <= i; j++)[/yellow]
        [pink]sum[/pink] [yellow]+= a[j];[/yellow]
    [yellow]System.out.println(...);[/yellow]
}
ğ–¦¹ Outer loop runs n times; inner loop runs i times for each i
â€¢ Inner loop has 2 assignments per step
- Explanation: Total = 1 + 3n + 2(1+2+â€¦+(nâ€“1)) = O(nÂ²)

16.3 Nested loops but with fixed-size work
ğ–¦¹ We print sums of last five cells of each subarray starting at 0
ğ–¦¹ Code:
[pink]for[/pink] [yellow](i = 4; i < n; i++)[/yellow] {
    [pink]for[/pink] [yellow](j = i-3, sum = a[i-4]; j <= i; j++)[/yellow]
        [pink]sum[/pink] [yellow]+= a[j];[/yellow]
    [yellow]System.out.println(...);[/yellow]
}
â€¢ Outer loop runs nâ€“4 times
â€¢ Inner loop always runs 4 times (constant work)
- Explanation: Total = 1 + 8Â·(nâ€“4) = O(n)

16.4 Loops where iteration count depends on data order
ğ–¦¹ We find length of longest increasing subarray
ğ–¦¹ Code:
[pink]for[/pink] [yellow](i = 0, length = 1; i < n-1; i++)[/yellow] {
    [pink]for[/pink] [yellow](i1 = i2 = k = i; k < n-1 && a[k] < a[k+1]; k++, i2++)[/yellow];
    [pink]if[/pink] [yellow](length < i2 - i1 + 1)[/yellow]
        [pink]length[/pink] [yellow]= i2 - i1 + 1;[/yellow]
    [yellow]System.out.println(...);[/yellow]
}
ğ–¦¹ Worst case (array strictly increasing):
â€¢ Outer loop runs nâ€“1 times, inner loop runs (nâ€“1â€“i) times  
- Explanation: Total = O(nÂ²)
ğ–¦¹ Best case (array strictly decreasing):
â€¢ Inner loop runs once each time  
- Explanation: Total = O(n)

16.5 Binary search complexity
ğ–¦¹ Binary search works by checking the middle of the current array part
ğ–¦¹ Code:
[pink]int[/pink] [yellow]binarySearch(int[] arr, int key) {[/yellow]
    [pink]int[/pink] [yellow]lo = 0, mid, hi = arr.length-1;[/yellow]
    [pink]while[/pink] [yellow](lo <= hi) {[/yellow]
        [yellow]mid = (lo + hi)/2;[/yellow]
        [pink]if[/pink] [yellow](key < arr[mid])[/yellow]
            [yellow]hi = mid - 1;[/yellow]
        [pink]else if[/pink] [yellow](arr[mid] < key)[/yellow]
            [yellow]lo = mid + 1;[/yellow]
        [pink]else return[/pink] [yellow]mid;[/yellow]
    [yellow]}[/yellow]
    [pink]return[/pink] [yellow]-1;[/yellow]
[yellow]}[/yellow]
ğ–¦¹ If key is absent:
â€¢ Checked array sizes go n â†’ n/2 â†’ n/4 â†’ ... â†’ 1
- Explanation: Number of halvings = m where n / 2^m = 1, so m = logâ‚‚ n  
â€¢ Complexity = O(log n)
--END--
--BEGIN--23/11/2025--LINKED LISTS--
1. Arrays and their limitations
ğ–¦¹ Arrays store elements one after another in memory, i.e., sequentially
ğ–¦¹ Limitations of arrays:
â€¢ Fixed size
- To change the size, you must create a new array and copy all data.
â€¢ Sequential memory
- Elements are next to each other in memory.
- Inserting in the middle requires shifting other elements, which is slow.

2. Linked structures
ğ–¦¹ Used to overcome array limitations.
ğ–¦¹ Made of nodes, where each node has:
â€¢ Data
- The value you want to store.
â€¢ Reference(s)
- Links to other nodes.
ğ–¦¹ Nodes can be anywhere in memory.
ğ–¦¹ You move from one node to another using links.

3. Singly Linked List (SLL)
ğ–¦¹ Each node has a link only to its next node (successor).
ğ–¦¹ Nodes are connected like a chain.
ğ–¦¹ Access the list using one variable pointing to the first node.
ğ–¦¹ Last node points to null to indicate the end of the list.
IMG_URL sll.png

4. Singly Linked List (SLL) implementation
ğ–¦¹ Demonstrates creating and linking nodes in a singly linked list.
ğ–¦¹ Code example:
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/linked-list/sll.cpp

5. Adding a Node to Singly Linked List
ğ–¦¹ A singly linked list has a head pointer pointing to the first node.
ğ–¦¹ Each node stores data and a pointer to the next node.

6. Deleting a Node from Singly Linked List
ğ–¦¹ A singly linked list has a head pointer pointing to the first node.
ğ–¦¹ Each node stores data and a pointer to the next node.
ğ–¦¹ Example C++ implementation:

[pink]#include[/pink] [yellow]<iostream>[/yellow]
[yellow]using namespace std;[/yellow]

[pink]class[/pink] SLLNode {
    [pink]public[/pink]:
        [pink]int[/pink] data;
        SLLNode* next;
        SLLNode([pink]int[/pink] data, SLLNode* next = [green]nullptr[/green]) {
            this->data = data;
            this->next = next;
        }
};

[pink]class[/pink] SinglyLinkedList {
    [pink]private[/pink]:
        SLLNode* head;
    [pink]public[/pink]:
        SinglyLinkedList() {
            head = [green]nullptr[/green];
        }
        ~SinglyLinkedList() {  // destructor to free memory
            SLLNode* temp = head;
            while(temp != [green]nullptr[/green]) {
                SLLNode* nextNode = temp->next;
                [pink]delete[/pink] temp;
                temp = nextNode;
            }
        }
        void printAll() {
            SLLNode* temp = head;
            while(temp != [green]nullptr[/green]) {
                [green]cout[/green] << temp->data << "->";
                temp = temp->next;
            }
            [green]cout[/green] << "END\n";
        }
        void addNode([pink]int[/pink] value) {
            SLLNode* newNode = [pink]new[/pink] SLLNode(value);
            if(head == [green]nullptr[/green]) {
                head = newNode;
            } else {
                SLLNode* temp = head;
                while(temp->next != [green]nullptr[/green]) {
                    temp = temp->next;
                }
                temp->next = newNode;
            }
        }
        void deleteNode([pink]int[/pink] value) {
            if(head == [green]nullptr[/green]) {
                [green]cout[/green] << "NOTHING TO DELETE\n";
            } else {
                SLLNode* temp = head;
                SLLNode* prev = [green]nullptr[/green];
                while(temp != [green]nullptr[/green] && temp->data != value) {
                    prev = temp;
                    temp = temp->next;
                }
                if(temp == [green]nullptr[/green]) {
                    [green]cout[/green] << "DATA NOT THERE\n";
                } else if(temp == head) {
                    head = head->next;
                } else {
                    prev->next = temp->next;
                }
                [pink]delete[/pink] temp;
            }
        }
};

[pink]int[/pink] [pink]main[/pink]() {
    SinglyLinkedList sll;
    sll.addNode(1);
    sll.addNode(2);
    sll.addNode(3);
    sll.printAll();
    sll.deleteNode(1);
    sll.printAll();
    sll.deleteNode(11);
    [pink]return[/pink] 0;
}

ğ–¦¹ [pink]deleteNode[/pink] searches for the node with given value.
ğ–¦¹ If the list is empty, it prints "NOTHING TO DELETE".
ğ–¦¹ If the value is not found, it prints "DATA NOT THERE".
ğ–¦¹ If the node is the head, update head to next node.
ğ–¦¹ Otherwise, update previous node's next to skip the deleted node.
ğ–¦¹ The destructor frees all nodes to avoid memory leaks.

7. Singly Linked List Operations and Complexity
ğ–¦¹ Insertion at head: O(1)
â€¢ Create a new node and point it to the current head.
- Very fast because no traversal is needed.
ğ–¦¹ Insertion at tail (without tail pointer): O(n)
â€¢ Traverse from head to the last node.
â€¢ Link the new node after the last node.
- Slower because traversal is needed.
ğ–¦¹ Insertion after a given node: O(1)
â€¢ If you have a pointer to the node, link the new node immediately.
- Constant time insertion.
ğ–¦¹ Deletion of head node: O(1)
â€¢ Move head pointer to the next node.
â€¢ Delete the old head node.
- Fast because no traversal is needed.
ğ–¦¹ Deletion of a node by value: O(n)
â€¢ Traverse the list to find the node with the value.
â€¢ Remove the node and fix links.
- Slower because search may require visiting all nodes.
ğ–¦¹ Searching for a value: O(n)
â€¢ Check each node from head to tail.
- Linear time search.

8. What is a DLL?
IMG_URL dll.png
ğ–¦¹ A list where each node has two links: next and prev
ğ–¦¹ You can move both forward and backward
ğ–¦¹ Helpful when you need two-way movement

9. Node structure
ğ–¦¹ Each node has:
â€¢ data
â€¢ next pointer â†’ goes to next node
â€¢ prev pointer â†’ goes to previous node
ğ–¦¹ First node has prev = NULL
ğ–¦¹ Last node has next = NULL

10. Basic picture
ğ–¦¹ NULL <- [10] <-> [20] <-> [30] -> NULL
11. Doubly Linked List Operations and Complexity
ğ–¦¹ Insertion at head: O(1)
â€¢ Create new node
â€¢ new->next = head
â€¢ head->prev = new
â€¢ head = new
- No need to walk through list
ğ–¦¹ Insertion at tail without tail pointer: O(n)
â€¢ Walk from head to last node
â€¢ last->next = new
â€¢ new->prev = last
- Must visit all nodes
ğ–¦¹ Insertion at tail with tail pointer: O(1)
â€¢ tail->next = new
â€¢ new->prev = tail
â€¢ tail = new
- Very quick
ğ–¦¹ Insertion after a given node: O(1)
â€¢ new->next = node->next
â€¢ new->prev = node
â€¢ Fix next nodeâ€™s prev
â€¢ Fix node->next
- Only pointer updates
ğ–¦¹ Insertion before a given node: O(1)
â€¢ new->prev = node->prev
â€¢ new->next = node
â€¢ Fix prev nodeâ€™s next
â€¢ Fix node->prev
- DLL makes â€œinsert beforeâ€ easy
ğ–¦¹ Deletion of head: O(1)
â€¢ head = head->next
â€¢ head->prev = NULL
â€¢ delete old head
- Very fast
ğ–¦¹ Deletion of tail with tail pointer: O(1)
â€¢ tail = tail->prev
â€¢ tail->next = NULL
â€¢ delete old tail
- No traversal needed
ğ–¦¹ Deletion by value: O(n)
â€¢ Walk to find the value
â€¢ Fix next and prev
â€¢ Delete the node
- Search takes linear time
ğ–¦¹ Searching for a value: O(n)
â€¢ Move node by node
- Same as singly list
ğ–¦¹ Forward traversal: O(n)
â€¢ Use next pointer

ğ–¦¹ Backward traversal: O(n)
â€¢ Use prev pointer
- Only DLL can do backward travel

12. Extra Advanced DLL Operations
ğ–¦¹ Reverse the list: O(n)
â€¢ Swap next and prev for each node
â€¢ Move head to last node
ğ–¦¹ Insert at position k: O(n)
â€¢ Walk to k
â€¢ Insert before or after
ğ–¦¹ Delete at position k: O(n)
â€¢ Walk to k
â€¢ Remove the node

13. Memory Usage
ğ–¦¹ DLL uses more memory than singly lists
â€¢ data
â€¢ next pointer
â€¢ prev pointer
ğ–¦¹ Extra pointer takes more space

14. Advantages of DLL
ğ–¦¹ Move in both directions
ğ–¦¹ Delete easier because prev exists
ğ–¦¹ Insert before any node easily
ğ–¦¹ Good for systems like:
â€¢ LRU cache
â€¢ Browser history
â€¢ Undo-redo
â€¢ Playlist navigation
ğ–¦¹ Fast tail deletion if tail pointer exists

15. Disadvantages of DLL
ğ–¦¹ Uses more memory
ğ–¦¹ More complex to code
ğ–¦¹ Must update two pointers
ğ–¦¹ Mistakes in pointers can break list

16. When to Use DLL
ğ–¦¹ Use DLL when:
â€¢ You need two-way movement
â€¢ You want quick delete after finding node
â€¢ You need undo/redo
â€¢ You want LRU cache
â€¢ You need easy navigation
ğ–¦¹ Do not use DLL when:
â€¢ You want simple structure
â€¢ Memory must be saved
â€¢ Only forward travel is needed
â€¢ Backward travel not needed

17. Doubly Linked List Example Program
[pink]#include[/pink] <iostream>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]class[/pink] [yellow]DLLNode[/yellow] {
[pink]public[/pink]:
    [pink]int[/pink] [yellow]data[/yellow];
    [blue]DLLNode*[/blue] [yellow]next[/yellow];
    [blue]DLLNode*[/blue] [yellow]prev[/yellow];

    [yellow]DLLNode[/yellow]([pink]int[/pink] [yellow]data[/yellow],
              [blue]DLLNode*[/blue] [yellow]next[/yellow] = [green]nullptr[/green],
              [blue]DLLNode*[/blue] [yellow]prev[/yellow] = [green]nullptr[/green]) {
        [pink]this[/pink]->[yellow]data[/yellow] = [yellow]data[/yellow];
        [pink]this[/pink]->[yellow]next[/yellow] = [yellow]next[/yellow];
        [pink]this[/pink]->[yellow]prev[/yellow] = [yellow]prev[/yellow];
    }
};

[pink]class[/pink] [yellow]DoublyLinkedList[/yellow] {
[pink]private[/pink]:
    [blue]DLLNode*[/blue] [yellow]head[/yellow];

[pink]public[/pink]:
    [yellow]DoublyLinkedList[/yellow]() {
        [yellow]head[/yellow] = [green]nullptr[/green];
    }

    [pink]~DoublyLinkedList[/pink]() {
        [blue]DLLNode*[/blue] [yellow]temp[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]temp[/yellow] != [green]nullptr[/green]) {
            [blue]DLLNode*[/blue] [yellow]nextNode[/yellow] = [yellow]temp[/yellow]->[yellow]next[/yellow];
            [pink]delete[/pink] [yellow]temp[/yellow];
            [yellow]temp[/yellow] = [yellow]nextNode[/yellow];
        }
    }

    [pink]void[/pink] [yellow]printAll[/yellow]() {
        [blue]DLLNode*[/blue] [yellow]temp[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]temp[/yellow] != [green]nullptr[/green]) {
            [green]cout[/green] << [yellow]temp[/yellow]->[yellow]data[/yellow] << " <-> ";
            [yellow]temp[/yellow] = [yellow]temp[/yellow]->[yellow]next[/yellow];
        }
        [green]cout[/green] << "END\n";
    }

    [pink]void[/pink] [yellow]addNode[/yellow]([pink]int[/pink] [yellow]value[/yellow]) {
        [blue]DLLNode*[/blue] [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]DLLNode[/yellow]([yellow]value[/yellow]);

        [pink]if[/pink] ([yellow]head[/yellow] == [green]nullptr[/green]) {
            [yellow]head[/yellow] = [yellow]newNode[/yellow];
            [pink]return[/pink];
        }

        [blue]DLLNode*[/blue] [yellow]temp[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]temp[/yellow]->[yellow]next[/yellow] != [green]nullptr[/green]) {
            [yellow]temp[/yellow] = [yellow]temp[/yellow]->[yellow]next[/yellow];
        }

        [yellow]temp[/yellow]->[yellow]next[/yellow] = [yellow]newNode[/yellow];
        [yellow]newNode[/yellow]->[yellow]prev[/yellow] = [yellow]temp[/yellow];
    }

    [pink]void[/pink] [yellow]deleteNode[/yellow]([pink]int[/pink] [yellow]value[/yellow]) {
        [pink]if[/pink] ([yellow]head[/yellow] == [green]nullptr[/green]) {
            [green]cout[/green] << "NOTHING TO DELETE\n";
            [pink]return[/pink];
        }

        [blue]DLLNode*[/blue] [yellow]temp[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]temp[/yellow] != [green]nullptr[/green] &&
               [yellow]temp[/yellow]->[yellow]data[/yellow] != [yellow]value[/yellow]) {
            [yellow]temp[/yellow] = [yellow]temp[/yellow]->[yellow]next[/yellow];
        }

        [pink]if[/pink] ([yellow]temp[/yellow] == [green]nullptr[/green]) {
            [green]cout[/green] << "DATA NOT THERE\n";
            [pink]return[/pink];
        }

        [pink]if[/pink] ([yellow]temp[/yellow] == [yellow]head[/yellow]) {
            [yellow]head[/yellow] = [yellow]head[/yellow]->[yellow]next[/yellow];
            [pink]if[/pink] ([yellow]head[/yellow] != [green]nullptr[/green]) {
                [yellow]head[/yellow]->[yellow]prev[/yellow] = [green]nullptr[/green];
            }
        } [pink]else[/pink] {
            [yellow]temp[/yellow]->[yellow]prev[/yellow]->[yellow]next[/yellow] = [yellow]temp[/yellow]->[yellow]next[/yellow];

            [pink]if[/pink] ([yellow]temp[/yellow]->[yellow]next[/yellow] != [green]nullptr[/green]) {
                [yellow]temp[/yellow]->[yellow]next[/yellow]->[yellow]prev[/yellow] = [yellow]temp[/yellow]->[yellow]prev[/yellow];
            }
        }

        [pink]delete[/pink] [yellow]temp[/yellow];
    }
};

[pink]int[/pink] [yellow]main[/yellow]() {
    [yellow]DoublyLinkedList[/yellow] [yellow]dll[/yellow];

    ;
    ;
    ;

    [yellow]dll[/yellow].[yellow]printAll[/yellow]();

    ;
    [yellow]dll[/yellow].[yellow]printAll[/yellow]();

    ;

    [pink]return[/pink] 0;
}

18. What is a Circularly Linked List (CLL)?
ğ–¦¹ Last node points back to first node, forming a loop
ğ–¦¹ Each node has data and next pointer
ğ–¦¹ Can be singly circular (one next) or doubly circular (next and prev)
ğ–¦¹ No true head or tail; can start from any node
ğ–¦¹ A cursor node marks starting point for operations

19. Structure
ğ–¦¹ Singly Circular:
IMG_URL csll.png
ğ–¦¹ Doubly Circular:
IMG_URL cdll.png

21. Key Concepts
ğ–¦¹ Cursor marks special node for operations
â€¢ back â†’ element at cursor
â€¢ front â†’ element after cursor
ğ–¦¹ Traversal
â€¢ Forward: follow next, eventually cycles back
â€¢ Backward (doubly): follow prev, cycles back
ğ–¦¹ Head/Tail Access
â€¢ Singly circular: tail pointer may be enough
â€¢ Tailâ€™s next points to head

22. Advantages of Circular List
ğ–¦¹ Useful in round-robin scheduling
ğ–¦¹ Can implement playlists, queues, process scheduling
ğ–¦¹ In doubly circular, insertion/deletion at both ends is easy
ğ–¦¹ No end; can cycle infinitely

23. Operations and Complexity
ğ–¦¹ Singly Circular:
â€¢ Add after cursor: O(1)
- Create new node
- newNode->next = cursor->next
- cursor->next = newNode
â€¢ Remove after cursor: O(1)
- Only node â†’ cursor = NULL
- Else â†’ cursor->next = cursor->next->next
- Delete old node
â€¢ Advance cursor: O(1)
- cursor = cursor->next
â€¢ Access front/back: O(1)
- back() = cursor->elem
- front() = cursor->next->elem
ğ–¦¹ Doubly Circular:
â€¢ Insert/delete at head or tail: O(1)
- prev pointer allows direct access to previous node
â€¢ Traversal backward: O(n)
- Can move in reverse without loops

24. Examples of Use
ğ–¦¹ Round-robin process scheduling
â€¢ Each process is a node
â€¢ Cursor moves to next process after execution
ğ–¦¹ Digital Audio Player / Playlist
â€¢ Each song is a node
â€¢ Cursor points to current song
â€¢ Advance moves to next song
â€¢ Add/remove songs after cursor
ğ–¦¹ Example Playlist Sequence
â€¢ Empty list: []
â€¢ Add "StayinAlive": [StayinAlive*]
â€¢ Add "LeFreak": [LeFreak, StayinAlive*]
â€¢ Add "JiveTalkin": [JiveTalkin, LeFreak, StayinAlive*]
â€¢ Advance cursor twice: [StayinAlive, JiveTalkin, LeFreak*]
â€¢ Remove after cursor: [JiveTalkin, LeFreak*]
â€¢ Add "DiscoInferno": [DiscoInferno, JiveTalkin, LeFreak*]

25. Memory Usage
ğ–¦¹ Similar to singly or doubly linked lists
ğ–¦¹ Doubly circular uses extra memory for prev pointers

26. Advantages of Circular Lists
ğ–¦¹ No head/tail limits; perfect for cycling
ğ–¦¹ O(1) insertion and deletion after cursor (or tail in doubly circular)
ğ–¦¹ Forward/backward traversal (doubly circular)
ğ–¦¹ Efficient for playlists, queues, round-robin

27. Disadvantages
ğ–¦¹ Slightly more complex than SLL or DLL
ğ–¦¹ Singly circular: reverse traversal difficult
ğ–¦¹ Must maintain links carefully; broken link breaks cycle

28. Reverse A Linked List
IMG_URL reverse-ll.gif
ğ–¦¹ PSEUDOCODE
function reverseLinkedList(head):
    prev = NULL           // start with prev as NULL
    curr = head           // start at the first node
    
    while curr is not NULL:
        nextNode = curr.next   // remember the next node
        curr.next = prev       // reverse the link
        prev = curr            // move prev forward
        curr = nextNode        // move curr forward
    
    head = prev           // prev is the new head
    return head

29. Skip List
ğ–¦¹ A skip list speeds up search, insertion, and deletion in a sorted linked list
ğ–¦¹ Adds extra "express lanes" or higher-level pointers
ğ–¦¹ Normal linked list: check nodes one by one â†’ slow
ğ–¦¹ Skip list: jump ahead using higher levels, drop down when needed
ğ–¦¹ Example:
â€¢ Level 3: A ------------------> E
â€¢ Level 2: A --------> C ------> E
â€¢ Level 1: A -> B -> C -> D -> E

30. Properties
ğ–¦¹ Elements must be sorted for skipping to work
ğ–¦¹ Multiple levels: top levels few nodes, bottom level all nodes
ğ–¦¹ Randomized levels: each node gets level randomly, balances list probabilistically
ğ–¦¹ Average time: O(log n) for search, insertion, deletion
ğ–¦¹ Space: O(n)

31. Analogy
ğ–¦¹ Like a book with page numbers
â€¢ Normal: read page by page
â€¢ Skip list: table of contents + bookmarks â†’ jump ahead, fine-tune
ğ–¦¹ Faster than normal linked list for sorted data
ğ–¦¹ Simpler than balanced trees like AVL or Red-Black

32. Search â€“ Average O(log n), Worst O(n)
ğ–¦¹ Average:
â€¢ Multiple levels allow skipping many nodes
â€¢ Each step reduces remaining nodes roughly by half
â€¢ Levels â‰ˆ logâ‚‚(n)
â€¢ Horizontal moves small
- Total steps â‰ˆ logâ‚‚(n) â†’ O(log n)
ğ–¦¹ Worst case:
â€¢ All nodes at level 1 â†’ behaves like normal linked list
â€¢ Traverse all n nodes â†’ O(n)

33. Insertion â€“ Average O(log n)
ğ–¦¹ Search for correct position (average O(log n))
ğ–¦¹ Insert node at all its levels (update pointers)
ğ–¦¹ Randomized level assignment limits number of levels per node
- Average insertion â‰ˆ O(log n)
- Worst case rare: all nodes at level 1 â†’ O(n)

34. Deletion â€“ Average O(log n)
ğ–¦¹ Search for node (average O(log n))
ğ–¦¹ Update pointers of predecessors at all levels
ğ–¦¹ Same reasoning as insertion â†’ total cost â‰ˆ O(log n)

35. Space â€“ O(n)
ğ–¦¹ Each node stores array of next pointers = nodeâ€™s level
ğ–¦¹ Average node level small (â‰ˆ 2) â†’ extra memory per node constant
ğ–¦¹ Total nodes = n â†’ total space O(n)

36. What is a Skip List
IMG_URL skiplist.gif
ğ–¦¹ An advanced linked list with multiple levels of forward pointers
ğ–¦¹ Faster search, insertion, and deletion using express lanes
ğ–¦¹ Each node has a randomly assigned level
ğ–¦¹ Search starts from top level and goes down

37. Node Levels
ğ–¦¹ Each node can have multiple levels = number of forward pointers
ğ–¦¹ Higher levels skip more nodes
ğ–¦¹ Levels assigned randomly to balance the list
ğ–¦¹ Example:
â€¢ Nodes: 1 2 3 4 5 6 7
â€¢ Levels: 1â†’5, 2â†’2, 3â†’3, 4â†’1, 5â†’2, 6â†’1, 7â†’1

38. How Search Works
ğ–¦¹ Start at header node, topmost level
ğ–¦¹ Move forward while next nodeâ€™s key < search key
ğ–¦¹ Drop down one level if next is nullptr or â‰¥ key
ğ–¦¹ Repeat until level 0
ğ–¦¹ curr points to predecessor â†’ check level 0:
â€¢ curr = curr->forward[0]; if curr != nullptr && curr->key == key found
- Step forward at level 0 because curr ends as largest node < key

39. Why Skip List is Fast
ğ–¦¹ Multiple levels allow jumping over nodes
ğ–¦¹ Average search = O(log n)
ğ–¦¹ Worst case = O(n) if all nodes end at level 0
ğ–¦¹ Space = O(n)

40. Example Search (key = 5)
ğ–¦¹ Nodes & levels: 1(5), 2(2), 3(3), 4(1), 5(2), 6(1), 7(1)
ğ–¦¹ Steps:
â€¢ Start at node 1, level 5 â†’ forward[5]=6 â†’ 6>5 â†’ drop to level 4
â€¢ Level 4 â†’ forward[4]=5 â†’ candidate? curr still points to 1
â€¢ Move forward level 0: curr=curr->forward[0] â†’ points to 5 â†’ key==5 âœ…

41. Key Operations
ğ–¦¹ Search: Avg O(log n), Worst O(n)
ğ–¦¹ Insertion: Avg O(log n)
ğ–¦¹ Deletion: Avg O(log n)
ğ–¦¹ Space: O(n)

42. Express Lanes Analogy
ğ–¦¹ Level >0 pointers = express lanes
ğ–¦¹ Level 0 pointers = normal linked list
ğ–¦¹ Node 1 level 5 can jump over nodes 2,3,4,5 to reach 6
ğ–¦¹ Nodes exist at multiple levels via random assignment

43. C++ Implementation
ğ–¦¹ Includes header, random, time libraries
ğ–¦¹ [pink]class[/pink] [yellow]Node[/yellow] with [yellow]key[/yellow], [blue]forward[/blue], [yellow]nodeLevel[/yellow]
ğ–¦¹ [pink]class[/pink] [yellow]SkipList[/yellow] with [yellow]level[/yellow] and [yellow]header[/yellow]
ğ–¦¹ Random level generator: 0.5 probability to go up
ğ–¦¹ [pink]insert[/pink](key): find position, assign random level, update forward pointers
ğ–¦¹ [pink]search[/pink](key): move top-down, return found/not found
ğ–¦¹ [pink]printList[/pink](): print all levels
ğ–¦¹ [pink]main[/pink](): create skip list, insert keys, print list, search keys
â€¢ Code Example:
[pink]#include[/pink] <yellow>iostream</yellow>  
[pink]#include[/pink] <yellow>cstdlib</yellow>  
[pink]#include[/pink] <yellow>ctime</yellow>  
using namespace <green>std</green>;  

const int MAX_LEVEL = 4;  

[pink]class[/pink] [yellow]Node[/yellow] {  
public:  
    int key;  
    [blue]Node**[/blue] forward;  
    int nodeLevel;  
    [pink]Node[/pink](int key, int level) { /* create forward array */ }  
};  

[pink]class[/pink] [yellow]SkipList[/yellow] {  
private:  
    int level;  
    [blue]Node*[/blue] header;  
public:  
    [pink]SkipList[/pink]() { /* init header */ }  
    int randomLevel() { /* 0.5 probability */ }  
    void insert(int key) { /* insert node */ }  
    bool search(int key) { /* search node */ }  
    void printList() { /* print levels */ }  
};  

[pink]int[/pink] [pink]main[/pink]() {  
    srand(time(0));  
    SkipList list;  
    list.insert(3); list.insert(6); /* insert more */  
    list.printList();  
    list.search(9); list.search(15);  
    return 0;  
}

44. Self-Organizing Lists
ğ–¦¹ Normal linked list is slow for search because you check nodes one by one
ğ–¦¹ Self-organizing lists reorder nodes dynamically to speed up search for frequent items

45. Move-to-Front Method
ğ–¦¹ After finding an element, move it to the beginning
ğ–¦¹ Frequently searched items stay near the front
ğ–¦¹ Example: A B C D, search D â†’ D A B C

46. Transpose Method
ğ–¦¹ After finding an element, swap it with the previous node
ğ–¦¹ Element moves gradually toward front
ğ–¦¹ Example: A B C D, search D â†’ swap with C â†’ A B D C

47. Count Method
ğ–¦¹ Keep a count of how many times each element is accessed
ğ–¦¹ Sort list so most accessed elements are near front
ğ–¦¹ Example: D accessed 3 times, B accessed 1 time â†’ D comes before B

48. Ordering Method
ğ–¦¹ Keep list sorted by natural order (alphabetical, birthday, salary)
ğ–¦¹ Position of elements does not change dynamically
ğ–¦¹ Example: Alice, Bob, Charlie, David

49. How New Data is Inserted
ğ–¦¹ In move-to-front, transpose, count methods: new data goes to end of list
ğ–¦¹ In ordering method: insert at correct position to maintain order

50. Why This Helps
ğ–¦¹ Frequently searched items stay near front â†’ fewer steps to find
ğ–¦¹ Useful for repeated searches in a data stream
ğ–¦¹ In ordering method, can stop early if element doesnâ€™t exist because list is sorted

51. Inserting a Node in the Middle of a Doubly Linked List
ğ–¦¹ To insert in the middle, first find the middle node
ğ–¦¹ Use two pointers: slow and fast
â€¢ [yellow]slow[/yellow] moves 1 step at a time
â€¢ [yellow]fast[/yellow] moves 2 steps at a time
â€¢ When [yellow]fast[/yellow] reaches end (nullptr), [yellow]slow[/yellow] points to middle
- Code:
[pink]while[/pink] ([yellow]fast[/yellow] != [green]nullptr[/green] && [yellow]fast[/yellow]->next != [green]nullptr[/green]) {
    [yellow]slow[/yellow] = [yellow]slow[/yellow]->next;       // 1 step
    [yellow]fast[/yellow] = [yellow]fast[/yellow]->next->next; // 2 steps
}
ğ–¦¹ Once middle node is found, insert new node before or after it
â€¢ Adjust [yellow]prev[/yellow] and [yellow]next[/yellow] pointers of surrounding nodes

52. Adapting Binary Search to Linked Lists
ğ–¦¹ Linked lists donâ€™t allow direct index access like arrays
ğ–¦¹ Binary search needs O(n) to reach middle each time
ğ–¦¹ So total time = O(n) + O(n/2) + O(n/4) + ... â‰ˆ O(n)
- Not as efficient as array binary search (O(log n))
ğ–¦¹ Works logically but practically slower for large lists

53. Unrolled Linked List
IMG_URL unrolled_ll.png
ğ–¦¹ A linked list variation where each node stores multiple elements in an array plus a pointer to next node.
ğ–¦¹ Purpose: reduce pointer overhead, improve cache performance, and reduce wasted memory.
ğ–¦¹ Acts like a mix between arrays and linked lists: dynamic insertion/deletion like linked lists but stores chunks to reduce overhead.

54. Node Structure
ğ–¦¹ Each node has:
â€¢ [yellow]next[/yellow] pointer (and optionally [yellow]prev[/yellow] for doubly)
â€¢ [yellow]numElements[/yellow] â†’ number of actual elements
â€¢ [yellow]elements[][/yellow] â†’ array of capacity [yellow]maxElements[/yellow]
- Typically nodes aim to be at least half full for efficiency
- Example:
[pink]record[/pink] [yellow]node[/yellow] {
   [yellow]node next[/yellow];
   [pink]int[/pink] [yellow]numElements[/yellow];
   [yellow]array elements[/yellow];
}

55. Capacity / Block Size
ğ–¦¹ Choose [yellow]maxElements[/yellow] so each node fits well into cache lines
ğ–¦¹ Example: each node fills one cache line or a small multiple

56. List Layout
ğ–¦¹ Nodes chained: Node1 â†’ Node2 â†’ Node3 â€¦
ğ–¦¹ Each node has an array of elements, e.g., Node1: [1,2,3,4], Node2: [5,6,7,8]
ğ–¦¹ Doubly unrolled list: nodes also have [yellow]prev[/yellow] pointer

57. Search / Traversal
ğ–¦¹ Traverse nodes until correct node found, then search inside nodeâ€™s array
ğ–¦¹ Reduces pointer hops because nodes hold multiple elements
ğ–¦¹ Example: n elements, block size ~âˆšn â†’ ~âˆšn nodes, each ~âˆšn size â†’ search ~O(âˆšn)

58. Insertion
ğ–¦¹ Find node where insertion belongs
ğ–¦¹ If node has space â†’ insert in array (shift if needed)
ğ–¦¹ If node full â†’ split node, move half elements to new node, insert new element

59. Deletion
ğ–¦¹ Find elementâ€™s node, remove from array, shift items
ğ–¦¹ If node falls below threshold (e.g., < half full) â†’ merge with neighbor or rebalance

60. Advantages
ğ–¦¹ Reduced pointer overhead: one pointer per node instead of per element
ğ–¦¹ Better cache performance: contiguous memory access inside node
ğ–¦¹ More efficient than plain linked lists for dynamic sequences

61. Disadvantages / Trade-offs
ğ–¦¹ Slightly complex: splitting/merging nodes, managing arrays inside nodes
ğ–¦¹ Large block size with few elements wastes space
ğ–¦¹ Within-node search is linear unless extra indexing used
ğ–¦¹ Worst-case time may still be linear in number of nodes

62. Complexity Summary
ğ–¦¹ Let n = total elements, B = block size
ğ–¦¹ Number of nodes â‰ˆ n/B
ğ–¦¹ Search = O(n/B + B)
ğ–¦¹ Insert/Delete = O(B) (may involve split/merge)
ğ–¦¹ Space overhead per element reduced compared to plain linked list

63. Example: 16 elements, block size 4
ğ–¦¹ Nodes: Node1: [1,2,3,4] â†’ Node2: [5,6,7,8] â†’ Node3: [9,10,11,12] â†’ Node4: [13,14,15,16]
ğ–¦¹ Search 7: traverse Node1 â†’ Node2, then linear scan inside Node2 â†’ 5 comparisons vs 7 in normal linked list
ğ–¦¹ Worst-case search 16: 3 node traversals + 4 inside-node â†’ 7 comparisons vs 16 in normal linked list

64. Choosing Block Size B
ğ–¦¹ Too small â†’ behaves like normal linked list
ğ–¦¹ Too large â†’ inside-node search slow
ğ–¦¹ Sweet spot: B â‰ˆ âˆšn â†’ search O(âˆšn)
ğ–¦¹ Example: n=10,000 â†’ B=100 â†’ ~100 nodes, inside-node scan â‰¤ 100 â†’ ~200 comparisons

65. C++ Program for Unrolled Linked List
[pink]#include[/pink] <[green]iostream[/green]>
[pink]#include[/pink] <[green]vector[/green]>
[pink]using[/pink] [pink]namespace[/pink] [green]std[/green];

[pink]class[/pink] [yellow]Node[/yellow] {
[pink]public[/pink]:
    [green]vector[/green]<[blue]int[/blue]> [yellow]elements[/yellow];
    [yellow]Node[/yellow]* [yellow]next[/yellow];
    [blue]int[/blue] [yellow]capacity[/yellow];

    [pink]Node[/pink]([blue]int[/blue] [yellow]cap[/yellow]) {
        [yellow]capacity[/yellow] = [yellow]cap[/yellow];
        [yellow]next[/yellow] = [green]nullptr[/green];
    }
};

[pink]class[/pink] [yellow]UnrolledLinkedList[/yellow] {
[pink]private[/pink]:
    [yellow]Node[/yellow]* [yellow]head[/yellow];
    [blue]int[/blue] [yellow]nodeCapacity[/yellow];

[pink]public[/pink]:
    [pink]UnrolledLinkedList[/pink]([blue]int[/blue] [yellow]cap[/yellow]) {
        [yellow]nodeCapacity[/yellow] = [yellow]cap[/yellow];
        [yellow]head[/yellow] = [pink]new[/pink] [yellow]Node[/yellow]([yellow]nodeCapacity[/yellow]);
    }

    [pink]void[/pink] [yellow]insert[/yellow]([blue]int[/blue] [yellow]val[/yellow]) {
        [yellow]Node[/yellow]* [yellow]curr[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]curr[/yellow]->[yellow]next[/yellow] != [green]nullptr[/green])
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]next[/yellow];

        [pink]if[/pink] ([yellow]curr[/yellow]->[yellow]elements[/yellow].[green]size[/green]() < [yellow]curr[/yellow]->[yellow]capacity[/yellow]) {
            [yellow]curr[/yellow]->[yellow]elements[/yellow].[green]push_back[/green]([yellow]val[/yellow]);
        } [pink]else[/pink] {
            [yellow]Node[/yellow]* [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]Node[/yellow]([yellow]nodeCapacity[/yellow]);
            [yellow]newNode[/yellow]->[yellow]elements[/yellow].[green]push_back[/green]([yellow]val[/yellow]);
            [yellow]curr[/yellow]->[yellow]next[/yellow] = [yellow]newNode[/yellow];
        }
    }

    [pink]bool[/pink] [yellow]search[/yellow]([blue]int[/blue] [yellow]val[/yellow]) {
        [yellow]Node[/yellow]* [yellow]curr[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [pink]if[/pink] (![yellow]curr[/yellow]->[yellow]elements[/yellow].[green]empty[/green]() && [yellow]val[/yellow] <= [yellow]curr[/yellow]->[yellow]elements[/yellow].[green]back[/green]()) {
                [pink]for[/pink] ([blue]int[/blue] [yellow]x[/yellow] : [yellow]curr[/yellow]->[yellow]elements[/yellow]) {
                    [pink]if[/pink] ([yellow]x[/yellow] == [yellow]val[/yellow]) {
                        [green]cout[/green] << "Found " << [yellow]val[/yellow] << " in node.\n";
                        [pink]return[/pink] [green]true[/green];
                    }
                }
                [pink]return[/pink] [green]false[/green];
            }
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]next[/yellow];
        }
        [green]cout[/green] << [yellow]val[/yellow] << " not found in list.\n";
        [pink]return[/pink] [green]false[/green];
    }

    [pink]void[/pink] [yellow]printList[/yellow]() {
        [yellow]Node[/yellow]* [yellow]curr[/yellow] = [yellow]head[/yellow];
        [blue]int[/blue] [yellow]nodeId[/yellow] = 1;
        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [green]cout[/green] << "Node " << [yellow]nodeId[/yellow] << ": ";
            [pink]for[/pink] ([blue]int[/blue] [yellow]x[/yellow] : [yellow]curr[/yellow]->[yellow]elements[/yellow])
                [green]cout[/green] << [yellow]x[/yellow] << " ";
            [green]cout[/green] << [green]endl[/green];
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]next[/yellow];
            [yellow]nodeId[/yellow]++;
        }
    }
};

[pink]int[/pink] [pink]main[/pink]() {
    [blue]int[/blue] [yellow]nodeCapacity[/yellow] = 4;
    [yellow]UnrolledLinkedList[/yellow] [yellow]list[/yellow]([yellow]nodeCapacity[/yellow]);

    [pink]for[/pink] ([blue]int[/blue] [yellow]i[/yellow] = 1; [yellow]i[/yellow] <= 16; [yellow]i[/yellow]++)
        [yellow]list[/yellow].[yellow]insert[/yellow]([yellow]i[/yellow]);

    [yellow]list[/yellow].[yellow]printList[/yellow]();

     ;
     ;
     ;

    [pink]return[/pink] 0;
}

66. XOR Linked List
IMG_URL xorll.png
ğ–¦¹ A normal doubly linked list has two pointers per node: next (points to next node) and prev (points to previous node)
ğ–¦¹ XOR linked list reduces this to one pointer per node by storing XOR(prev, next)
â€¢ Each node has [blue]Node*[/blue] [yellow]npx[/yellow] = prev XOR next
- Using XOR, if you know one node (prev or next), you can compute the other

67. How it works
ğ–¦¹ XOR is a bitwise operation: a XOR b lets you reconstruct a or b if the other is known
ğ–¦¹ To move forward: [yellow]next[/yellow] = [yellow]prev[/yellow] XOR [yellow]npx[/yellow]
ğ–¦¹ To move backward: [yellow]prev[/yellow] = [yellow]next[/yellow] XOR [yellow]npx[/yellow]

68. Traversal example
ğ–¦¹ Suppose list is A <-> B <-> C
ğ–¦¹ Node B stores: [yellow]B.npx[/yellow] = A XOR C
ğ–¦¹ If you are at B and came from A: [yellow]next[/yellow] = B.npx XOR prev â†’ (A XOR C) XOR A = C
- This lets traversal use only one pointer per node

69. Pros & Cons
ğ–¦¹ Pros
â€¢ Saves memory: one pointer instead of two per node
â€¢ Clever low-level technique
ğ–¦¹ Cons
â€¢ Hard to debug
â€¢ Needs XOR operation each traversal
â€¢ Not suitable for garbage-collected languages
â€¢ Insertions and deletions are tricky

70. Key Idea
ğ–¦¹ Each node keeps combined XOR of prev and next
ğ–¦¹ Always need one known node (prev or next) to find the other
ğ–¦¹ Traversal is sequential but memory usage is reduced
ğ–¦¹ Formula:
â€¢ npx = address(prev) XOR address(next)
â€¢ To go forward: next = prev XOR npx
â€¢ To go backward: prev = next XOR npx

71. C++ Implementation
[pink]#include[/pink] <[green]iostream[/green]>
[pink]using[/pink] [pink]namespace[/pink] [green]std[/green];

[pink]class[/pink] [yellow]XORNode[/yellow] {
[pink]public[/pink]:
    [blue]int[/blue] [yellow]data[/yellow];
    [yellow]XORNode[/yellow]* [yellow]npx[/yellow]; // XOR of prev and next
    [pink]XORNode[/pink]([blue]int[/blue] [yellow]val[/yellow]) {
        [yellow]data[/yellow] = [yellow]val[/yellow];
        [yellow]npx[/yellow] = [green]nullptr[/green];
    }
};

// Helper XOR function
[pink]XORNode*[/pink] [yellow]XOR[/yellow]([yellow]XORNode[/yellow]* [yellow]a[/yellow], [yellow]XORNode[/yellow]* [yellow]b[/yellow]) {
    return ([pink]reinterpret_cast[/pink]<[yellow]XORNode[/yellow]*>(
        ([blue]uintptr_t[/blue]) [yellow]a[/yellow] ^ ([blue]uintptr_t[/blue]) [yellow]b[/yellow]));
}

[pink]class[/pink] [yellow]XORLinkedList[/yellow] {
[pink]private[/pink]:
    [yellow]XORNode[/yellow]* [yellow]head[/yellow];
    [yellow]XORNode[/yellow]* [yellow]tail[/yellow];
[pink]public[/pink]:
    [pink]XORLinkedList[/pink]() {
        [yellow]head[/yellow] = [green]nullptr[/green];
        [yellow]tail[/yellow] = [green]nullptr[/green];
    }

    [pink]void[/pink] [yellow]insert[/yellow]([blue]int[/blue] [yellow]val[/yellow]) {
        [yellow]XORNode[/yellow]* [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]XORNode[/yellow]([yellow]val[/yellow]);
        [pink]if[/pink] ([yellow]head[/yellow] == [green]nullptr[/green]) {
            [yellow]head[/yellow] = [yellow]tail[/yellow] = [yellow]newNode[/yellow];
        } [pink]else[/pink] {
            [yellow]newNode[/yellow]->[yellow]npx[/yellow] = [yellow]XOR[/yellow]([green]nullptr[/green], [yellow]tail[/yellow]);
            [yellow]tail[/yellow]->[yellow]npx[/yellow] = [yellow]XOR[/yellow]([yellow]XOR[/yellow]([yellow]tail[/yellow]->[yellow]npx[/yellow], [green]nullptr[/green]), [yellow]newNode[/yellow]);
            [yellow]tail[/yellow] = [yellow]newNode[/yellow];
        }
    }

    [pink]void[/pink] [yellow]traverseForward[/yellow]() {
        [yellow]XORNode[/yellow]* [yellow]curr[/yellow] = [yellow]head[/yellow];
        [yellow]XORNode[/yellow]* [yellow]prev[/yellow] = [green]nullptr[/green];
        [yellow]XORNode[/yellow]* [yellow]next[/yellow];

        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [green]cout[/green] << [yellow]curr[/yellow]->[yellow]data[/yellow] << " ";
            [yellow]next[/yellow] = [yellow]XOR[/yellow]([yellow]prev[/yellow], [yellow]curr[/yellow]->[yellow]npx[/yellow]);
            [yellow]prev[/yellow] = [yellow]curr[/yellow];
            [yellow]curr[/yellow] = [yellow]next[/yellow];
        }
        [green]cout[/green] << [green]endl[/green];
    }
};

[pink]int[/pink] [pink]main[/pink]() {
    [yellow]XORLinkedList[/yellow] [yellow]list[/yellow];
     ;
     ;
     ;
     ;

    [green]cout[/green] << "Forward traversal: ";
    [yellow]list[/yellow].[yellow]traverseForward[/yellow]();

    [pink]return[/pink] 0;
}
--END--
--BEGIN--24/11/2025--STACKS--
1. A Stack
IMG_URL stack.gif
ğ–¦¹ A stack is a list where you add or remove only at the top.
ğ–¦¹ push means you add at the top.
ğ–¦¹ pop means you remove from the top.
ğ–¦¹ topEl means you look at the top without removing.
ğ–¦¹ Last added is first removed, so it is LIFO.

2. Stack operations
ğ–¦¹ clear() means make stack empty.
ğ–¦¹ isEmpty() means check if stack has no items.
ğ–¦¹ push(x) means put x on top.
ğ–¦¹ pop() means remove the top item.
ğ–¦¹ topEl() means see the top item without removing.

3. Example of push and pop
ğ–¦¹ Start empty.
ğ–¦¹ push 10 â†’ stack becomes [10].
ğ–¦¹ push 5 â†’ stack becomes [10, 5].
ğ–¦¹ pop removes 5 â†’ stack becomes [10].
ğ–¦¹ push 15 â†’ stack becomes [10, 15].
ğ–¦¹ push 7 â†’ stack becomes [10, 15, 7].
ğ–¦¹ pop removes 7 â†’ stack becomes [10, 15].

4. Checking brackets using stack
ğ–¦¹ Used to match brackets like (), [], {} and block comments.
ğ–¦¹ For code like:
[yellow]while[/yellow] ([yellow]m[/yellow] < ([yellow]n[/yellow][8] + [yellow]o[/yellow])) { [yellow]p[/yellow] = 7; }
â€¢ When you see opening bracket, push it.
â€¢ When you see closing bracket, pop and check if types match.
- If mismatch, it is an error.
- If stack ends empty, everything matches.
ğ–¦¹ Helps because inner brackets must match before outer ones.

5. Adding very large numbers
ğ–¦¹ When numbers are too big for normal number types, treat them as strings.
ğ–¦¹ Push digits of each number into two stacks.
ğ–¦¹ Pop from each stack to add from right to left.

6. JVM use of stacks
ğ–¦¹ JVM pushes a frame when a method starts.
ğ–¦¹ JVM pops the frame when method ends.
ğ–¦¹ Inside each frame, JVM uses an operand stack for calculations.
ğ–¦¹ For example:
[pink]imul[/pink] pops two numbers, multiplies them, and pushes the result.

7. Ways to implement a stack
ğ–¦¹ Using [yellow]ArrayList[/yellow].
â€¢ Fast, needs resizing when full.
â€¢ push/pop usually O(1).
ğ–¦¹ Using [yellow]LinkedList[/yellow].
â€¢ No resizing needed.
â€¢ push/pop always O(1).
â€¢ Very close to real stack behavior.

8. Stack implementation using array or linked list
ğ–¦¹ Both array stack and linked-list stack give O(1) time for push, pop, top, and isEmpty.
ğ–¦¹ Array stack uses a fixed-size array decided early.
â€¢ Very fast and uses less memory.
â€¢ Items are in continuous memory, so it is cache-friendly.
â€¢ Can overflow if array becomes full.
â€¢ Can waste memory if chosen size is too big.
ğ–¦¹ Linked-list stack grows and shrinks as needed.
â€¢ Does not overflow unless whole system runs out of memory.
â€¢ A bit slower because each push needs dynamic memory work.
â€¢ Each node stores an extra pointer, so it uses more memory and is less cache-friendly.
ğ–¦¹ Summary: array stack is faster but fixed in size; linked-list stack is flexible but slower and uses more memory.

9. Implementing stack
ğ–¦¹ A stack can be made using array.
ğ–¦¹ A stack can also be made using linked list.
ğ–¦¹ Both methods are simple and complete.

10. Stack using array (C++ code)
ğ–¦¹ Uses a fixed-size array.
ğ–¦¹ top moves up and down when pushing or popping.
ğ–¦¹ Code:
/* array stack */
[pink]#include[/pink] <[yellow]iostream[/yellow]>
[pink]using[/pink] [pink]namespace[/pink] [yellow]std[/yellow];

[pink]class[/pink] [yellow]Stack[/yellow] {
[pink]private[/pink]:
    [blue]int[/blue] [yellow]arr[/yellow][100];
    [blue]int[/blue] [yellow]top[/yellow];

[pink]public[/pink]:
    [yellow]Stack[/yellow]() { [yellow]top[/yellow] = -1; }

    [blue]bool[/blue] [yellow]isEmpty[/yellow]() {
        [pink]return[/pink] [yellow]top[/yellow] == -1;
    }

    [blue]bool[/blue] [yellow]isFull[/yellow]() {
        [pink]return[/pink] [yellow]top[/yellow] == 99;
    }

    [pink]void[/pink] [yellow]push[/yellow]([blue]int[/blue] x) {
        [pink]if[/pink] ([yellow]isFull[/yellow]()) {
            [green]cout[/green] << "Stack Overflow\n";
            [pink]return[/pink];
        }
        [yellow]arr[/yellow][++[yellow]top[/yellow]] = x;
    }

    [pink]void[/pink] [yellow]pop[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Stack Underflow\n";
            [pink]return[/pink];
        }
        [yellow]top[/yellow]--;
    }

    [blue]int[/blue] [yellow]topElement[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Stack is Empty\n";
            [pink]return[/pink] -1;
        }
        [pink]return[/pink] [yellow]arr[/yellow][[yellow]top[/yellow]];
    }
};

[pink]int[/pink] [pink]main[/pink]() {
    [yellow]Stack[/yellow] s;
    s.push(10);
    s.push(20);
    s.push(30);
    [green]cout[/green] << s.[yellow]topElement[/yellow]() << [green]endl[/green];
    s.[yellow]pop[/yellow]();
    [green]cout[/green] << s.[yellow]topElement[/yellow]() << [green]endl[/green];
}

11. Stack using linked list (C++ code)
ğ–¦¹ Uses nodes that link together.
ğ–¦¹ No fixed size; grows and shrinks freely.
ğ–¦¹ Code:
/* linked list stack */
[pink]#include[/pink] <[yellow]iostream[/yellow]>
[pink]using[/pink] [pink]namespace[/pink] [yellow]std[/yellow];

[pink]class[/pink] [yellow]Node[/yellow] {
[pink]public[/pink]:
    [blue]int[/blue] [yellow]data[/yellow];
    [yellow]Node[/yellow]* [yellow]next[/yellow];
};

[pink]class[/pink] [yellow]Stack[/yellow] {
[pink]private[/pink]:
    [yellow]Node[/yellow]* [yellow]top[/yellow];

[pink]public[/pink]:
    [yellow]Stack[/yellow]() { [yellow]top[/yellow] = [green]nullptr[/green]; }

    [blue]bool[/blue] [yellow]isEmpty[/yellow]() {
        [pink]return[/pink] [yellow]top[/yellow] == [green]nullptr[/green];
    }

    [pink]void[/pink] [yellow]push[/yellow]([blue]int[/blue] x) {
        [yellow]Node[/yellow]* [yellow]temp[/yellow] = [pink]new[/pink] [yellow]Node[/yellow]();
        [yellow]temp[/yellow]->[yellow]data[/yellow] = x;
        [yellow]temp[/yellow]->[yellow]next[/yellow] = [yellow]top[/yellow];
        [yellow]top[/yellow] = [yellow]temp[/yellow];
    }

    [pink]void[/pink] [yellow]pop[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Stack Underflow\n";
            [pink]return[/pink];
        }
        [yellow]Node[/yellow]* [yellow]temp[/yellow] = [yellow]top[/yellow];
        [yellow]top[/yellow] = [yellow]top[/yellow]->[yellow]next[/yellow];
        [pink]delete[/pink] [yellow]temp[/yellow];
    }

    [blue]int[/blue] [yellow]topElement[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Stack is Empty\n";
            [pink]return[/pink] -1;
        }
        [pink]return[/pink] [yellow]top[/yellow]->[yellow]data[/yellow];
    }
};

[pink]int[/pink] [pink]main[/pink]() {
    [yellow]Stack[/yellow] s;
    s.push(10);
    s.push(20);
    s.push(30);
    [green]cout[/green] << s.[yellow]topElement[/yellow]() << [green]endl[/green];
    s.[yellow]pop[/yellow]();
    [green]cout[/green] << s.[yellow]topElement[/yellow]() << [green]endl[/green];
}
--END--
--BEGIN--24/11/2025--QUEUES--
1. A Queue
IMG_URL queue.gif
ğ–¦¹ A queue stores items in the order they arrive.
ğ–¦¹ It follows FIFO (first in, first out).
â€¢ First added item is removed first.
- Explanation: works like people standing in a line.

2. Queue operations
ğ–¦¹ Enqueue(x): add an item at the back.
ğ–¦¹ Dequeue(): remove an item from the front.
ğ–¦¹ Front() / Peek(): show front item without removing it.
ğ–¦¹ isEmpty(): check if queue has no items.
ğ–¦¹ isFull(): only for array version; checks if space is over.

3. How a queue is built
ğ–¦¹ We keep two positions: [yellow]front[/yellow] and [yellow]rear[/yellow].
â€¢ [yellow]front[/yellow] â†’ first item
â€¢ [yellow]rear[/yellow] â†’ last item
ğ–¦¹ Two ways to build it:
â€¢ Array queue: use an array and move [yellow]rear[/yellow] for enqueue, move [yellow]front[/yellow] for dequeue.
- Problem: if many operations happen, array may show overflow even when free space exists at the start.
â€¢ Linked-list queue: each node has [yellow]data[/yellow] and [yellow]next[/yellow].
- [yellow]front[/yellow] is head, [yellow]rear[/yellow] is tail.
- Enqueue at tail, dequeue at head.

4. Queue behaviour
ğ–¦¹ Works like real-life waiting lines.
â€¢ Examples: ticket counter, printer jobs, server requests, CPU task list.
- Explanation: items leave in same order they came.

5. Time complexity of queue operations
ğ–¦¹ Array queue: all operations O(1).
ğ–¦¹ Linked-list queue: all operations O(1).
â€¢ isFull() only applies to array queue.

6. Memory use
ğ–¦¹ Array queue: fixed size; no extra memory per item; may waste space.
ğ–¦¹ Linked-list queue: grows and shrinks; uses extra pointer memory; no wasted space.

7. Where we use queues
ğ–¦¹ CPU scheduling.
ğ–¦¹ Printer jobs.
ğ–¦¹ Web server request management.
ğ–¦¹ BFS in graphs/trees.
ğ–¦¹ Real-time buffering.
- Purpose: keep items in same order while giving fast insert and remove.

8. Why queue is important
ğ–¦¹ It models natural waiting.
ğ–¦¹ Many systems need FIFO order.
â€¢ Gives fast insert and delete at ends.
â€¢ Simple and powerful for many tasks.

9. Queue using array â€” C++ program
ğ–¦¹ Simple linear array queue with fixed size.
[pink]#include[/pink] <iostream>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]class[/pink] [yellow]Queue[/yellow] {
[pink]private[/pink]:
    [pink]int[/pink] [yellow]arr[/yellow][100];
    [pink]int[/pink] [yellow]front[/yellow], [yellow]rear[/yellow];

[pink]public[/pink]:
    [yellow]Queue[/yellow]() {
        [yellow]front[/yellow] = 0;
        [yellow]rear[/yellow] = -1;
    }

    [pink]bool[/pink] [yellow]isEmpty[/yellow]() {
        [pink]return[/pink] [yellow]front[/yellow] > [yellow]rear[/yellow];
    }

    [pink]bool[/pink] [yellow]isFull[/yellow]() {
        [pink]return[/pink] [yellow]rear[/yellow] == 99;
    }

    [pink]void[/pink] [yellow]enqueue[/yellow]([pink]int[/pink] [yellow]x[/yellow]) {
        [pink]if[/pink] ([yellow]isFull[/yellow]()) {
            [green]cout[/green] << "Queue Overflow\n";
            [pink]return[/pink];
        }
        [yellow]arr[/yellow][++[yellow]rear[/yellow]] = [yellow]x[/yellow];
    }

    [pink]void[/pink] [yellow]dequeue[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Queue Underflow\n";
            [pink]return[/pink];
        }
        [yellow]front[/yellow]++;
    }

    [pink]int[/pink] [yellow]frontElement[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Queue is Empty\n";
            [pink]return[/pink] -1;
        }
        [pink]return[/pink] [yellow]arr[/yellow][[yellow]front[/yellow]];
    }
};

[pink]int[/pink] [pink]main[/pink]() {
    [yellow]Queue[/yellow] q;
    q.enqueue(10);
    q.enqueue(20);
    q.enqueue(30);
    [green]cout[/green] << q.[yellow]frontElement[/yellow]() << [green]endl[/green];
    q.[yellow]dequeue[/yellow]();
    [green]cout[/green] << q.[yellow]frontElement[/yellow]() << [green]endl[/green];
}

10. Queue using linked list: C++ program
ğ–¦¹ Uses nodes; grows until memory ends.
[pink]#include[/pink] <iostream>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]class[/pink] [yellow]Node[/yellow] {
[pink]public[/pink]:
    [pink]int[/pink] [yellow]data[/yellow];
    [yellow]Node[/yellow]* [yellow]next[/yellow];
};

[pink]class[/pink] [yellow]Queue[/yellow] {
[pink]private[/pink]:
    [yellow]Node[/yellow]* [yellow]front[/yellow];
    [yellow]Node[/yellow]* [yellow]rear[/yellow];

[pink]public[/pink]:
    [yellow]Queue[/yellow]() {
        [yellow]front[/yellow] = [yellow]rear[/yellow] = [green]nullptr[/green];
    }

    [pink]bool[/pink] [yellow]isEmpty[/yellow]() {
        [pink]return[/pink] [yellow]front[/yellow] == [green]nullptr[/green];
    }

    [pink]void[/pink] [yellow]enqueue[/yellow]([pink]int[/pink] [yellow]x[/yellow]) {
        [yellow]Node[/yellow]* [yellow]temp[/yellow] = [pink]new[/pink] [yellow]Node[/yellow]();
        [yellow]temp[/yellow]->[yellow]data[/yellow] = [yellow]x[/yellow];
        [yellow]temp[/yellow]->[yellow]next[/yellow] = [green]nullptr[/green];

        [pink]if[/pink] ([yellow]rear[/yellow] == [green]nullptr[/green]) {
            [yellow]front[/yellow] = [yellow]rear[/yellow] = [yellow]temp[/yellow];
        } [pink]else[/pink] {
            [yellow]rear[/yellow]->[yellow]next[/yellow] = [yellow]temp[/yellow];
            [yellow]rear[/yellow] = [yellow]temp[/yellow];
        }
    }

    [pink]void[/pink] [yellow]dequeue[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Queue Underflow\n";
            [pink]return[/pink];
        }
        [yellow]Node[/yellow]* [yellow]temp[/yellow] = [yellow]front[/yellow];
        [yellow]front[/yellow] = [yellow]front[/yellow]->[yellow]next[/yellow];

        [pink]if[/pink] ([yellow]front[/yellow] == [green]nullptr[/green]) {
            [yellow]rear[/yellow] = [green]nullptr[/green];
        }

        [pink]delete[/pink] [yellow]temp[/yellow];
    }

    [pink]int[/pink] [yellow]frontElement[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) {
            [green]cout[/green] << "Queue is Empty\n";
            [pink]return[/pink] -1;
        }
        [pink]return[/pink] [yellow]front[/yellow]->[yellow]data[/yellow];
    }
};

[pink]int[/pink] [pink]main[/pink]() {
    [yellow]Queue[/yellow] q;
    q.enqueue(5);
    q.enqueue(15);
    q.enqueue(25);
    [green]cout[/green] << q.[yellow]frontElement[/yellow]() << [green]endl[/green];
    q.[yellow]dequeue[/yellow]();
    [green]cout[/green] << q.[yellow]frontElement[/yellow]() << [green]endl[/green];
}

11. Queue vs. Stack
ğ–¦¹ Order:
â€¢ Stack â†’ LIFO (last in, first out)
â€¢ Queue â†’ FIFO (first in, first out)
ğ–¦¹ Operations:
â€¢ Stack â†’ push, pop, top
â€¢ Queue â†’ enqueue, dequeue, front
ğ–¦¹ Uses:
â€¢ Stack â†’ function calls, undo, expression work, DFS
â€¢ Queue â†’ CPU tasks, printers, BFS, servers
ğ–¦¹ Speed:
â€¢ Both give O(1) operations.
ğ–¦¹ Memory:
â€¢ Array stack â†’ continuous memory
â€¢ Array queue â†’ may waste front space if many dequeues
â€¢ Linked-list forms â†’ dynamic with pointer cost

12. Priority queue basics
IMG_URL queue-types.jpg
ğ–¦¹ A priority queue always removes the element with the best priority.
ğ–¦¹ Best priority may mean smallest number or largest number based on rule.
ğ–¦¹ How we store items changes the speed of insert and delete.

13. Unsorted List
ğ–¦¹ Keep items in a normal list without sorting.
ğ–¦¹ Insert is very fast because we just place the new item anywhere.
ğ–¦¹ Remove is slow because we must search the whole list to find the best priority.
â€¢ Insert time: O(1)
â€¢ Delete time: O(n)
- Explanation: The best priority can be anywhere, so we need a full scan.
ğ–¦¹ Useful when inserts happen many times and deletes happen few times.
ğ–¦¹ Related code:

[pink]#include[/pink] <iostream>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]struct[/pink] [yellow]Node[/yellow] {
    [pink]int[/pink] [yellow]value[/yellow];
    [pink]int[/pink] [yellow]priority[/yellow];
    [blue]Node*[/blue] [yellow]next[/yellow];
    [pink]Node[/pink]([pink]int[/pink] v, [pink]int[/pink] p) : [yellow]value[/yellow](v), [yellow]priority[/yellow](p), [yellow]next[/yellow](nullptr) {}
};

[pink]class[/pink] [yellow]UnsortedPriorityQueue[/yellow] {
[pink]private[/pink]:
    [blue]Node*[/blue] [yellow]head[/yellow];

[pink]public[/pink]:
    [pink]UnsortedPriorityQueue[/pink]() : [yellow]head[/yellow](nullptr) {}

    // Insert at head
    [pink]void[/pink] [yellow]enqueue[/yellow]([pink]int[/pink] value, [pink]int[/pink] priority) {
        [blue]Node*[/blue] [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]Node[/yellow](value, priority);
        [yellow]newNode[/yellow]->[yellow]next[/yellow] = [yellow]head[/yellow];
        [yellow]head[/yellow] = [yellow]newNode[/yellow];
    }

    // Remove highest priority
    [pink]int[/pink] [yellow]dequeue[/yellow]() {
        [pink]if[/pink] (![yellow]head[/yellow]) {
            [green]cout[/green] << "Queue empty\n";
            [pink]return[/pink] -1;
        }

        [blue]Node*[/blue] [yellow]best[/yellow] = [yellow]head[/yellow];
        [blue]Node*[/blue] [yellow]bestPrev[/yellow] = nullptr;

        [blue]Node*[/blue] [yellow]curr[/yellow] = [yellow]head[/yellow]->[yellow]next[/yellow];
        [blue]Node*[/blue] [yellow]prev[/yellow] = [yellow]head[/yellow];

        [pink]while[/pink] ([yellow]curr[/yellow]) {
            [pink]if[/pink] ([yellow]curr[/yellow]->[yellow]priority[/yellow] < [yellow]best[/yellow]->[yellow]priority[/yellow]) {
                [yellow]best[/yellow] = [yellow]curr[/yellow];
                [yellow]bestPrev[/yellow] = [yellow]prev[/yellow];
            }
            [yellow]prev[/yellow] = [yellow]curr[/yellow];
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]next[/yellow];
        }

        [pink]if[/pink] ([yellow]bestPrev[/yellow]) [yellow]bestPrev[/yellow]->[yellow]next[/yellow] = [yellow]best[/yellow]->[yellow]next[/yellow];
        [pink]else[/pink] [yellow]head[/yellow] = [yellow]best[/yellow]->[yellow]next[/yellow];

        [pink]int[/pink] [yellow]val[/yellow] = [yellow]best[/yellow]->[yellow]value[/yellow];
        [pink]delete[/pink] [yellow]best[/yellow];
        [pink]return[/pink] [yellow]val[/yellow];
    }

    [pink]bool[/pink] [yellow]isEmpty[/yellow]() {
        [pink]return[/pink] [yellow]head[/yellow] == nullptr;
    }
};

14. Sorted List
ğ–¦¹ Keep items always sorted by priority.
ğ–¦¹ Insert is slow because we must find the correct place.
ğ–¦¹ Remove is fast because the best priority is always stored at one known spot.
â€¢ Insert time: O(n)
â€¢ Delete time: O(1)
- Explanation: The head keeps the best priority element.
ğ–¦¹ Useful when deletes happen many times and inserts happen few times.
ğ–¦¹ Related code:

[pink]#include[/pink] <iostream>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]struct[/pink] [yellow]Node2[/yellow] {
    [pink]int[/pink] [yellow]value[/yellow];
    [pink]int[/pink] [yellow]priority[/yellow];
    [blue]Node2*[/blue] [yellow]next[/yellow];
    [pink]Node2[/pink]([pink]int[/pink] v, [pink]int[/pink] p) : [yellow]value[/yellow](v), [yellow]priority[/yellow](p), [yellow]next[/yellow](nullptr) {}
};

[pink]class[/pink] [yellow]SortedPriorityQueue[/yellow] {
[pink]private[/pink]:
    [blue]Node2*[/blue] [yellow]head[/yellow];

[pink]public[/pink]:
    [pink]SortedPriorityQueue[/pink]() : [yellow]head[/yellow](nullptr) {}

    // Insert in sorted order
    [pink]void[/pink] [yellow]enqueue[/yellow]([pink]int[/pink] value, [pink]int[/pink] priority) {
        [blue]Node2*[/blue] [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]Node2[/yellow](value, priority);

        [pink]if[/pink] (![yellow]head[/yellow] || priority < [yellow]head[/yellow]->[yellow]priority[/yellow]) {
            [yellow]newNode[/yellow]->[yellow]next[/yellow] = [yellow]head[/yellow];
            [yellow]head[/yellow] = [yellow]newNode[/yellow];
            [pink]return[/pink];
        }

        [blue]Node2*[/blue] [yellow]curr[/yellow] = [yellow]head[/yellow];
        [pink]while[/pink] ([yellow]curr[/yellow]->[yellow]next[/yellow] && [yellow]curr[/yellow]->[yellow]next[/yellow]->[yellow]priority[/yellow] <= priority) {
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]next[/yellow];
        }

        [yellow]newNode[/yellow]->[yellow]next[/yellow] = [yellow]curr[/yellow]->[yellow]next[/yellow];
        [yellow]curr[/yellow]->[yellow]next[/yellow] = [yellow]newNode[/yellow];
    }

    // Remove highest priority
    [pink]int[/pink] [yellow]dequeue[/yellow]() {
        [pink]if[/pink] (![yellow]head[/yellow]) {
            [green]cout[/green] << "Queue empty\n";
            [pink]return[/pink] -1;
        }

        [blue]Node2*[/blue] [yellow]temp[/yellow] = [yellow]head[/yellow];
        [yellow]head[/yellow] = [yellow]head[/yellow]->[yellow]next[/yellow];

        [pink]int[/pink] [yellow]val[/yellow] = [yellow]temp[/yellow]->[yellow]value[/yellow];
        [pink]delete[/pink] [yellow]temp[/yellow];
        [pink]return[/pink] [yellow]val[/yellow];
    }

    [pink]bool[/pink] [yellow]isEmpty[/yellow]() {
        [pink]return[/pink] [yellow]head[/yellow] == nullptr;
    }
};

15. Comparison
Structure   Insert   Delete_best   Notes
Unsorted    O(1)     O(n)          Fast insert, slow delete
Sorted      O(n)     O(1)          Slow insert, fast delete

16. Using Heap
ğ–¦¹ It must add new elements fast
ğ–¦¹ It must give the most important element fast
ğ–¦¹ It must remove the most important element fast
â€¢ push â†’ add an element
â€¢ top â†’ get highest-priority element
â€¢ pop â†’ remove highest-priority element
- Binary heap is used because:
  push = O(log n)
  pop = O(log n)
  top = O(1)

17. How priority queue works inside
ğ–¦¹ It is built on top of a binary heap
ğ–¦¹ The heap is kept in an array in level order
â€¢ Example max-heap:
  Tree:
         100
       /     \
      50      40
     /  \    /  \
    45  10  20  30
  Array:
  [100, 50, 40, 45, 10, 20, 30]

18. What happens on push()
ğ–¦¹ When we do pq., it goes to the end of the array
ğ–¦¹ Then â€œbubble-upâ€ runs to fix the heap
â€¢ It swaps with parents until heap rule becomes correct
- Same as heap push

19. What happens on pop()
ğ–¦¹ pq.[yellow]pop[/yellow]() removes the root (highest priority)
ğ–¦¹ Last element moves to the root
ğ–¦¹ Then â€œheapify-down (Percolate Down/Sift Down)â€ runs
â€¢ It swaps with the larger child until heap rule becomes correct
- Same as heap pop

20. What top() does
ğ–¦¹ pq.[yellow]top[/yellow]() returns the root element
ğ–¦¹ It only reads heap[0]
â€¢ So it is O(1)

21. How C++ implements priority_queue
ğ–¦¹ It uses a [green]vector[/green] to store the heap
ğ–¦¹ It builds the heap using [green]make_heap[/green]
â€¢ C++ uses:
  [green]push_heap[/green]() â†’ O(log n)
  [green]pop_heap[/green]() â†’ O(log n)
  [green]make_heap[/green]() â†’ O(n)

22. What is a deque
ğ–¦¹ A deque (double-ended queue) allows adding/removing elements from both front and back
ğ–¦¹ It is like a mix of a queue and a stack
â€¢ All operations work in O(1) time (amortized)

23. Why "double-ended"
ğ–¦¹ Normal queue only allows:
â€¢ push at back
â€¢ pop from front
ğ–¦¹ Deque allows:
â€¢ push_front(x)
â€¢ push_back(x)
â€¢ pop_front()
â€¢ pop_back()
- Both ends are open for insertion and deletion

24. Visual intuition
ğ–¦¹ Think of a line of people
â€¢ People can join from front or back
â€¢ People can leave from front or back
- Front <--- [ A B C D ] ---> Back

25. Operations supported
ğ–¦¹ push_front(x) â†’ add x at front
ğ–¦¹ push_back(x) â†’ add x at back
ğ–¦¹ pop_front() â†’ remove front element
ğ–¦¹ pop_back() â†’ remove back element
ğ–¦¹ front() â†’ read front element
ğ–¦¹ back() â†’ read back element
ğ–¦¹ empty() â†’ check if deque is empty
- All O(1) time

26. How a deque is implemented
ğ–¦¹ Doubly linked list:
â€¢ Each node has prev + next
â€¢ Easy to add/remove at both ends
- Cache performance is poor
ğ–¦¹ Circular array / circular buffer (used in C++):
â€¢ Fixed-size array blocks
â€¢ Head and tail move circularly
â€¢ Very fast and memory-efficient

27. Circular Array (Array-Based) Implementation
ğ–¦¹ A deque can be implemented using a fixed-size circular array
ğ–¦¹ Maintains front and rear indices and moves them circularly using modulo
â€¢ push_front(x) â†’ move front backward circularly and insert x
â€¢ push_back(x) â†’ move rear forward circularly and insert x
â€¢ pop_front() â†’ move front forward circularly
â€¢ pop_back() â†’ move rear backward circularly
â€¢ getFront() â†’ return arr[front]
â€¢ getBack() â†’ return arr[rear]
- All operations O(1) amortized

#include <iostream>
using namespace std;

[pink]class[/pink] [yellow]Deque[/yellow] {
private:
    [pink]int*[/pink] [yellow]arr[/yellow];
    [pink]int[/pink] [yellow]front[/yellow], [yellow]rear[/yellow], [yellow]size[/yellow], [yellow]capacity[/yellow];

public:
    [pink]Deque[/pink]([pink]int[/pink] [yellow]cap[/yellow]) {
        [yellow]capacity[/yellow] = [yellow]cap[/yellow];
        [yellow]arr[/yellow] = [pink]new[/pink] [pink]int[/pink][[yellow]cap[/yellow]];
        [yellow]front[/yellow] = [yellow]rear[/yellow] = -1;
        [yellow]size[/yellow] = 0;
    }

    [pink]bool[/pink] [yellow]isEmpty[/yellow]() { return [yellow]size[/yellow] == 0; }
    [pink]bool[/pink] [yellow]isFull[/yellow]() { return [yellow]size[/yellow] == [yellow]capacity[/yellow]; }

    [pink]void[/pink] [yellow]push_front[/yellow]([pink]int[/pink] [yellow]x[/yellow]) {
        [pink]if[/pink] ([yellow]isFull[/yellow]()) { cout << "Deque full!\n"; [pink]return[/pink]; }
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) [yellow]front[/yellow] = [yellow]rear[/yellow] = 0;
        [pink]else[/pink] [yellow]front[/yellow] = ([yellow]front[/yellow] - 1 + [yellow]capacity[/yellow]) % [yellow]capacity[/yellow];
        [yellow]arr[/yellow][[yellow]front[/yellow]] = [yellow]x[/yellow];
        [yellow]size[/yellow]++;
    }

    [pink]void[/pink] [yellow]push_back[/yellow]([pink]int[/pink] [yellow]x[/yellow]) {
        [pink]if[/pink] ([yellow]isFull[/yellow]()) { cout << "Deque full!\n"; [pink]return[/pink]; }
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) [yellow]front[/yellow] = [yellow]rear[/yellow] = 0;
        [pink]else[/pink] [yellow]rear[/yellow] = ([yellow]rear[/yellow] + 1) % [yellow]capacity[/yellow];
        [yellow]arr[/yellow][[yellow]rear[/yellow]] = [yellow]x[/yellow];
        [yellow]size[/yellow]++;
    }

    [pink]void[/pink] [yellow]pop_front[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink]; }
        [pink]if[/pink] ([yellow]front[/yellow] == [yellow]rear[/yellow]) [yellow]front[/yellow] = [yellow]rear[/yellow] = -1;
        [pink]else[/pink] [yellow]front[/yellow] = ([yellow]front[/yellow] + 1) % [yellow]capacity[/yellow];
        [yellow]size[/yellow]--;
    }

    [pink]void[/pink] [yellow]pop_back[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink]; }
        [pink]if[/pink] ([yellow]front[/yellow] == [yellow]rear[/yellow]) [yellow]front[/yellow] = [yellow]rear[/yellow] = -1;
        [pink]else[/pink] [yellow]rear[/yellow] = ([yellow]rear[/yellow] - 1 + [yellow]capacity[/yellow]) % [yellow]capacity[/yellow];
        [yellow]size[/yellow]--;
    }

    [pink]int[/pink] [yellow]getFront[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink] -1; }
        [pink]return[/pink] [yellow]arr[/yellow][[yellow]front[/yellow]];
    }

    [pink]int[/pink] [yellow]getBack[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink] -1; }
        [pink]return[/pink] [yellow]arr[/yellow][[yellow]rear[/yellow]];
    }
};

[pink]int[/pink] [yellow]main[/yellow]() {
     ;

     ;
     ;
     ;

    cout << "Front: " << [yellow]dq[/yellow].[yellow]getFront[/yellow]() << "\n";  // 20
    cout << "Back: " << [yellow]dq[/yellow].[yellow]getBack[/yellow]() << "\n";    // 30

    [yellow]dq[/yellow].[yellow]pop_front[/yellow]();
    cout << "Front after pop_front: " << [yellow]dq[/yellow].[yellow]getFront[/yellow]() << "\n"; // 10

    [yellow]dq[/yellow].[yellow]pop_back[/yellow]();
    cout << "Back after pop_back: " << [yellow]dq[/yellow].[yellow]getBack[/yellow]() << "\n";    // 10

    [pink]return[/pink] 0;
}

28. Doubly Linked List Implementation
ğ–¦¹ A deque can be implemented using a doubly linked list
ğ–¦¹ Each node has prev and next pointers
â€¢ push_front(x) â†’ insert new node at front
â€¢ push_back(x) â†’ insert new node at back
â€¢ pop_front() â†’ remove node from front
â€¢ pop_back() â†’ remove node from back
â€¢ getFront() â†’ return front->data
â€¢ getBack() â†’ return rear->data
- All operations O(1)

#include <iostream>
using namespace std;

[pink]struct[/pink] [yellow]Node[/yellow] {
    [pink]int[/pink] [yellow]data[/yellow];
    [yellow]Node[/yellow]* [yellow]prev[/yellow];
    [yellow]Node[/yellow]* [yellow]next[/yellow];
    [yellow]Node[/yellow]([pink]int[/pink] [yellow]x[/yellow]) : [yellow]data[/yellow]([yellow]x[/yellow]), [yellow]prev[/yellow](nullptr), [yellow]next[/yellow](nullptr) {}
};

[pink]class[/pink] [yellow]Deque[/yellow] {
private:
    [yellow]Node[/yellow]* [yellow]front[/yellow];
    [yellow]Node[/yellow]* [yellow]rear[/yellow];

public:
    [pink]Deque[/pink]() {
        [yellow]front[/yellow] = [yellow]rear[/yellow] = nullptr;
    }

    [pink]bool[/pink] [yellow]isEmpty[/yellow]() { return [yellow]front[/yellow] == nullptr; }

    [pink]void[/pink] [yellow]push_front[/yellow]([pink]int[/pink] [yellow]x[/yellow]) {
        [yellow]Node[/yellow]* [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]Node[/yellow]([yellow]x[/yellow]);
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) [yellow]front[/yellow] = [yellow]rear[/yellow] = [yellow]newNode[/yellow];
        [pink]else[/pink] {
            [yellow]newNode[/yellow]->next = [yellow]front[/yellow];
            [yellow]front[/yellow]->prev = [yellow]newNode[/yellow];
            [yellow]front[/yellow] = [yellow]newNode[/yellow];
        }
    }

    [pink]void[/pink] [yellow]push_back[/yellow]([pink]int[/pink] [yellow]x[/yellow]) {
        [yellow]Node[/yellow]* [yellow]newNode[/yellow] = [pink]new[/pink] [yellow]Node[/yellow]([yellow]x[/yellow]);
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) [yellow]front[/yellow] = [yellow]rear[/yellow] = [yellow]newNode[/yellow];
        [pink]else[/pink] {
            [yellow]rear[/yellow]->next = [yellow]newNode[/yellow];
            [yellow]newNode[/yellow]->prev = [yellow]rear[/yellow];
            [yellow]rear[/yellow] = [yellow]newNode[/yellow];
        }
    }

    [pink]void[/pink] [yellow]pop_front[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink]; }
        [yellow]Node[/yellow]* [yellow]temp[/yellow] = [yellow]front[/yellow];
        [yellow]front[/yellow] = [yellow]front[/yellow]->next;
        [pink]if[/pink] ([yellow]front[/yellow]) [yellow]front[/yellow]->prev = nullptr;
        [pink]else[/pink] [yellow]rear[/yellow] = nullptr;
        [pink]delete[/pink] [yellow]temp[/yellow];
    }

    [pink]void[/pink] [yellow]pop_back[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink]; }
        [yellow]Node[/yellow]* [yellow]temp[/yellow] = [yellow]rear[/yellow];
        [yellow]rear[/yellow] = [yellow]rear[/yellow]->prev;
        [pink]if[/pink] ([yellow]rear[/yellow]) [yellow]rear[/yellow]->next = nullptr;
        [pink]else[/pink] [yellow]front[/yellow] = nullptr;
        [pink]delete[/pink] [yellow]temp[/yellow];
    }

    [pink]int[/pink] [yellow]getFront[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink] -1; }
        [pink]return[/pink] [yellow]front[/yellow]->data;
    }

    [pink]int[/pink] [yellow]getBack[/yellow]() {
        [pink]if[/pink] ([yellow]isEmpty[/yellow]()) { cout << "Deque empty!\n"; [pink]return[/pink] -1; }
        [pink]return[/pink] [yellow]rear[/yellow]->data;
    }
};

[pink]int[/pink] [yellow]main[/yellow]() {
    [yellow]Deque[/yellow] [yellow]dq[/yellow];

     ;
     ;
     ;

    cout << "Front: " << [yellow]dq[/yellow].[yellow]getFront[/yellow]() << "\n";  // 20
    cout << "Back: " << [yellow]dq[/yellow].[yellow]getBack[/yellow]() << "\n";    // 30

    [yellow]dq[/yellow].[yellow]pop_front[/yellow]();
    cout << "Front after pop_front: " << [yellow]dq[/yellow].[yellow]getFront[/yellow]() << "\n"; // 10

    [yellow]dq[/yellow].[yellow]pop_back[/yellow]();
    cout << "Back after pop_back: " << [yellow]dq[/yellow].[yellow]getBack[/yellow]() << "\n";    // 10

    [pink]return[/pink] 0;
}

--END--
--BEGIN--24/11/2025--HEAPS--
1. Heaps
IMG_URL heaps.png
ğ–¦¹ A heap is a tree where each parent is more important than its children
ğ–¦¹ More important means smaller (min-heap) or larger (max-heap)
ğ–¦¹ Two rules must always hold
â€¢ Shape rule: tree must be a complete binary tree (filled left to right)
â€¢ Order rule: parent must follow heap property (â‰¤ for min-heap, â‰¥ for max-heap)
- Explanation: if any rule breaks, the tree stops being a heap
ğ–¦¹ A heap only checks parent-child order, not brother-brother order
ğ–¦¹ Because of this, a heap is not a sorted tree

2. Max heap example
ğ–¦¹ Parent is always â‰¥ children
ğ–¦¹ Example tree
â€¢       100
        /   \
      50    90
     / \
    30 20

3. Min heap example
ğ–¦¹ Parent is always â‰¤ children
ğ–¦¹ Example tree
â€¢       5
      /   \
     7     9
    / \
   8  10
- Explanation: 5 â‰¤ 7, 5 â‰¤ 9, 7 â‰¤ 8, 7 â‰¤ 10

4. Heap as array form
ğ–¦¹ A min-heap stored in array form
â€¢ Index: 1 2 3 4 5 6 7
â€¢ Value: 2 5 6 8 9 10 11
ğ–¦¹ Same tree shape using array positions
ROOT: FLOOR[(i-1)/2]

5. Pop operation idea (Extract-min)
ğ–¦¹ Remove root (minimum element)
ğ–¦¹ Move last element to root
ğ–¦¹ Heapify down to fix heap property

6. First pop
        2
      /    \
     5      6
    / \    / \ 
   8  9  10   11
ğ–¦¹ Remove 2 and move 11 to root
ğ–¦¹ Heapify by swapping with smaller child until property holds
ğ–¦¹ Tree after moving 11:
        11
      /    \
     5      6
    / \    / 
   8  9  10
ğ–¦¹ After swaps:
        5
      /    \
     8      6
    / \    / 
   11 9  10
â€¢ Final array: 5 8 6 11 9 10

7. Second pop
ğ–¦¹ Remove 5 and move 10 to root
ğ–¦¹ Tree after moving 10:
        10
      /    \
     8      6
    / \    
   11 9  
ğ–¦¹ Swap with smaller child 6:
        6
      /    \
     8      10
    / \    
   11 9  
â€¢ Final array: 6 8 10 11 9

8. Third pop
ğ–¦¹ Remove 6 and move 9 to root
ğ–¦¹ Tree:
        9
      /   \
     8     10
    /  
   11     
ğ–¦¹ Swap with 8:
        8
      /   \
     9     10
    /      
   11     
â€¢ Final array: 8 9 10 11

9. Fourth pop
ğ–¦¹ Remove 8 and move 11 to root
ğ–¦¹ Tree:
        11
      /   \
     9     10
ğ–¦¹ Swap with 9:
        9
      /   \
    11     10
â€¢ Final array: 9 11 10

10. Fifth pop
ğ–¦¹ Remove 9 and move 10 to root
ğ–¦¹ Tree:
      10
     /
    11
ğ–¦¹ 10 already satisfies heap property
â€¢ Final array: 10 11

11. Sixth pop
ğ–¦¹ Remove 10 and move 11 to root
ğ–¦¹ Tree:
      11
ğ–¦¹ No children, heap is fine
â€¢ Final array: 11

12. Seventh pop
ğ–¦¹ Remove 11
ğ–¦¹ Heap becomes empty

13. Final pop order
ğ–¦¹ Values removed one by one in order
â€¢ 2, 5, 6, 8, 9, 10, 11
- Explanation: min-heap gives ascending order when popping

14. MinHeap
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/heaps/min_heap.cpp

15. MaxHeap code
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/heaps/max_heap.cpp
--END--

--BEGIN--24/11/2025--TREES--
1. Trees
ğ–¦¹ A tree organizes data in a hierarchy like a family tree or company structure
ğ–¦¹ It has nodes (data points) and edges/arcs (connections between nodes)
ğ–¦¹ The root is the top node and has no parent
ğ–¦¹ Leaves are nodes with no children
ğ–¦¹ A path is the sequence of edges from the root to a node
ğ–¦¹ The level of a node is its distance from the root (root = level 1)
ğ–¦¹ The height of a tree is the largest level in the tree
â€¢ Example:
- Root (level 1)
  â”œâ”€ Child 1 (level 2)
  â””â”€ Child 2 (level 2)

2. Why use trees instead of lists
ğ–¦¹ In a linked list, finding an element may require checking every node
ğ–¦¹ Trees can make searching faster if organized properly
â€¢ Especially ordered trees

3. Binary Trees
ğ–¦¹ A binary tree is a tree where each node has at most two children: left and right
â€¢ Example:
-       10
        /  \
       5    15
ğ–¦¹ Complete binary tree: all levels full except possibly last, nodes as far left as possible
ğ–¦¹ Number of nodes at level i is at most 2^i

4. Binary Search Trees (BSTs)
ğ–¦¹ A BST is a binary tree with an ordering rule:
â€¢ Left child < parent
â€¢ Right child > parent
ğ–¦¹ Ordering makes searching, inserting, deleting faster
â€¢ Example:
-        10
         /  \
        5    20
       / \   / \
      2   7 15 25
ğ–¦¹ Searching is efficient because at each step you choose left or right instead of checking all nodes

5. Tree Traversals
ğ–¦¹ There are three main recursive traversals and one level-order traversal
â€¢ Preorder: visits root first, then recursively goes left and right
â€¢ Inorder: goes all the way left, backtracks to root, then goes right
â€¢ Postorder: goes all the way left and right, then backtracks to visit root
â€¢ Level-order: visits nodes level by level; uses BFS, useful for shortest path
ğ–¦¹ Example tree:
          50
        /    \
      30      70
     /  \    /  \
   20   40  60   80
  /         \      \
10          65      90

ğ–¦¹ Traversals for the tree:
â€¢ PREORDER: 50 â†’ 30 â†’ 20 â†’ 10 â†’ 40 â†’ 70 â†’ 60 â†’ 65 â†’ 80 â†’ 90
â€¢ INORDER: 10 â†’ 20 â†’ 30 â†’ 40 â†’ 50 â†’ 60 â†’ 65 â†’ 70 â†’ 80 â†’ 90
â€¢ POSTORDER: 10 â†’ 20 â†’ 40 â†’ 30 â†’ 65 â†’ 60 â†’ 80 â†’ 90 â†’ 70 â†’ 50
â€¢ LEVELORDER: 50 â†’ 30 â†’ 70 â†’ 20 â†’ 40 â†’ 60 â†’ 80 â†’ 10 â†’ 65 â†’ 90

ITERATIVE INORDER AND POSTORDER ROUTINES:
[pink]void[/pink] [yellow]iterativeInorder[/yellow]([blue]BSTNode*[/blue] [yellow]root[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink];
    [green]stack[/green]<[blue]BSTNode*[/blue]> [yellow]s[/yellow];
    [blue]BSTNode*[/blue] [yellow]curr[/yellow] = [yellow]root[/yellow];

    [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green] || ![yellow]s[/yellow].[green]empty[/green]()) {
        // Go as left as possible
        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [yellow]s[/yellow].[green]push[/green]([yellow]curr[/yellow]);
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]left[/yellow];
        }
        // Pop and visit
        [yellow]curr[/yellow] = [yellow]s[/yellow].[green]top[/green]();
        [yellow]s[/yellow].[green]pop[/green]();
        [green]cout[/green] << [yellow]curr[/yellow]->[yellow]key[/yellow] << " ";
        // Go right
        [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]right[/yellow];
    }
}

[pink]void[/pink] [yellow]iterativePostorder[/yellow]([blue]BSTNode*[/blue] [yellow]root[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink];
    [green]stack[/green]<[blue]BSTNode*[/blue]> [yellow]s[/yellow];
    [blue]BSTNode*[/blue] [yellow]curr[/yellow] = [yellow]root[/yellow];
    [blue]BSTNode*[/blue] [yellow]lastVisited[/yellow] = [green]nullptr[/green];

    [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green] || ![yellow]s[/yellow].[green]empty[/green]()) {
        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [yellow]s[/yellow].[green]push[/green]([yellow]curr[/yellow]);
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]left[/yellow];
        }

        [blue]BSTNode*[/blue] [yellow]topNode[/yellow] = [yellow]s[/yellow].[green]top[/green]();

        [pink]if[/pink] ([yellow]topNode[/yellow]->[yellow]right[/yellow] != [green]nullptr[/green] && [yellow]lastVisited[/yellow] != [yellow]topNode[/yellow]->[yellow]right[/yellow]) {
            [yellow]curr[/yellow] = [yellow]topNode[/yellow]->[yellow]right[/yellow];
        } [pink]else[/pink] {
            [green]cout[/green] << [yellow]topNode[/yellow]->[yellow]key[/yellow] << " ";
            [yellow]lastVisited[/yellow] = [yellow]topNode[/yellow];
            [yellow]s[/yellow].[green]pop[/green]();
        }
    }
}
--END--
--BEGIN--24/11/2025--BINARY SEARCH TREE--
1. Binary Search Tree (BST)
ğ–¦¹ A BST is a special binary tree where each node has at most two children
ğ–¦¹ BST property:
â€¢ All keys in the left subtree of a node are less than the nodeâ€™s key
â€¢ All keys in the right subtree of a node are greater than the nodeâ€™s key
â€¢ This property holds recursively â€” left and right subtrees are also BSTs
ğ–¦¹ Usually, BSTs do not allow duplicate values or handle them in a specific way

ğ–¦¹ Why use a BST?
â€¢ Efficient search, insertion, and deletion: ordering property allows skipping large parts of the tree
â€¢ Sorted data: in-order traversal returns keys in sorted order
â€¢ Dynamic structure: nodes can be inserted or removed, tree grows or shrinks
â€¢ Used in symbol tables and associative arrays
          50
        /    \
      30      70
     /  \    /  \
   20   40  60   80
  /             /  \
10             75   90

ğ–¦¹ Operations on a BST
â€¢ Search:
- Start at root
- Compare target key with current node
- If equal â†’ found
- If less â†’ go left
- If greater â†’ go right
- Repeat until found or null
â€¢ Insertion:
- Find correct leaf position comparing keys
- Insert new node while preserving BST property
â€¢ Deletion:
- No child (leaf): remove node
- One child: replace node with its child
- Two children: replace node with minimum in right subtree (successor) or maximum in left subtree (predecessor), then delete that node
â€¢ Traversal:
- Can traverse in inorder, preorder, postorder
- Inorder is useful because it returns sorted keys

ğ–¦¹ Time & Space Complexity
â€¢ Search / Insert / Delete (average case): O(h), where h = height of BST
â€¢ Balanced BST: height h â‰ˆ O(log n), average complexity O(log n)
â€¢ Worst case (skewed BST): height h = n, operations O(n)
â€¢ Space for recursion: O(n) in worst case due to call stack

ğ–¦¹ Limitations / Disadvantages
â€¢ Unbalanced BSTs degrade performance (search, insert, delete â†’ O(n))
â€¢ Managing duplicates can be tricky
â€¢ Guaranteed performance may require self-balancing BSTs like AVL trees or Red-Black trees

2. BST Operations: Insert, Search, Delete
ğ–¦¹ Example BST:
          50
        /    \
      30      70
     /  \    /  \
   20   40  60   80
	         \      \
	          65      90

ğ–¦¹ Delete
â€¢ Three cases:
- Node is a leaf â†’ delete it
- Node has one child â†’ replace node with child
- Node has two children â†’ replace node with inorder successor (smallest in right subtree) or predecessor (largest in left subtree), then delete that node

--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/trees/bst.cpp
3. BST Complexity
ğ–¦¹ Search
â€¢ Can be done recursively or iteratively
â€¢ Logic: start at [yellow]root[/yellow], go left if key is smaller, right if key is larger
â€¢ Time Complexity
  - Best/Average (balanced BST): O(log n)
  - Worst (skewed tree): O(n)
ğ–¦¹ Insertion
â€¢ Find correct place according to BST property and insert new node
â€¢ Can be recursive or iterative
â€¢ Time Complexity
  - Best/Average (balanced BST): O(log n)
  - Worst (skewed tree): O(n)
ğ–¦¹ Deletion
â€¢ Handle 3 cases
  â€¢ Node is leaf â†’ delete directly
  â€¢ Node has one child â†’ replace node with its child
  â€¢ Node has two children â†’ replace with inorder successor or predecessor, then delete that node
â€¢ Time Complexity
  - Best/Average (balanced BST): O(log n)
  - Worst (skewed tree): O(n)
ğ–¦¹ Traversals
â€¢ Preorder ([pink]Root[/pink] â†’ [pink]Left[/pink] â†’ [pink]Right[/pink])
  - Visit all nodes recursively
  - Time Complexity: O(n)
â€¢ Inorder ([pink]Left[/pink] â†’ [pink]Root[/pink] â†’ [pink]Right[/pink])
  - Visit all nodes recursively
  - Time Complexity: O(n)
â€¢ Postorder ([pink]Left[/pink] â†’ [pink]Right[/pink] â†’ [pink]Root[/pink])
  - Visit all nodes recursively
  - Time Complexity: O(n)
â€¢ Level-order (Breadth-first using [green]queue[/green])
  - Visit all nodes level by level
  - Time Complexity: O(n)
ğ–¦¹ Space Complexity
â€¢ Preorder/Inorder/Postorder (recursive): O(h), h = tree height
â€¢ Level-order (using [green]queue[/green]): O(width), width = max nodes at any level
ğ–¦¹ TL;DR
â€¢ Search: Best/Average O(log n), Worst O(n)
â€¢ Insert: Best/Average O(log n), Worst O(n)
â€¢ Delete: Best/Average O(log n), Worst O(n)
â€¢ Preorder: O(n), O(n)
â€¢ Inorder: O(n), O(n)
â€¢ Postorder: O(n), O(n)
â€¢ Level-order: O(n), O(n)
--END--
--BEGIN--24/11/2025--BALANCING TREES--
1. Why Balance a Tree
ğ–¦¹ Trees make searching faster than linked lists
ğ–¦¹ Lopsided trees act like linked lists â†’ searching becomes slow
â€¢ Example: inserting elements in ascending order â†’ tree becomes long chain
ğ–¦¹ Balanced tree
â€¢ Keeps height difference between left and right subtrees â‰¤ 1
â€¢ Perfectly balanced tree: all levels fully filled except maybe last
â€¢ Searching is fast because tree height is minimal
â€¢ Formula: Max nodes in tree of height h â†’ 2^h - 1
â€¢ Example: 10,000 elements â†’ balanced tree height â‰ˆ 14 â†’ only 14 comparisons needed
â€¢ Linked list â†’ worst case 10,000 comparisons
ğ–¦¹ How to build a balanced tree
â€¢ Sort data first (if not already sorted)
â€¢ Pick middle element â†’ root
â€¢ Divide array into left half and right half
â€¢ Middle of left â†’ left child
â€¢ Middle of right â†’ right child
â€¢ Repeat recursively for all subarrays until all elements inserted
ğ–¦¹ Balancing BST: Code Example
[green]#include[/green] <iostream>
[green]using namespace[/green] std;
// Node of BST
[pink]struct[/pink] [yellow]BSTNode[/yellow] {
    [pink]int[/pink] [yellow]key[/yellow];
    [blue]BSTNode*[/blue] [yellow]left[/yellow];
    [blue]BSTNode*[/blue] [yellow]right[/yellow];
    [yellow]BSTNode[/yellow]([pink]int[/pink] [yellow]k[/yellow]) : [yellow]key[/yellow]([yellow]k[/yellow]), [yellow]left[/yellow]([green]nullptr[/green]), [yellow]right[/yellow]([green]nullptr[/green]) {}
};
// BST root
[blue]BSTNode*[/blue] [yellow]root[/yellow] = [green]nullptr[/green];
// Insert function for BST
[blue]BSTNode*[/blue] [yellow]insert[/yellow]([blue]BSTNode*[/blue] [yellow]node[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink]([yellow]node[/yellow] == [green]nullptr[/green]) {
        [pink]return[/pink] [pink]new[/pink] [yellow]BSTNode[/yellow]([yellow]key[/yellow]); // create new node
    }
    [pink]if[/pink]([yellow]key[/yellow] < [yellow]node[/yellow]->key) {
        [yellow]node[/yellow]->left = [yellow]insert[/yellow]([yellow]node[/yellow]->left, [yellow]key[/yellow]);
    } [pink]else if[/pink]([yellow]key[/yellow] > [yellow]node[/yellow]->key) {
        [yellow]node[/yellow]->right = [yellow]insert[/yellow]([yellow]node[/yellow]->right, [yellow]key[/yellow]);
    }
    [pink]return[/pink] [yellow]node[/yellow];
}
// Wrapper insert to use global root
[pink]void[/pink] [yellow]insert[/yellow]([pink]int[/pink] [yellow]key[/yellow]) {
    [yellow]root[/yellow] = [yellow]insert[/yellow]([yellow]root[/yellow], [yellow]key[/yellow]);
}
// Build balanced BST from sorted array
[pink]void[/pink] [yellow]balance[/yellow]([pink]int[/pink] [yellow]data[/yellow][], [pink]int[/pink] [yellow]first[/yellow], [pink]int[/pink] [yellow]last[/yellow]) {
    [pink]if[/pink]([yellow]first[/yellow] <= [yellow]last[/yellow]) {
        [pink]int[/pink] [yellow]middle[/yellow] = ([yellow]first[/yellow] + [yellow]last[/yellow]) / 2;
        [yellow]insert[/yellow]([yellow]data[/yellow][[yellow]middle[/yellow]]);             // insert middle as root/subroot
        [yellow]balance[/yellow]([yellow]data[/yellow], [yellow]first[/yellow], [yellow]middle[/yellow] - 1);  // left subtree
        [yellow]balance[/yellow]([yellow]data[/yellow], [yellow]middle[/yellow] + 1, [yellow]last[/yellow]);   // right subtree
    }
}
// Inorder traversal to verify BST
[pink]void[/pink] [yellow]inorder[/yellow]([blue]BSTNode*[/blue] [yellow]node[/yellow]) {
    [pink]if[/pink](![yellow]node[/yellow]) [pink]return[/pink];
    [yellow]inorder[/yellow]([yellow]node[/yellow]->left);
    [green]cout[/green] << [yellow]node[/yellow]->key << " ";
    [yellow]inorder[/yellow]([yellow]node[/yellow]->right);
}
[pink]int[/pink] [pink]main[/pink]() {
    [pink]int[/pink] [yellow]data[/yellow][] = {0,1,2,3,4,5,6,7,8,9}; // sorted array
    [pink]int[/pink] [yellow]n[/yellow] = sizeof([yellow]data[/yellow]) / sizeof([yellow]data[/yellow][0]);

    [yellow]balance[/yellow]([yellow]data[/yellow], 0, [yellow]n[/yellow] - 1);  // build balanced BST

    [green]cout[/green] << "Inorder of balanced BST: ";
    [yellow]inorder[/yellow]([yellow]root[/yellow]);
    [green]cout[/green] << endl;

    [pink]return[/pink] 0;
}
--END--
--BEGIN--24/11/2025--AVL TREES--
1. AVL Tree Basics
ğ–¦¹ An AVL tree is a binary search tree that keeps itself balanced.
ğ–¦¹ Balance is important because a long, skinny tree makes searching slow.
â€¢ Balanced trees keep search fast: O(log n) time.
ğ–¦¹ AVL trees fix themselves after inserting or deleting nodes.

2. AVL Tree Rules
ğ–¦¹ AVL = BST + height rule
ğ–¦¹ Must satisfy BST ordering.
ğ–¦¹ Balance rule: For every node, |height(left) â€“ height(right)| â‰¤ 1
â€¢ Difference is called balance factor: balance factor = height(right) â€“ height(left)
â€¢ Allowed values: â€“1, 0, +1
ğ–¦¹ If balance factor becomes â€“2 or +2 â†’ tree is unbalanced and must be fixed.

3. When AVL Tree Needs Fixing
ğ–¦¹ Tree becomes unbalanced after inserting or deleting a node.
ğ–¦¹ There are 4 rotation cases (2 main + 2 mirror images).

4. LL Rotation (Left-Left)
ğ–¦¹ Happens when insertion is in left subtree of left child.
â€¢ Fix: Right rotation on P
BEFORE
      P
     /
    Q
   /
  R
AFTER
      Q
     / \
    R   P

5. RR Rotation (Right-Right)
ğ–¦¹ Happens when insertion is in right subtree of right child.
â€¢ Fix: Left rotation on P
BEFORE
  P
   \
    Q
     \
      R
AFTER
      Q
     / \
    P   R

6. LR Rotation (Left-Right)
ğ–¦¹ Happens when insertion is in right subtree of left child.
â€¢ Fix: Double rotation â†’ Left rotation on Q, Right rotation on P
BEFORE
      P
     /
    Q
     \
      R
AFTER
      R
     / \
    Q   P

7. RL Rotation (Right-Left)
ğ–¦¹ Happens when insertion is in left subtree of right child.
â€¢ Fix: Double rotation â†’ Right rotation on Q, Left rotation on P
BEFORE
    P
     \
      Q
     /
    R
AFTER
      R
     / \
    P   Q

8. Rotation Summary
ğ–¦¹ LL: Right rotate P â†’ Root becomes Q
ğ–¦¹ RR: Left rotate P â†’ Root becomes Q
ğ–¦¹ LR: Rotate Q â†’ Rotate P â†’ Root becomes R
ğ–¦¹ RL: Rotate Q â†’ Rotate P â†’ Root becomes R

9. Node Definition in C++
ğ–¦¹ [pink]struct[/pink] [yellow]Node[/yellow] {
  [pink]int[/pink] [yellow]key[/yellow];
  [pink]Node*[/pink] [yellow]left[/yellow];
  [pink]Node*[/pink] [yellow]right[/yellow];
  [pink]int[/pink] [yellow]height[/yellow];
  [pink]Node[/pink]([pink]int[/pink] [yellow]k[/yellow]) {
    [yellow]key[/yellow] = [yellow]k[/yellow];
    [yellow]left[/yellow] = [yellow]right[/yellow] = [green]nullptr[/green];
    [yellow]height[/yellow] = 1;
  }
};

10. Helper Functions
ğ–¦¹ [pink]int[/pink] [yellow]height[/yellow]([pink]Node*[/pink] [yellow]n[/yellow]) { if (![yellow]n[/yellow]) return 0; return [yellow]n[/yellow]->height; }
ğ–¦¹ [pink]int[/pink] [yellow]getBalance[/yellow]([pink]Node*[/pink] [yellow]n[/yellow]) { if (![yellow]n[/yellow]) return 0; return height([yellow]n[/yellow]->right) - height([yellow]n[/yellow]->left); }
ğ–¦¹ void [yellow]updateHeight[/yellow]([pink]Node*[/pink] [yellow]n[/yellow]) { [yellow]n[/yellow]->height = 1 + [green]max[/green](height([yellow]n[/yellow]->left), height([yellow]n[/yellow]->right)); }

11. Rotations
ğ–¦¹ Right rotation (LL)
[pink]Node*[/pink] [yellow]rightRotate[/yellow]([pink]Node*[/pink] [yellow]y[/yellow]) {
  [pink]Node*[/pink] [yellow]x[/yellow] = [yellow]y[/yellow]->left;
  [pink]Node*[/pink] [yellow]T2[/yellow] = [yellow]x[/yellow]->right;
  [yellow]x[/yellow]->right = [yellow]y[/yellow];
  [yellow]y[/yellow]->left = [yellow]T2[/yellow];
  updateHeight([yellow]y[/yellow]); updateHeight([yellow]x[/yellow]);
  return [yellow]x[/yellow];
}
ğ–¦¹ Left rotation (RR)
[pink]Node*[/pink] [yellow]leftRotate[/yellow]([pink]Node*[/pink] [yellow]x[/yellow]) {
  [pink]Node*[/pink] [yellow]y[/yellow] = [yellow]x[/yellow]->right;
  [pink]Node*[/pink] [yellow]T2[/yellow] = [yellow]y[/yellow]->left;
  [yellow]y[/yellow]->left = [yellow]x[/yellow];
  [yellow]x[/yellow]->right = [yellow]T2[/yellow];
  updateHeight([yellow]x[/yellow]); updateHeight([yellow]y[/yellow]);
  return [yellow]y[/yellow];
}

12. Insertion with AVL Balancing
ğ–¦¹ [pink]Node*[/pink] [yellow]insert[/yellow]([pink]Node*[/pink] [yellow]node[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
  if (![yellow]node[/yellow]) return new [yellow]Node[/yellow]([yellow]key[/yellow]);
  if ([yellow]key[/yellow] < [yellow]node[/yellow]->key) [yellow]node[/yellow]->left = insert([yellow]node[/yellow]->left, [yellow]key[/yellow]);
  else [yellow]node[/yellow]->right = insert([yellow]node[/yellow]->right, [yellow]key[/yellow]);
  updateHeight([yellow]node[/yellow]);
  [pink]int[/pink] [yellow]balance[/yellow] = getBalance([yellow]node[/yellow]);
  if ([yellow]balance[/yellow] < -1 && [yellow]key[/yellow] < [yellow]node[/yellow]->left->key) return rightRotate([yellow]node[/yellow]);
  if ([yellow]balance[/yellow] > 1 && [yellow]key[/yellow] > [yellow]node[/yellow]->right->key) return leftRotate([yellow]node[/yellow]);
  if ([yellow]balance[/yellow] < -1 && [yellow]key[/yellow] > [yellow]node[/yellow]->left->key) { [yellow]node[/yellow]->left = leftRotate([yellow]node[/yellow]->left); return rightRotate([yellow]node[/yellow]); }
  if ([yellow]balance[/yellow] > 1 && [yellow]key[/yellow] < [yellow]node[/yellow]->right->key) { [yellow]node[/yellow]->right = rightRotate([yellow]node[/yellow]->right); return leftRotate([yellow]node[/yellow]); }
  return [yellow]node[/yellow];
}

13. Utility: Inorder Traversal
ğ–¦¹ void [yellow]inorder[/yellow]([pink]Node*[/pink] [yellow]root[/yellow]) { if (![yellow]root[/yellow]) return; inorder([yellow]root[/yellow]->left); [green]cout[/green] << [yellow]root[/yellow]->key << " "; inorder([yellow]root[/yellow]->right); }

14. Example Usage
ğ–¦¹ [pink]int[/pink] [yellow]main[/yellow]() {
  [pink]Node*[/pink] [yellow]root[/yellow] = [green]nullptr[/green];
  [pink]int[/pink] [yellow]nums[/yellow][] = {10, 20, 30, 40, 50, 25};
  for ([pink]int[/pink] [yellow]key[/yellow] : [yellow]nums[/yellow]) [yellow]root[/yellow] = insert([yellow]root[/yellow], [yellow]key[/yellow]);
  [green]cout[/green] << "Inorder traversal of AVL tree: ";
  inorder([yellow]root[/yellow]);
  [green]cout[/green] << [green]endl[/green];
  return 0;
}

15. Example 1: Inserting Nodes in Ascending Order
ğ–¦¹ Insert nodes: 10, 20, 30, 40, 50, 25
â€¢ Step 1: Insert 10, 20, 30
- Insert 10 â†’ tree: 10
- Insert 20 â†’ tree: 10 â†’ 20
- Insert 30 â†’ tree becomes unbalanced (RR case at 10)
- Fix RR rotation at 10 â†’ new root = 20
      20
     /  \
   10    30
âœ… Now balanced
â€¢ Step 2: Insert 40, 50
- Insert 40 â†’ tree:
      20
     /  \
   10    30
           \
            40
- Insert 50 â†’ tree unbalanced (RR case at 30)
- Fix RR rotation at 30 â†’ 40 becomes new subtree root
      20
     /  \
   10    40
        /  \
      30    50
âœ… Still AVL balanced
â€¢ Step 3: Insert 25
- Insert 25 under 30:
      20
     /  \
   10    40
        /  \
      30    50
     /
   25
- Check balance:
  â€¢ Node 30: left height 1, right height 0 â†’ balance = -1 â†’ fine
  â€¢ Node 40: left height 2, right height 1 â†’ balance = +1 â†’ fine
  â€¢ Node 20: left height 1, right height 3 â†’ balance = +2 â†’ unbalanced
- This is RL case at 20:
  â€¢ Step 1: Right rotate on 40's left child (30)
  â€¢ Step 2: Left rotate on 20
- After rotations:
        30
       /  \
     20    40
    / \      \
  10   25    50
âœ… Balanced AVL tree

16. Example 2: Complex LR Case
ğ–¦¹ Insert nodes: 50, 30, 70, 20, 40, 35
â€¢ Step 1: Build initial tree
    50
   /
  30
 /
20
- LL case at 50 â†’ right rotate 50
    30
   /  \
 20    50
â€¢ Step 2: Insert 40, then 35
      30
     /  \
   20    50
        /
      40
     /
   35
- Check balance:
  â€¢ Node 50: left height 2, right height 0 â†’ balance = -2 â†’ unbalanced
- This is LR case at 50 (left-right heavy):
  â€¢ Step 1: Left rotate on 40 â†’ 35 becomes left child of 50
      30
     /  \
   20    50
        /
      35
        \
        40
  â€¢ Step 2: Right rotate on 50 â†’ 35 becomes new subtree root
      30
     /  \
   20    35
           \
            50
           /
         40
âœ… Balanced AVL tree again
--END--
--BEGIN--24/11/2025--RED BLACK TREES--
1. Red Black Tree
ğ–¦¹ It is a special binary search tree that keeps its height small.
ğ–¦¹ Every node has a color: red or black.
ğ–¦¹ The color rules keep the tree almost balanced.
â€¢ Rule: Every node is either red or black.
â€¢ Rule: The root is always black.
â€¢ Rule: Red node cannot have a red child.
â€¢ Rule: Every path from a node to its leaf-null has the same number of black nodes.
ğ–¦¹ Because of these rules, the longest path is at most twice the shortest path.
ğ–¦¹ So the height h â‰¤ 2 Ã— logâ‚‚(n+1).
ğ–¦¹ It supports fast search, insert, and delete in O(log n).

2. Red black tree worries removed
ğ–¦¹ You do not need to arrange colors or rotations by yourself.
ğ–¦¹ The rules will always fix the tree to keep height low.
ğ–¦¹ The operations are always near log time.
ğ–¦¹ You just use insert and delete; balancing happens inside.

3. Operations needed
ğ–¦¹ You need: left rotate, right rotate.
ğ–¦¹ You need: color flip or recolor.
ğ–¦¹ Insert and delete use these to fix problems automatically.
ğ–¦¹ The property â€œno two reds in a rowâ€ is always checked and repaired.
ğ–¦¹ The black-height rule is also kept.

4. C++ code: Node structure
ğ–¦¹ Here is the simple node structure.
<blue>struct</blue> Node {
    <green>int</green> data;
    <blue>bool</blue> <orange>color</orange>; <grey>// 0 = black, 1 = red</grey>
    Node* left;
    Node* right;
    Node* parent;
};

5. C++ code: Left rotate
ğ–¦¹ This rotation moves a child up and shifts nodes to the side.
<blue>void</blue> leftRotate(Node* <purple>&root</purple>, Node* <purple>x</purple>) {
    Node* y = x->right;
    x->right = y->left;
    <yellow>if</yellow> (y->left != <red>nullptr</red>)
        y->left->parent = x;
    y->parent = x->parent;
    <yellow>if</yellow> (x->parent == <red>nullptr</red>)
        root = y;
    <yellow>else if</yellow> (x == x->parent->left)
        x->parent->left = y;
    <yellow>else</yellow>
        x->parent->right = y;
    y->left = x;
    x->parent = y;
}

6. C++ code: Right rotate
ğ–¦¹ This rotation is the mirror of left rotate.
<blue>void</blue> rightRotate(Node* <purple>&root</purple>, Node* <purple>y</purple>) {
    Node* x = y->left;
    y->left = x->right;
    <yellow>if</yellow> (x->right != <red>nullptr</red>)
        x->right->parent = y;
    x->parent = y->parent;
    <yellow>if</yellow> (y->parent == <red>nullptr</red>)
        root = x;
    <yellow>else if</yellow> (y == y->parent->right)
        y->parent->right = x;
    <yellow>else</yellow>
        y->parent->left = x;
    x->right = y;
    y->parent = x;
}

7. C++ code: Fix insert
ğ–¦¹ When a new node is inserted, it may break red-black rules.
ğ–¦¹ This function repairs it.
<blue>void</blue> fixInsert(Node* <purple>&root</purple>, Node* <purple>z</purple>) {
    <yellow>while</yellow> (z->parent != <red>nullptr</red> && z->parent->color == <brown>1</brown>) {
        <yellow>if</yellow> (z->parent == z->parent->parent->left) {
            Node* y = z->parent->parent->right;
            <yellow>if</yellow> (y != <red>nullptr</red> && y->color == <brown>1</brown>) {
                z->parent->color = <brown>0</brown>;
                y->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                z = z->parent->parent;
            } <yellow>else</yellow> {
                <yellow>if</yellow> (z == z->parent->right) {
                    z = z->parent;
                    leftRotate(root, z);
                }
                z->parent->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                rightRotate(root, z->parent->parent);
            }
        } <yellow>else</yellow> {
            Node* y = z->parent->parent->left;
            <yellow>if</yellow> (y != <red>nullptr</red> && y->color == <brown>1</brown>) {
                z->parent->color = <brown>0</brown>;
                y->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                z = z->parent->parent;
            } <yellow>else</yellow> {
                <yellow>if</yellow> (z == z->parent->left) {
                    z = z->parent;
                    rightRotate(root, z);
                }
                z->parent->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                leftRotate(root, z->parent->parent);
            }
        }
    }
    root->color = <brown>0</brown>;
}

8. C++ code: Insert function
ğ–¦¹ This inserts normally like a BST.
ğ–¦¹ Then fixInsert() repairs the tree.
<blue>void</blue> insert(Node* <purple>&root</purple>, <green>int</green> data) {
    Node* z = <blue>new</blue> Node{data, <brown>1</brown>, <red>nullptr</red>, <red>nullptr</red>, <red>nullptr</red>};
    Node* y = <red>nullptr</red>;
    Node* x = root;
    <yellow>while</yellow> (x != <red>nullptr</red>) {
        y = x;
        <yellow>if</yellow> (z->data < x->data)
            x = x->left;
        <yellow>else</yellow>
            x = x->right;
    }
    z->parent = y;
    <yellow>if</yellow> (y == <red>nullptr</red>)
        root = z;
    <yellow>else if</yellow> (z->data < y->data)
        y->left = z;
    <yellow>else</yellow>
        y->right = z;
    fixInsert(root, z);
}
--END--
--BEGIN--24/11/2025--SELF ADJUSTING TREES--
1. Self-Adjusting Trees
ğ–¦¹ When a node is accessed, move it closer to the root.
ğ–¦¹ Frequently accessed nodes stay near the top; rarely used nodes stay deeper.
ğ–¦¹ This makes searches faster for important elements.

2. Deciding which nodes to move
ğ–¦¹ Two ways:
â€¢ Using counters: each node tracks access count; nodes with high count move toward root.
â€¢ Simple assumption: move accessed node up immediately, assuming it will be used again.
ğ–¦¹ The tree acts like a priority tree with most used nodes near the root.

3. Single Rotation
ğ–¦¹ Move a node up by one step.
ğ–¦¹ Example: accessing node 2 in this tree:
      10
     /  \
    5    20
   / \
  2   7
ğ–¦¹ Rotate 2 with its parent 5:
      10
     /  \
    2    20
     \
      5
       \
        7
ğ–¦¹ Node 2 moved closer to root. Repeated accesses can move it further.

4. Move-to-Root
ğ–¦¹ Move a node all the way to root in one access.
ğ–¦¹ Example: accessing node 2:
Step 1: rotate 2 with 5
      10
     /  \
    2    20
     \
      5
       \
        7
Step 2: rotate 2 with 10
      2
       \
        10
       /  \
      5    20
       \
        7
ğ–¦¹ Node 2 becomes root immediately; next access is very fast.
--END--
--BEGIN--24/11/2025--SPLAYING TREES--
1. Splaying
ğ–¦¹ A smarter move-to-root method using pairs of rotations.
ğ–¦¹ Rotations depend on the node's parent and grandparent.
ğ–¦¹ This flattens the tree and makes frequently accessed nodes easier to reach.

2. Splay Case 1: Parent is root
ğ–¦¹ Node R with parent Q:
Initial:
   Q
  /
 R
ğ–¦¹ Rotate R with Q:
   R
    \
     Q
ğ–¦¹ Node R becomes root.

3. Splay Case 2: Homogeneous (zig-zig)
ğ–¦¹ Left-left example: node R under Q under P
Initial:
     P
    /
   Q
  /
 R
Step 1: Rotate Q with P
   Q
  / \
 R   P
Step 2: Rotate R with Q
     R
      \
       Q
        \
         P
ğ–¦¹ Node R moves up two levels; tree is flatter.
ğ–¦¹ Right-right is symmetric.

4. Splay Case 3: Heterogeneous (zig-zag)
ğ–¦¹ Left-right example: node R under Q under P
Initial:
     P
    /
   Q
    \
     R
Step 1: Rotate R with Q
     P
    /
   R
  /
 Q
Step 2: Rotate R with P
    R
   / \
  Q   P
ğ–¦¹ Node R is closer to root; tree is flatter.
TO LEARN: DELETION BY COPYING, MERGING AND POLISH AND REVERSE POLISH NOTATIONS
--END--
--BEGIN--25/11/2025--TREAPS--
1. Treap
IMG_URL treap.gif
ğ–¦¹ A treap is a data structure that mixes a binary search tree idea (sorted by key) and a heap idea (ordered by priority).
ğ–¦¹ Each node has a key for searching and a priority for balancing.
ğ–¦¹ The tree stays balanced on average because priorities are random.
â€¢ A treap follows two rules:
  - Binary search tree rule: left child key < node key < right child key.
  - Heap rule: parent priority is smaller than children.
â€¢ Insert, delete, and search take O(log n) on average.
â€¢ Insert first follows BST rule, then rotations fix the heap rule.
â€¢ Random priorities keep the shape balanced without complex rules.

2. How a treap works
ğ–¦¹ Sorted by key decides left or right child.
ğ–¦¹ Ordered by priority decides how high or low the node sits.
ğ–¦¹ After inserting by key, rotations fix any heap-rule break.
â€¢ Random priorities:
  - Make the tree balanced on average.
  - Avoid complex rules used in other balanced BSTs.

3. Node information
ğ–¦¹ Each node has (key, priority).
ğ–¦¹ Smaller priority means the node should be higher in the tree.
â€¢ Example keys:
  - 42, 7, 55, 13, 90, 31
â€¢ Example priorities:
  - (42,80), (7,10), (55,60), (13,30), (90,90), (31,40)

4. BST insertion step
ğ–¦¹ Insert based on key as in a binary search tree.
ğ–¦¹ Example order: 42 â†’ 7 â†’ 55 â†’ 13 â†’ 90 â†’ 31
ğ–¦¹ The BST shape forms by key only.

5. Heap fixing step
ğ–¦¹ Smaller priority means better position.
ğ–¦¹ Each node rotates upward if its priority is smaller than the parent.
ğ–¦¹ Final treap shape follows both BST and heap rules.
â€¢ Example final shape:
  - (7,10) â†’ (13,30) â†’ (31,40) â†’ (42,80) â†’ (55,60) â†’ (90,90)
â€¢ This forms a chain because keys and priorities increased in similar order by chance.

6. Use of a treap
ğ–¦¹ Gives all BST operations (search, insert, delete).
ğ–¦¹ Maintains O(log n) expected time.
ğ–¦¹ Simpler code compared to AVL or Red-Black trees.
â€¢ It stays balanced automatically because priorities are random.
  - Height stays close to log n.
  - Makes operations fast.
  - Long chains are rare on average.

7. Main operations
ğ–¦¹ Fast search
â€¢ Works using keys like a normal BST.
ğ–¦¹ Fast insert
  - Random priority + rotations keep balance.
ğ–¦¹ Fast delete
  - Rotate the node down until it becomes a leaf, then remove.
ğ–¦¹ Split and merge
  - Split makes two treaps: keys < x, and keys â‰¥ x.
  - Merge joins two treaps if all keys in the first are < all keys in the second.
  - Both operations take O(log n).
  - Other balanced trees cannot do this easily.

8. What you can build with treaps
ğ–¦¹ Ordered sets or maps
â€¢ Similar to C++ set/map but simpler to code.
ğ–¦¹ Range queries
  - You can store subtree sum, max, count, lazy flags, etc.
ğ–¦¹ Interval trees
  - Useful for overlapping intervals, scheduling, compilers.
ğ–¦¹ Rope structure
  - Used in editors, versioning, undo/redo, and long strings.
ğ–¦¹ Randomized balanced BST
  - Common in competitive programming.
ğ–¦¹ Implicit treap
  - Index acts like the key.
  - Helps with cutting arrays, reversing ranges, inserting in the middle, splitting strings, merging strings in O(log n).

9. Implementation in C++
[pink]#include[/pink] <bits/stdc++.h>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]struct[/pink] [blue]Treap[/blue] {
    [pink]int[/pink] [yellow]key[/yellow], [yellow]priority[/yellow];
    [blue]Treap[/blue] *[yellow]left[/yellow], *[yellow]right[/yellow];

    [blue]Treap[/blue]([pink]int[/pink] [yellow]k[/yellow]) {
        [yellow]key[/yellow] = [yellow]k[/yellow];
        [yellow]priority[/yellow] = [green]rand[/green]();  [gray]// random priority[/gray]
        [yellow]left[/yellow] = [yellow]right[/yellow] = [green]NULL[/green];
    }
};

[gray]// Right rotation[/gray]
[blue]Treap[/blue]* rotateRight([blue]Treap[/blue]* [yellow]y[/yellow]) {
    [blue]Treap[/blue]* [yellow]x[/yellow] = [yellow]y[/yellow]->left;
    [blue]Treap[/blue]* [yellow]T[/yellow] = [yellow]x[/yellow]->right;

    [yellow]x[/yellow]->right = [yellow]y[/yellow];
    [yellow]y[/yellow]->left = [yellow]T[/yellow];
    [pink]return[/pink] [yellow]x[/yellow];
}

[gray]// Left rotation[/gray]
[blue]Treap[/blue]* rotateLeft([blue]Treap[/blue]* [yellow]x[/yellow]) {
    [blue]Treap[/blue]* [yellow]y[/yellow] = [yellow]x[/yellow]->right;
    [blue]Treap[/blue]* [yellow]T[/yellow] = [yellow]y[/yellow]->left;

    [yellow]y[/yellow]->left = [yellow]x[/yellow];
    [yellow]x[/yellow]->right = [yellow]T[/yellow];
    [pink]return[/pink] [yellow]y[/yellow];
}

[gray]// Insert key into treap[/gray]
[blue]Treap[/blue]* insert([blue]Treap[/blue]* [yellow]root[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink] [pink]new[/pink] [blue]Treap[/blue]([yellow]key[/yellow]);

    [pink]if[/pink] ([yellow]key[/yellow] < [yellow]root[/yellow]->key) {
        [yellow]root[/yellow]->left = insert([yellow]root[/yellow]->left, [yellow]key[/yellow]);

        [pink]if[/pink] ([yellow]root[/yellow]->left->priority > [yellow]root[/yellow]->priority)
            [yellow]root[/yellow] = rotateRight([yellow]root[/yellow]);

    } [pink]else[/pink] {
        [yellow]root[/yellow]->right = insert([yellow]root[/yellow]->right, [yellow]key[/yellow]);

        [pink]if[/pink] ([yellow]root[/yellow]->right->priority > [yellow]root[/yellow]->priority)
            [yellow]root[/yellow] = rotateLeft([yellow]root[/yellow]);
    }

    [pink]return[/pink] [yellow]root[/yellow];
}

[gray]// Delete a key from treap[/gray]
[blue]Treap[/blue]* remove([blue]Treap[/blue]* [yellow]root[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink] [yellow]root[/yellow];

    [pink]if[/pink] ([yellow]key[/yellow] < [yellow]root[/yellow]->key) {
        [yellow]root[/yellow]->left = remove([yellow]root[/yellow]->left, [yellow]key[/yellow]);

    } [pink]else if[/pink] ([yellow]key[/yellow] > [yellow]root[/yellow]->key) {
        [yellow]root[/yellow]->right = remove([yellow]root[/yellow]->right, [yellow]key[/yellow]);

    } [pink]else[/pink] { 
        [pink]if[/pink] (![yellow]root[/yellow]->left) {
            [blue]Treap[/blue]* [yellow]r[/yellow] = [yellow]root[/yellow]->right;
            [pink]delete[/pink] [yellow]root[/yellow];
            [pink]return[/pink] [yellow]r[/yellow];

        } [pink]else if[/pink] (![yellow]root[/yellow]->right) {
            [blue]Treap[/blue]* [yellow]l[/yellow] = [yellow]root[/yellow]->left;
            [pink]delete[/pink] [yellow]root[/yellow];
            [pink]return[/pink] [yellow]l[/yellow];

        } [pink]else[/pink] {
            [pink]if[/pink] ([yellow]root[/yellow]->left->priority > [yellow]root[/yellow]->right->priority) {
                [yellow]root[/yellow] = rotateRight([yellow]root[/yellow]);
                [yellow]root[/yellow]->right = remove([yellow]root[/yellow]->right, [yellow]key[/yellow]);
            } [pink]else[/pink] {
                [yellow]root[/yellow] = rotateLeft([yellow]root[/yellow]);
                [yellow]root[/yellow]->left = remove([yellow]root[/yellow]->left, [yellow]key[/yellow]);
            }
        }
    }
    [pink]return[/pink] [yellow]root[/yellow];
}

[gray]// Search a key[/gray]
[pink]bool[/pink] search([blue]Treap[/blue]* [yellow]root[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return false[/pink];
    [pink]if[/pink] ([yellow]root[/yellow]->key == [yellow]key[/yellow]) [pink]return true[/pink];
    [pink]if[/pink] ([yellow]key[/yellow] < [yellow]root[/yellow]->key) [pink]return[/pink] search([yellow]root[/yellow]->left, [yellow]key[/yellow]);
    [pink]return[/pink] search([yellow]root[/yellow]->right, [yellow]key[/yellow]);
}

[gray]// Inorder traversal[/gray]
[pink]void[/pink] inorder([blue]Treap[/blue]* [yellow]root[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink];
    inorder([yellow]root[/yellow]->left);
    [green]cout[/green] << "(" << [yellow]root[/yellow]->key << ", p=" << [yellow]root[/yellow]->priority << ") ";
    inorder([yellow]root[/yellow]->right);
}

[pink]int[/pink] main() {
    [green]srand[/green]([green]time[/green]([green]NULL[/green]));

    [blue]Treap[/blue]* [yellow]root[/yellow] = [green]NULL[/green];

    [yellow]root[/yellow] = insert([yellow]root[/yellow], 5);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 2);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 8);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 1);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 3);

    [green]cout[/green] << "Treap inorder: ";
    inorder([yellow]root[/yellow]);
    [green]cout[/green] << "\n";

    [green]cout[/green] << "Search 3: " << search([yellow]root[/yellow], 3) << "\n";
    [green]cout[/green] << "Search 10: " << search([yellow]root[/yellow], 10) << "\n";

    [yellow]root[/yellow] = remove([yellow]root[/yellow], 2);

    [green]cout[/green] << "After deleting 2: ";
    inorder([yellow]root[/yellow]);
    [green]cout[/green] << "\n";
}
--END--
--BEGIN--25/11/2025--MULTIWAY TREES--
1. Multiway tree
IMG_URL mway-tree.png
ğ–¦¹ A multiway tree is a tree where one node can have many children.
ğ–¦¹ If a node can have m children, it is called an m-way tree.
â€¢ Example:
  - A 4-way tree means each node can have up to 4 children.
- A multiway tree becomes shorter because more keys fit in one node.

2. Why use multiway trees
ğ–¦¹ Binary trees may become very tall when unbalanced.
ğ–¦¹ Multiway trees are shorter because many keys are stored in one node.
â€¢ Shorter height means faster search, which is important for disks and large databases.

3. m-way search tree
ğ–¦¹ It is a multiway tree with ordering rules for fast search.
ğ–¦¹ Each node stores m â€“ 1 keys and m children.
- Searching works like a BST but with more children.

4. Rules of an m-way search tree
ğ–¦¹ Rule 1: Each node has m children and m â€“ 1 keys.
â€¢ Example for m = 4:
  - Node has 3 keys and 4 children.
ğ–¦¹ Rule 2: Keys in a node are sorted in ascending order.
â€¢ Example: [30, 50, 80]
ğ–¦¹ Rule 3: Keys in the first i children are smaller than the i-th key.
â€¢ Example:
  - Keys: 30  50  80
  - Children: C1 C2 C3 C4
  - All keys in C1 < 30
  - All keys in C2 are between 30 and 50
  - All keys in C3 are between 50 and 80
ğ–¦¹ Rule 4: Keys in the last m â€“ i children are larger than the i-th key.
â€¢ Example:
  - All keys in C4 > 80

5. Why we need m-way search trees
ğ–¦¹ Binary search trees often become unbalanced.
ğ–¦¹ If unbalanced, some elements take many steps to find.
â€¢ This makes the height large and slows search on disk.
ğ–¦¹ Better balanced multiway trees fix this for large data.
â€¢ Examples:
  - B-trees
  - B+-trees
  - 2-3 trees
  - 2-3-4 trees
--END--
--BEGIN--25/11/2025--WHY B TREES?--
1. How disks work
IMG_URL seek-rotation-transfer.png
ğ–¦¹ Disks are divided into blocks for reading and writing data.
ğ–¦¹ When accessing data, the whole block is read into memory.
ğ–¦¹ When storing data, the entire block is written to disk.

2. Disk access is slow
ğ–¦¹ Disk access is slower than memory because disks have mechanical parts.
ğ–¦¹ Total access time = seek time + rotational delay + transfer time.
â€¢ Seek time: moving disk head to correct track.
â€¢ Rotational delay (latency): waiting for correct block to spin under head.
â€¢ Transfer time: moving data to memory.
â€¢ Example:
  - Seek time = 40 ms
  - Latency = 10 ms
  - Transfer 5KB = 5 ms
  - Total access time = 55 ms

3. Memory vs disk
ğ–¦¹ CPU works in microseconds or nanoseconds, much faster than disk.
ğ–¦¹ Disk works in milliseconds.
ğ–¦¹ Accessing data from disk is 1,000 to 1,000,000 times slower than memory operations.

4. Problem with binary search trees on disk
ğ–¦¹ Each BST node may be in a different disk block.
ğ–¦¹ Searching, inserting, or deleting may need many block reads.
ğ–¦¹ Result: BSTs fast in memory become slow on disk.

5. Accessing large chunks is faster
ğ–¦¹ Reading more data at once reduces disk access overhead.
â€¢ Example:
  - 10KB at once â†’ 40 + 10 + 10 = 60 ms
  - Two 5KB pieces â†’ 2 Ã— (40 + 10 + 5) = 110 ms
ğ–¦¹ Key idea: Minimize the number of disk accesses in data structures.
ğ–¦¹ B-trees and multiway trees store many keys in one node/block.
ğ–¦¹ This reduces block reads and improves performance on large datasets.
--END--
--BEGIN--25/11/2025--B TREES--
1. B-tree = Multiway search tree
ğ–¦¹ A B-tree is a multiway tree where each node can have more than 2 children.
ğ–¦¹ In a B-tree of order m:
â€¢ Each node can have at most m children.
â€¢ Each node can have at most m-1 keys.
- Keys divide the children. Example: a node with 3 keys can have 4 children.

2. Whatâ€™s in a node
ğ–¦¹ Each node contains:
â€¢ Array of keys â†’ up to m-1 keys
â€¢ Array of children references â†’ up to m children
â€¢ Leaf flag â†’ true if node is a leaf
â€¢ Key count â†’ number of keys actually present
ğ–¦¹ Example for order m = 4:
[pink]Node[/pink]:
  keys = [yellow]10, 20, 30[/yellow]      // 3 keys
  children = [yellow]C0, C1, C2, C3[/yellow]  // 4 children
  leaf = false
  keyCount = 3
â€¢ C0 contains keys < 10
â€¢ C1 contains keys 10â€“19
â€¢ C2 contains keys 20â€“29
â€¢ C3 contains keys â‰¥ 30

3. Root node
ğ–¦¹ The root can have fewer than m-1 keys (even 1 key if not a leaf).
ğ–¦¹ Every node except root must have at least ceil(m/2) â€“ 1 keys.
- Root may have fewer keys than other nodes.

4. Leaf vs internal nodes
ğ–¦¹ Leaf node: no children, only keys.
ğ–¦¹ Internal node: has children references + keys.
ğ–¦¹ Leaf flag helps the algorithm know whether to stop or go deeper.

5. Visualization (order 4, root example)
ğ–¦¹ Example tree:
          [20]
        /      \
   [5, 10]   [25, 30]
ğ–¦¹ Root has 1 key â†’ 2 children
ğ–¦¹ Left child has 2 keys â†’ 3 children (if not leaf)
ğ–¦¹ Right child has 2 keys â†’ 3 children
ğ–¦¹ Keys in children are less than, between, or greater than parent keys.

6. In Essence
ğ–¦¹ Each node can hold multiple keys.
ğ–¦¹ Keys divide the range of children.
ğ–¦¹ Root can have fewer keys than other nodes.
ğ–¦¹ Leaf flag + children pointers help traverse tree efficiently.

6. Search in a B-tree
ğ–¦¹ Start at root and go down the tree until key is found or leaf reached.
ğ–¦¹ Look at keys in the node (sorted).
â€¢ If key matches â†’ found
â€¢ If key < first key â†’ go to first child
â€¢ If key between keys â†’ go to corresponding child
â€¢ If key > last key â†’ go to last child
ğ–¦¹ Repeat until key is found or leaf reached.
ğ–¦¹ Example (order 4):
         [20]
       /     \
   [5, 10]   [25, 30]
â€¢ Search 10 â†’ 10 < 20 â†’ go left â†’ [5, 10] â†’ 10 found
ğ–¦¹ Cost proportional to height â†’ few disk reads if node size matches block size.

7. Insertion in a B-tree
ğ–¦¹ Always insert in a leaf. If leaf is full, split and push middle key to parent.
ğ–¦¹ Steps:
â€¢ Find the leaf where new key should go.
â€¢ Insert key in leaf in sorted order.
â€¢ If leaf has more than m-1 keys â†’ split node into two.
â€¢ Middle key moves up to parent.
â€¢ If parent full â†’ repeat split up to root.
â€¢ If root splits â†’ create new root â†’ height increases by 1.
ğ–¦¹ Example (order 4):
â€¢ Insert 15 into leaf [5,10,12] â†’ leaf full â†’ split â†’ [5,10] and [15,12], middle 12 goes up.

8. Deletion in a B-tree
ğ–¦¹ Remove key. If node less than half full â†’ borrow from sibling or merge nodes.
ğ–¦¹ Steps:
â€¢ Find key to delete.
â€¢ If key in leaf:
  - Delete it.
  - If node still has enough keys â†’ done.
  - If node < minimum keys â†’ borrow from sibling or merge with sibling and move separator from parent.
â€¢ If key in internal node:
  - Replace with predecessor (max in left subtree) or successor (min in right subtree).
  - Delete that key from leaf using leaf deletion rules.
ğ–¦¹ Example:
â€¢ Delete 10 from leaf [5,10,12] â†’ node still enough â†’ [5,12]
â€¢ If underflow occurs â†’ borrow or merge happens.

9. NOTES
ğ–¦¹ Search: follow keys â†’ O(log n)
ğ–¦¹ Insert: insert in leaf â†’ split if needed â†’ propagate up â†’ keeps tree balanced
ğ–¦¹ Delete: remove from leaf or internal node â†’ borrow/merge â†’ tree stays balanced
--END--
--BEGIN--25/11/2025--B+ TREES--
IMG_URL bplustree.png
1. Structure of a B+-tree
ğ–¦¹ A B+-tree is a multiway search tree like a B-tree.
ğ–¦¹ Internal nodes (non-leaves) store only keys, no actual data.
â€¢ They serve as an index to guide searches.
ğ–¦¹ Leaf nodes store actual keys and references to records.
â€¢ Leaves are linked sequentially â†’ makes range queries or ordered scanning fast.
ğ–¦¹ Visual example (order 4):

          [20 | 40]
         /    |    \
    [5,10]  [25,30]   [45,50]

â€¢ Internal node [20|40] â†’ guides search
â€¢ Leaves [5,10], [25,30], [45,50] â†’ store actual data
â€¢ Leaves linked: [5,10] â†’ [25,30] â†’ [45,50]
ğ–¦¹ Difference from B-tree: data only in leaves.

2. Searching in a B+-tree
ğ–¦¹ Start at root, follow keys to correct child.
ğ–¦¹ Repeat until leaf reached.
ğ–¦¹ Look in leaf for the key.
ğ–¦¹ Benefit: searching is fast and predictable since data only at leaves.

3. Insertion in a B+-tree
ğ–¦¹ Step 1: Find the leaf where key should go.
ğ–¦¹ Step 2:
â€¢ If leaf has room â†’ insert in sorted order.
â€¢ If leaf full â†’ split leaf:
  - Create new leaf
  - Divide keys evenly between old and new leaf
  - Copy first key of new leaf to parent (separator)
â€¢ If parent full â†’ split parent recursively
ğ–¦¹ Important: Only leaves hold data; internal nodes are indexes.

4. Deletion in a B+-tree
ğ–¦¹ Step 1: Find the leaf containing key.
ğ–¦¹ Step 2: Remove key from leaf.
â€¢ If leaf â‰¥ half full â†’ done
â€¢ If leaf underflows â†’ borrow from sibling or merge with sibling
â€¢ Update parent separator keys if needed
ğ–¦¹ Step 3: Fix internal nodes recursively if affected (like B-tree)
ğ–¦¹ Example:
â€¢ Leaves: [2,6] [8,10]
â€¢ Delete 2 â†’ underflow â†’ merge â†’ [6,8,10]
â€¢ Remove separator in parent â†’ fix parent keys

5. Why B+-trees are useful
ğ–¦¹ All data in leaves â†’ sequential scan fast.
ğ–¦¹ Internal nodes are indexes â†’ fewer disk accesses for search.
ğ–¦¹ Leaves linked â†’ easy iteration and range queries.
ğ–¦¹ Better for databases and file systems than B-trees.
ğ–¦¹ Comparison:
â€¢ Data storage: B-tree â†’ any node, B+-tree â†’ leaves only
â€¢ Internal nodes: B-tree â†’ keys + data references, B+-tree â†’ keys only
â€¢ Leaves: B-tree â†’ not linked, B+-tree â†’ linked sequentially
â€¢ Range scan: B-tree â†’ slower, B+-tree â†’ fast
--END--
--BEGIN--25/11/2025--B* TREES--
1. B*-tree
ğ–¦¹ A B*-tree is a better form of a normal B-tree.
ğ–¦¹ The idea is to use node space well so we do not create many nodes.
ğ–¦¹ Fewer nodes are good because each node is on disk, and disk reading is slow.
ğ–¦¹ To reduce nodes, each node should hold more keys.

2. Need for fewer nodes
ğ–¦¹ Each B-tree node is stored in secondary memory.
ğ–¦¹ Accessing secondary memory is slow.
ğ–¦¹ So we want nodes to be more full, which reduces the number of nodes.

3. Difference between B-tree and B*-tree
ğ–¦¹ Normal B-tree: Every non-root node must be at least half full.
ğ–¦¹ B*-tree: Every non-root node must be at least two-thirds full.
ğ–¦¹ This means B*-tree nodes hold more keys on average.
ğ–¦¹ So the number of created nodes becomes less.

4. Example of minimum keys
ğ–¦¹ If order m = 9:
â€¢ Normal B-tree non-root node minimum keys = 4
â€¢ B*-tree non-root node minimum keys = 6

5. Insertion in a B*-tree
ğ–¦¹ When inserting, if a node is full, try redistribution first.
â€¢ Instead of splitting at once, borrow or share keys with sibling.

6. Redistribution example
ğ–¦¹ Suppose you insert 6 into a left node that is full.
ğ–¦¹ Check the right sibling:
â€¢ If sibling has space, take keys from both nodes, sort them, divide evenly.
â€¢ Push the middle key to the parent.
ğ–¦¹ This fixes overflow without splitting.

7. Three-way split
ğ–¦¹ If both the node and sibling are full:
â€¢ Combine node keys, sibling keys, and parent separator key.
â€¢ Sort them.
â€¢ Split them into 3 nodes.
â€¢ Insert 2 separator keys into the parent.
ğ–¦¹ This keeps all new nodes at least two-thirds full.
ğ–¦¹ This reduces splits and improves disk usage.

8. Fill factor
ğ–¦¹ B*-tree average node fullness is about 81%.
ğ–¦¹ Some systems allow different fill levels.
â€¢ Example: 75% full is called a B**-tree.
ğ–¦¹ General form: A Bâ¿-tree uses fill rule n / (n + 1).
--END--
--BEGIN--26/11/2025--BIT TREES--
1. Bit-tree
ğ–¦¹ A Bit-tree is like a Bâº-tree but compares keys more deeply.
ğ–¦¹ Bâº-trees compare full keys or prefixes, but Bit-trees compare the exact bit where two keys differ.
ğ–¦¹ Instead of comparing full values like K or N, it compares bits.

2. D-bit (Distinction Bit)
ğ–¦¹ A D-bit shows the first bit position where two keys differ.
â€¢ Example: ASCII of K = 01001011, ASCII of N = 01001110
â€¢ The first difference is at bit position 5
â€¢ So D(K, N) = 5
ğ–¦¹ Bit-trees store these D-bits at the leaves.

3. Data storage in Bit-trees
ğ–¦¹ Leaves do not store keys directly.
ğ–¦¹ Each leaf stores:
â€¢ Keys in sorted order in a connected data file
â€¢ D-bit between each pair of neighbor keys
ğ–¦¹ This reduces space and speeds up searching.

4. Example leaf structure
ğ–¦¹ Sorted keys: K, N, O, R, V
â€¢ K = 01001011
â€¢ N = 01001110
â€¢ O = 01001111
â€¢ R = 01010010
â€¢ V = 01010110
ğ–¦¹ D-bits:
â€¢ K â†’ N = 5
â€¢ N â†’ O = 7
â€¢ O â†’ R = 3
â€¢ R â†’ V = 5

5. Searching in a Bit-tree
ğ–¦¹ Searching uses bits of the given key plus the leafâ€™s D-bits.
ğ–¦¹ Steps:
â€¢ Start with record Râ‚€.
â€¢ For each D-bit:
  - Check that bit in the search key.
  - If the bit is 1, move to that record.
  - If the bit is 0, skip to the next smaller D-bit.
â€¢ After the loop, you reach some record R.
â€¢ Finally compare Râ€™s key with the search key.
ğ–¦¹ If equal â†’ found, else â†’ not found.

6. Search example for key â€œVâ€
ğ–¦¹ V = 01010110
ğ–¦¹ Leaf D-bits: 5, 7, 3, 5
â€¢ Dâ‚ = 5 â†’ V bit 5 = 1 â†’ pick Râ‚
â€¢ Dâ‚‚ = 7 â†’ V bit 7 = 0 â†’ skip until smaller D-bit
â€¢ Dâ‚ƒ = 3 â†’ V bit 3 = 1 â†’ pick Râ‚ƒ
â€¢ Dâ‚„ = 5 â†’ V bit 5 = 1 â†’ pick Râ‚…
ğ–¦¹ End reached â†’ result is Râ‚… â†’ correct record for V.

7. If the key is not present
ğ–¦¹ Example: S = 01010011
ğ–¦¹ The D-bit steps may land on some record like Râ‚ƒ even if S is absent.
ğ–¦¹ Final check:
â€¢ If record key = S â†’ found
â€¢ Else â†’ not found
ğ–¦¹ This avoids wrong answers.
--END--
--BEGIN--26/11/2025--R TREES--
1. R-trees
ğ–¦¹ R-trees store spatial data such as maps, buildings, roads, CAD models, and VLSI designs.
ğ–¦¹ They help answer questions like â€œfind all buildings in this areaâ€ or â€œfind all objects within this distanceâ€.
ğ–¦¹ B-trees cannot store this because spatial objects are rectangles, not single numeric keys.

2. How R-trees store data in leaf nodes
ğ–¦¹ A leaf stores entries of the form (rectangle, id).
â€¢ A rectangle can be ([x1, x2], [y1, y2]) in 2-D or ([c1, c2], â€¦) in n-D.
ğ–¦¹ The rectangle is the minimum bounding box (MBB) of the object.
â€¢ Example: Object X lies in [10,100] Ã— [5,52], so a leaf stores (([10,100], [5,52]), X).

3. How R-trees store data in non-leaf nodes
ğ–¦¹ A non-leaf node stores (enclosing_rectangle, child_pointer).
ğ–¦¹ The enclosing rectangle fully covers all rectangles stored inside its child node.
ğ–¦¹ The tree becomes a hierarchy: small rectangles â†’ bigger rectangles â†’ even bigger rectangles â†’ root.

4. Insertion in R-trees
ğ–¦¹ Start at root and choose the child whose rectangle needs the smallest expansion to include the new object.
ğ–¦¹ Go down until a leaf and insert the new rectangle.
ğ–¦¹ If a leaf becomes full, split it into two nodes.
ğ–¦¹ After splitting, parent rectangles are updated to tightly cover their children.
â€¢ Main difficulty: finding a good split so overlap is low, area is small, and future searches are efficient.

5. Overlap problem in R-trees
ğ–¦¹ Rectangles in non-leaf nodes may overlap.
ğ–¦¹ A search may enter many paths because the search rectangle intersects multiple parent rectangles.
â€¢ Example: R3 lies inside both R10 and R11, so the search may follow a wrong path.
ğ–¦¹ In large R-trees, this overlap can cause slow searches.

6. R+-trees
ğ–¦¹ R+-trees remove overlap between parent rectangles.
ğ–¦¹ Parent rectangles are not allowed to overlap.
ğ–¦¹ If a data rectangle crosses two parent rectangles, it is stored in both leaves.
â€¢ Example: Rectangle R8 is stored in two leaves in the R+-tree.

7. R+-tree advantages and drawbacks
ğ–¦¹ Advantages:
â€¢ No overlap means no confusion during search.
â€¢ Search follows one correct path.
ğ–¦¹ Drawbacks:
â€¢ Node utilization is harder to maintain.
â€¢ One object may appear in multiple leaves.

8. Summary
ğ–¦¹ Parent rectangles overlap: R-tree = Yes, R+-tree = No
ğ–¦¹ Speed: R-tree = Slower, R+-tree = Faster
ğ–¦¹ Object stored in: R-tree = One leaf, R+-tree = Many leaves possible
ğ–¦¹ Node utilization: R-tree = Easier, R+-tree = Harder
ğ–¦¹ Search paths: R-tree = May branch wrongly, R+-tree = Single correct path
ğ–¦¹ R-tree: Tree for spatial objects using bounding rectangles; overlap allowed.
ğ–¦¹ R+-tree: R-tree without overlap in internal nodes; objects may appear many times.
--END--
--BEGIN--26/11/2025--2-4 TREES--
1. 2â€“4 tree
ğ–¦¹ A 2â€“4 tree has nodes that can hold 1, 2, or 3 keys.
ğ–¦¹ A node with 1 key has 2 children; 2 keys â†’ 3 children; 3 keys â†’ 4 children.
ğ–¦¹ Although B-trees are for disk storage, 2â€“4 trees are also used in main memory.

2. Reason for converting a 2â€“4 tree to a binary tree
ğ–¦¹ A 2â€“4 node holds 3 keys and 4 pointers, which wastes space in memory.
ğ–¦¹ So it is changed into a binary tree where each node holds only one key.
ğ–¦¹ Special link types (horizontal or vertical, or red/black links) help recreate the original 2â€“4 structure.
â€¢ This binary form is called a vh-tree or a red-black tree.

3. Vertical and horizontal links
ğ–¦¹ Vertical links show parentâ€“child connections.
ğ–¦¹ Horizontal links show keys that belong to the same 2â€“4 node.
ğ–¦¹ Horizontal links mean â€œthese keys came from the same original nodeâ€.

4. Properties of vh-trees
ğ–¦¹ All root-to-leaf paths have the same number of vertical links, so the tree stays balanced.
ğ–¦¹ No path may have two horizontal links in a row.
â€¢ This stops wrong merging of nodes.
ğ–¦¹ Search is like BST search because we ignore link types while searching.

5. vh-tree height
ğ–¦¹ We check how tall a vh-tree can be.
ğ–¦¹ Height lower bound: log2(n + 1)
ğ–¦¹ Height upper bound: 2 log2(n + 2) â€“ 2
â€¢ Means vh-tree height is at most twice that of a balanced binary tree.
â€¢ This is similar to red-black tree height bounds.

6. Splitting a 4-node
ğ–¦¹ A 4-node has 3 keys and must be split during insertion.
ğ–¦¹ In a 2â€“4 tree, splitting creates two nodes and pushes the middle key upward.
ğ–¦¹ In a vh-tree, splitting is done by flipping 3 link flags:
â€¢ Two child links become vertical.
â€¢ Parent link becomes horizontal.
ğ–¦¹ If flipping causes two horizontal links in a row, rotations are needed.
â€¢ There are around 8 main split patterns.
â€¢ Only some need 1 or 2 rotations.

7. Why rotations are needed
ğ–¦¹ Sometimes the structure becomes: node â†’ horizontal â†’ child â†’ horizontal â†’ grandchild.
ğ–¦¹ This pattern is not allowed and must be fixed.
ğ–¦¹ Fixing uses:
â€¢ Rotations (like in BSTs)
â€¢ A few link flips
ğ–¦¹ Rotations do not increase the height.
--END--
--BEGIN--26/11/2025--SEGMENT TREES--
1. Segment Tree
ğ–¦¹ A segment tree is a binary tree used to answer range-based questions fast.
ğ–¦¹ It helps with tasks like range sum, range min/max, counting in a range, and fast updates.
ğ–¦¹ It keeps both query and update time as O(log n).

2. Reason for using segment trees
ğ–¦¹ Normal array gives slow range queries (O(n)) but fast updates.
ğ–¦¹ Prefix sums give fast range sums (O(1)) but slow updates (O(n)).
ğ–¦¹ Segment tree gives both query and update in O(log n).

3. Basic idea
ğ–¦¹ The array is divided into segments.
â€¢ Example: whole â†’ [0,5], left â†’ [0,2], right â†’ [3,5].
ğ–¦¹ Each segment stores chosen information such as sum, min, max, gcd, xor, etc.
ğ–¦¹ Leaves store single element values; internal nodes store the combined value of their children.

4. Example of building a sum segment tree
ğ–¦¹ For A = [2, 5, 1, 4], the tree stores sums of segments.
ğ–¦¹ Example layout:
â€¢ [0,3] = 12
â€¢ [0,1] = 7, [2,3] = 5
â€¢ [0,0] = 2, [1,1] = 5, [2,2] = 1, [3,3] = 4
ğ–¦¹ Each parent value is the sum of its two child values.

5. Range query example (sum of [1,3])
ğ–¦¹ Fully inside segments â†’ add value.
ğ–¦¹ Fully outside segments â†’ ignore.
ğ–¦¹ Partially inside â†’ go deeper.
ğ–¦¹ Final answer: 5 + 1 + 4 = 10 in O(log n).

6. Update example (A[2] = 10)
ğ–¦¹ Go to leaf [2,2] and change 1 â†’ 10.
ğ–¦¹ Move upward and fix parent values.
â€¢ [2,3] changes.
â€¢ [0,3] changes.
ğ–¦¹ The tree adjusts in O(log n).

7. Size of a segment tree
ğ–¦¹ Maximum size is about 4n nodes.
ğ–¦¹ Using an array of size 4n is safe.

8. Types of segment trees
ğ–¦¹ Sum segment tree.
ğ–¦¹ Min or max segment tree.
ğ–¦¹ GCD segment tree.
ğ–¦¹ Lazy segment tree.
â€¢ Used for range updates like adding +5 to all elements in a range.
â€¢ Normal range update is O(n); lazy update becomes O(log n).

9. Time complexity
ğ–¦¹ Build: O(n)
ğ–¦¹ Query: O(log n)
ğ–¦¹ Update: O(log n)
ğ–¦¹ Lazy propagation update: O(log n)

10. When to use a segment tree
ğ–¦¹ Use when both fast range queries and fast updates are needed.
ğ–¦¹ Common uses:
â€¢ Range sum
â€¢ Range minimum or maximum
â€¢ Range GCD
â€¢ Range XOR
â€¢ Range addition or increment updates
--END--
--BEGIN--02/12/2025--GRAPHS--
1. Graph
ğ–¦¹ A graph has two sets: vertices V and edges E.
ğ–¦¹ An edge is a pair (v, w). If the pair has order, the graph is directed.
ğ–¦¹ In a directed graph, (v, w) means w is next to v. In undirected graphs, (v, w) and (w, v) mean both are next to each other.
ğ–¦¹ An edge can also have a weight or cost.
â €â €â €â €â €â €â €â¢€â£ â£¤â£¤â£„â£€â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €
â €â €â €â €â €â €â¡´â£Ÿâ£¯â¡·â£¿â¡½â£Ÿâ£·â¡€â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €
â €â €â €â €â €â¢€â¢„â¢„â¢€â ™â¢¯â£¿â »â ™â “â €â¢€â¢€â¡€â¡€â €â €â €â €â €â €â €â €â €â €â£€â£ â£ â£€â €â €â €â €â €â €
â €â €â €â €â €â ¸â¡¸â¡¸â¡¸â €â¢€â£ â£´â£¾â£»â£Ÿâ£¿â£»â£Ÿâ£¿â£»â£Ÿâ£·â£¶â£¤â£„â¡€â €â °â£Ÿâ£¯â£¿â£½â£¯â¡¿â£†â €â €â €â €
â €â €â €â €â €â €â £â ƒâ£ â¡¾â£Ÿâ£¯â¡·â£¿â£½â£¯â£¿â£½â£¯â£¿â£½â£¯â¡·â£¿â¢¾â£¯â¡¿â£·â£¦â¡ˆâ ³â¢¿â¢¾â ³â ›â ™â ‚â €â €â €
â €â €â €â €â €â €â¢€â£´â£Ÿâ£¿â¢¯â£¿â£»â£½â¡¾â£·â¢¿â¡¾â£·â¢¿â¡¾â£·â£Ÿâ£¿â£»â¡·â£Ÿâ£¿â¢¾â¡¿â£†â ˆâ¢€â¢”â¢”â¢²â ‚â €â €â €
â €â €â €â €â €â¢€â£¾â£¯â¡¿â£¾â£»â£½â¢¿â£¾â£»â£Ÿâ£¿â£»â£Ÿâ£¿â£»â£¯â£¿â£½â£¯â£¿â£»â£½â£Ÿâ£¿â£»â£·â €â¢±â¢±â ‘â â €â €â €
â €â €â €â €â €â¢¼â¡·â£¿â¡½â£¿â£½â¢¾â£¿â£½â£¯â£¿â£½â£¯â£¿â£½â£¯â¡·â£¿â¢¾â¡·â£¿â£½â¡·â£¿â£½â£Ÿâ£¾â£‡â €â €â €â €â €â €â €
â €â €â €â €â¢€â£¿â£»â£½â¢¿â£½â£¾â£»â¢·â¡¿â£¾â¢·â¡¿â£¾â¢·â¡¿â£¾â£Ÿâ£¿â£»â£Ÿâ£¿â¢¾â£Ÿâ£¿â¢¾â£¯â£·â¢¿â¡€â €â €â €â €â €â €
â €â €â €â €â¢â£¿â£½â¢¾â£»â£·â ‹â ‰â ‰â¢»â£Ÿâ£¿â£»â£Ÿâ£¿â£»â£¯â£¿â£½â£¯â ¿â ½â¢»â£¯â£¿â£»â¡·â£¿â£»â¡‚â €â €â €â €â €â €
â €â €â €â €â â£¿â¢¾â£¿â£½â¢¾â¡€â €â €â£°â£¿â£½â£¿â Ÿâ ›â¢¿â£·â¡¿â£â ‡â €â €â ˆâ£·â¢¿â£½â£Ÿâ£¿â£½â ‚â €â €â €â €â €â €
â €â €â €â €â €â¢¹â£Ÿâ£·â¢¿â£»â£Ÿâ£¯â¡¿â£¯â£¿â£¿â ¿â ‚â €â¢¾â£¿â£¿â¡¿â£·â£¤â ¤â â ›â «â¢·â¡¿â£½â¡â €â €â €â €â €â €â €
â €â €â €â €â €â €â ™â£¿â£»â£½â£¯â£·â¢¿â£¯â£¿â£¯â£¤â£¶â£§â£„â£¼â£¿â£Ÿâ£¿â â¢ â¡ºâ¡¿â£¦â ˆâ£¿â¡¯â ƒâ €â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â ‘â ¿â¢¾â£¯â¡¿â£·â¢¿â£¾â£»â£Ÿâ£¿â£»â£¯â¡·â¡¿â ™â£â£¸â¡»â£¿â£â¡€â ™â â €â €â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â ˆâ¢‰â ‰â ‹â “â »â ½â ¯â ·â »â ½â €â£¼â£â Ÿâ »â£¾â£®â¡»â¡·â£¦â£€â¢¤â¢¤â¡€â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â €â£¿â£»â£Ÿâ£·â¢¶â£–â£†â €â ’â €â â£â£Ÿâ¢§â¢´â â¢»â¢¿â¢¿â£®â£»â¡»â¡·â â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â¢€â£¿â£½â£¯â¢¿â£»â£½â£¯â¡¿â£¿â¢¶â¡€â ˆâ »â£·â£¤â¡‚â¢¸â£·â£€â£¸â¡»â¡‡â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â °â£¿â£â£¯â£¿â£»â¡šâ ³â ¿â¡»â ¿â â£¸â¡¢â£„â ‰â »â ·â£·â£â¡Ÿâ Ÿâ €â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â ¨â£¿â¢¾â£·â£»â£½â£·â£¶â¡†â¢€â¢¶â£®â£¯â¡»â£®â£Ÿâ£–â¢¦â£„â €â €â €â €â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â ¨â£¿â¢¯â¡·â£Ÿâ£·â¢¿â£½â£‡â£ˆâ£â£„â ™â »â¢¾â£®â ƒâ €â €â €â €â €â €â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â €â ¹â£Ÿâ£¿â ¤â €â €â €â ˆâ €â €â €â ¸â¡€â ™â â €â €â €â €â €â €â €â €â €â €â €â €â €
â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â €â ˆâ ˆâ €â €â €â €â €â €â €â €â €â €â €
2. Paths
ğ–¦¹ A path is a sequence of vertices w1, w2, â€¦, wN where each pair (wi, wi+1) is an edge.
ğ–¦¹ Path length = number of edges = N âˆ’ 1.
ğ–¦¹ A path from a vertex to itself with no edges has length 0.
ğ–¦¹ A loop is an edge like (v, v). We usually avoid loops.
ğ–¦¹ A simple path has all different vertices (first and last may match).

3. Cycles
ğ–¦¹ A cycle in a directed graph is a path with length â‰¥ 1 where first and last vertices are the same.
ğ–¦¹ A simple cycle has all distinct vertices except first and last.
ğ–¦¹ In undirected graphs, edges in the cycle must be different.
ğ–¦¹ A directed graph with no cycles is acyclic (DAG).

4. Connectivity
ğ–¦¹ An undirected graph is connected if every vertex can reach every other.
ğ–¦¹ A directed graph is strongly connected if every vertex can reach every other with direction.
ğ–¦¹ If it is not strongly connected but becomes connected when ignoring direction, it is weakly connected.
ğ–¦¹ A complete graph has an edge between every pair of vertices.

5. Graph Representations
IMG_URL directed_g.png
ğ–¦¹ Graph has 7 vertices and 13 edges
ğ–¦¹ Edges: 1â†’2, 1â†’3, 1â†’4, 2â†’4, 2â†’5, 3â†’4, 3â†’6, 4â†’6, 4â†’7, 5â†’4, 5â†’7, 6â†’7, 7â†’6

6. Adjacency Matrix
ğ–¦¹ Rows = source vertex, Columns = target vertex
ğ–¦¹ 1 = edge exists, 0 = no edge
ğ–¦¹ Table:
      1 2 3 4 5 6 7
1     0 1 1 1 0 0 0
2     0 0 0 1 1 0 0
3     0 0 0 1 0 1 0
4     0 0 0 0 0 1 1
5     0 0 0 1 0 0 1
6     0 0 0 0 0 0 1
7     0 0 0 0 0 1 0

7. Adjacency List
ğ–¦¹ Each vertex stores a list of neighbors
ğ–¦¹ List:
1: 2, 3, 4
2: 4, 5
3: 4, 6
4: 6, 7
5: 4, 7
6: 7
7: 6

8. Incidence Matrix
ğ–¦¹ Rows = vertices, Columns = edges (e1 to e13)
ğ–¦¹ Use -1 for edge start, +1 for edge end, 0 otherwise
ğ–¦¹ Table:
	e1	e2	e3	e4	e5	e6	e7	e8	e9	e10	e11	e12	e13
1	-1	-1	-1	0	0	0	0	0	0	0	0	0	0
2	1	0	0	-1	-1	0	0	0	0	0	0	0	0
3	0	1	0	0	0	-1	0	0	0	0	0	0	0
4	0	0	1	1	0	1	-1	-1	0	0	0	0	0
5	0	0	0	0	1	0	0	1	0	0	0	0	0
6	0	0	0	0	0	0	1	0	-1	0	0	0	0
7	0	0	0	0	0	0	0	0	1	-1	0	0	0
ğ–¦¹ Column meaning: e1=1â†’2, e2=1â†’3, e3=1â†’4, e4=2â†’4, e5=2â†’5, e6=3â†’4, e7=3â†’6, e8=4â†’6, e9=4â†’7, e10=5â†’4, e11=5â†’7, e12=6â†’7, e13=7â†’6

9. Compressed Sparse Row (CSR)
ğ–¦¹ Step 1: List edges per vertex (values, columns)
â€¢ Vertex 1 â†’ 2, 3, 4
â€¢ Vertex 2 â†’ 4, 5
â€¢ Vertex 3 â†’ 4, 6
â€¢ Vertex 4 â†’ 6, 7
â€¢ Vertex 5 â†’ 4, 7
â€¢ Vertex 6 â†’ 7
â€¢ Vertex 7 â†’ 6
ğ–¦¹ Step 2: values = [1,1,1, 1,1, 1,1, 1,1, 1,1, 1,1]  # 13 edges
ğ–¦¹ Step 3: columns = [2,3,4, 4,5, 4,6, 6,7, 4,7, 7,6]
ğ–¦¹ Step 4: row_ptr = [0, 3, 5, 7, 9, 11, 12, 13]
â€¢ Vertex 1 edges â†’ indices 0:3 â†’ 3 edges
â€¢ Vertex 2 edges â†’ indices 3:5 â†’ 2 edges
â€¢ Vertex 3 edges â†’ indices 5:7 â†’ 2 edges
â€¢ Vertex 4 edges â†’ indices 7:9 â†’ 2 edges
â€¢ Vertex 5 edges â†’ indices 9:11 â†’ 2 edges
â€¢ Vertex 6 edges â†’ indices 11:12 â†’ 1 edge
â€¢ Vertex 7 edges â†’ indices 12:13 â†’ 1 edge

10. Adjacency Matrix
ğ–¦¹ Structure: VÃ—V matrix
ğ–¦¹ Space: O(VÂ²)
â€¢ Reason: store 0 for every missing edge
ğ–¦¹ Time:
â€¢ Check edge (u,v) â†’ O(1)
â€¢ Iterate neighbors of vertex â†’ O(V)
â€¢ Iterate all edges â†’ O(VÂ²)
ğ–¦¹ Summary:
â€¢ Space: O(VÂ²)
â€¢ Check edge: O(1)
â€¢ Iterate neighbors: O(V)
â€¢ Iterate all edges: O(VÂ²)

11. Adjacency List
ğ–¦¹ Structure: Array or list of lists; each vertex stores outgoing neighbors
ğ–¦¹ Space: O(V + E)
â€¢ Reason: pointers for V vertices + E edges
ğ–¦¹ Time:
â€¢ Check edge (u,v) â†’ O(degree(u)) worst-case O(V)
â€¢ Iterate neighbors â†’ O(degree(u))
â€¢ Iterate all edges â†’ O(V + E)
ğ–¦¹ Summary:
â€¢ Space: O(V + E)
â€¢ Check edge: O(degree(u))
â€¢ Iterate neighbors: O(degree(u))
â€¢ Iterate all edges: O(V + E)

12. Incidence Matrix
ğ–¦¹ Structure: VÃ—E matrix; row = vertex, column = edge, values -1,0,1
ğ–¦¹ Space: O(VÃ—E)
â€¢ Reason: stores outgoing and incoming info
ğ–¦¹ Time:
â€¢ Check edge (u,v) â†’ O(E)
â€¢ Iterate neighbors â†’ O(E)
â€¢ Iterate all edges â†’ O(VÃ—E)
ğ–¦¹ Summary:
â€¢ Space: O(VÃ—E)
â€¢ Check edge: O(E)
â€¢ Iterate neighbors: O(E)
â€¢ Iterate all edges: O(VÃ—E)

13. Compressed Sparse Row (CSR)
ğ–¦¹ Structure:
â€¢ values â†’ store edges (size E)
â€¢ columns â†’ target vertices (size E)
â€¢ row_ptr â†’ start index of each vertex (size V+1)
ğ–¦¹ Space: O(V + E)
â€¢ Reason: values + columns = 2E, row_ptr = V+1
ğ–¦¹ Time:
â€¢ Check edge (u,v) â†’ O(degree(u))
â€¢ Iterate neighbors â†’ O(degree(u))
â€¢ Iterate all edges â†’ O(E)
ğ–¦¹ Summary:
â€¢ Space: O(V + E)
â€¢ Check edge: O(degree(u))
â€¢ Iterate neighbors: O(degree(u))
â€¢ Iterate all edges: O(E)

14. Quick Comparison
ğ–¦¹ Adjacency Matrix: Space O(VÂ²), Edge check O(1), Neighbors O(V), All edges O(VÂ²)
ğ–¦¹ Adjacency List: Space O(V+E), Edge check O(deg(u)), Neighbors O(deg(u)), All edges O(V+E)
ğ–¦¹ Incidence Matrix: Space O(VÃ—E), Edge check O(E), Neighbors O(E), All edges O(VÃ—E)
ğ–¦¹ CSR: Space O(V+E), Edge check O(deg(u)), Neighbors O(deg(u)), All edges O(E)

15. Degree in a Graph
ğ–¦¹ Degree of a vertex = number of edges connected to it
ğ–¦¹ In undirected graphs, each edge counts for both connected vertices
ğ–¦¹ In directed graphs:
â€¢ In-degree = number of edges coming into the vertex
â€¢ Out-degree = number of edges going out from the vertex

16. Examples
ğ–¦¹ Directed Graph: Edges 1â†’2, 1â†’3, 2â†’3
â€¢ Vertex 1: Out-degree = 2, In-degree = 0
â€¢ Vertex 2: Out-degree = 1, In-degree = 1
â€¢ Vertex 3: Out-degree = 0, In-degree = 2
ğ–¦¹ Undirected Graph: Edges 1â€”2, 1â€”3, 2â€”3
â€¢ Vertex 1 degree = 2
â€¢ Vertex 2 degree = 2
â€¢ Vertex 3 degree = 2

17. Importance of Degree
ğ–¦¹ Shows how connected a vertex is
ğ–¦¹ Used in algorithms:
â€¢ Topological sort â†’ uses in-degree in directed graphs
â€¢ Euler path/cycle â†’ degree conditions decide existence
â€¢ Graph traversal â†’ vertices with higher degree may take longer to explore
--END--
--BEGIN--02/12/2025--TOPOLOGICAL SORT--
18. Topological Sort
ğ–¦¹ If there is an edge uâ†’v, then u must come before v in the order
ğ–¦¹ Works only for graphs with no cycles (DAGs)
â€¢ A cycle makes the order impossible because each node depends on another in a loop

19. Basic Idea
ğ–¦¹ Nodes with no incoming edges are the starting points
ğ–¦¹ Pick all zero-indegree nodes first
ğ–¦¹ After picking a node, remove it and its outgoing edges
â€¢ This may create new zero-indegree nodes
ğ–¦¹ Repeat until all nodes are processed or no zero-indegree node is left
ğ–¦¹ If nodes remain but none have indegree 0, a cycle exists and no valid order is possible
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/graphs/topological_sort_bruteforce.cpp

20. Kahnâ€™s Algorithm (BFS Style)
ğ–¦¹ Count indegree of each node once
ğ–¦¹ Put all zero-indegree nodes into a queue
ğ–¦¹ Remove nodes from queue one by one
â€¢ Reduce indegree of their neighbors
â€¢ When a neighborâ€™s indegree becomes zero, add it to the queue
ğ–¦¹ If all nodes are removed, order is valid; else, there is a cycle
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/graphs/topological_sort_khan.cpp

--END--
--BEGIN--02/12/2025--BFS AND DFS--
21. BFS
ğ–¦¹ BFS = Breadth-First Search; explores graph level by level like waves
ğ–¦¹ Start at one node:
â€¢ First explore nodes 1 step away
â€¢ Then nodes 2 steps away
â€¢ Then 3 steps away, and so on
ğ–¦¹ Finish one layer before moving to next
ğ–¦¹ BFS grows outward like ripples

22. Why Use a Queue
ğ–¦¹ Queue gives first-come, first-served order
ğ–¦¹ When a node is discovered, add to back
ğ–¦¹ When processing, take from front
ğ–¦¹ Ensures earliest discovered nodes are processed first â†’ level by level
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/graphs/bfs.cpp

23. What BFS Provides
ğ–¦¹ Order of node visits
ğ–¦¹ Shortest path in number of edges from start node
ğ–¦¹ Checks if graph is connected
â€¢ If some nodes are not reached, graph has unreachable parts

24. When BFS is Used
ğ–¦¹ Shortest path problems with equal edge weight
ğ–¦¹ Social networks (find people at distance 1,2,3â€¦)
ğ–¦¹ Level-order tree traversal
ğ–¦¹ Solving puzzles (Rubikâ€™s cube, sliding puzzles)
ğ–¦¹ Routing and networking

25. BFS Complexity
ğ–¦¹ Time = O(V + E)
ğ–¦¹ Space = O(V) (for queue and visited nodes)

26. DFS
ğ–¦¹ DFS = Depth-First Search; explores graph deep along a path before backtracking
ğ–¦¹ Like walking in a maze:
â€¢ Pick a path and follow it as far as possible
â€¢ If dead end, backtrack to previous junction
â€¢ Repeat until all paths explored

27. How DFS Works
ğ–¦¹ Start at a node and mark it visited
ğ–¦¹ Pick one unvisited neighbor and explore recursively
ğ–¦¹ Backtrack when no more unvisited neighbors
ğ–¦¹ Repeat until all reachable nodes are visited
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/graphs/dfs.cpp

28. Why a Stack is Used
ğ–¦¹ DFS can use recursion (call stack) or an explicit stack
ğ–¦¹ Stack remembers current path for correct backtracking
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/graphs/dfs_stack.cpp

29. What DFS Provides
ğ–¦¹ Order of nodes visited (depth-first)
ğ–¦¹ Can detect cycles
ğ–¦¹ Can classify edges: tree, back, forward, cross
ğ–¦¹ Helps in connected components, checking paths, and solving puzzles

30. DFS Complexity
ğ–¦¹ Time = O(V + E)
ğ–¦¹ Space = O(V) (for recursion stack or explicit stack)
--END--
--BEGIN--02/12/2025--SHORTEST PATH--
1. Shortest Path Problems
ğ–¦¹ A network of cities connected by roads can have costs like distance, time, or money
ğ–¦¹ A path = sequence of connected roads from one city to another
ğ–¦¹ Weighted path length = sum of all road costs
ğ–¦¹ Unweighted path length = number of roads only
ğ–¦¹ Single-source shortest path = find cheapest route from one city to all others
ğ–¦¹ Useful in real life:
â€¢ Sending data over networks
â€¢ Planning flight/train routes
â€¢ GPS navigation

2. Unweighted Shortest Path
ğ–¦¹ All roads considered equal or we care only about number of roads
ğ–¦¹ Start from source city, visit cities 1 road away, then 2 roads away, and so on
ğ–¦¹ Uses BFS:
â€¢ Start at source, distance = 0
â€¢ Visit neighbors, distance = 1
â€¢ Visit neighbors of neighbors, distance = 2
â€¢ Repeat until all reachable cities are visited
ğ–¦¹ Distance recorded is guaranteed shortest in terms of number of roads
ğ–¦¹ Time Complexity = O(V + E), Space Complexity = O(V)

3. Weighted Shortest Path
ğ–¦¹ Roads have different costs (weights)
ğ–¦¹ Positive weights only â†’ use Dijkstraâ€™s algorithm
â€¢ Pick city with smallest known cost, update neighbors
ğ–¦¹ Negative weights allowed â†’ use Bellman-Ford algorithm
â€¢ Handles negative cycles, but shortest path may not exist if negative cycle exists
ğ–¦¹ Useful for:
â€¢ Roads with tolls or different travel times
â€¢ Optimizing network traffic with varying link costs
â€¢ Scheduling tasks with dependencies and costs
ğ–¦¹ Time & Space Complexity:
â€¢ Dijkstra (with min-heap) â†’ Time O((V+E) log V), Space O(V)
â€¢ Bellman-Ford â†’ Time O(VE), Space O(V)
--END--

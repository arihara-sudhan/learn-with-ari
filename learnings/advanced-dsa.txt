IMG_URL sparse_array.png
1. Sparse Arrays
ð–¦¹ Concept: An array where most elements are zero or "empty" (null, None, etc.)
ð–¦¹ Example:
â€¢ Regular array: [0, 0, 0, 5, 0, 0, 0, 0, 0, 10]
â€¢ Sparse array: Only non-zero values stored: index 3 â†’ 5, index 9 â†’ 10
ð–¦¹ Reason: Storing lots of zeros wastes memory, especially in large arrays

2. Problem with Regular Arrays
ð–¦¹ Memory wasted storing zeros
ð–¦¹ Operations like traversal or copying waste time on zeros
ð–¦¹ Large arrays may exceed memory capacity if most entries are empty

3. Solution: Store only non-empty elements
ð–¦¹ Store only non-zero or meaningful elements with their indices
ð–¦¹ Reduces memory usage drastically

4. Implementations
ð–¦¹ Hash Map / Dictionary
â€¢ Idea: Use key = index, value = non-zero element
â€¢ Example in C++:
<pink>unordered_map</pink><yellow><int,int> sparse_dict;</yellow>
<pink>int</pink> arr[10] = {0,0,0,5,0,0,0,0,0,10};
sparse_dict[3] = 5;
sparse_dict[9] = 10;
<pink>int</pink> i = 3;
<pink>int</pink> value = sparse_dict.count(i) ? sparse_dict[i] : 0; // returns 5
â€¢ Pros: Fast lookups O(1), no memory wasted on zeros
â€¢ Cons: Hash table overhead (extra memory for keys and structure)
ð–¦¹ List of Tuples (Index-Value Pairs)
â€¢ Idea: Store as a list of (index, value) pairs sorted by index
â€¢ Example in C++:
<pink>vector</pink><yellow><pair<int,int>> sparse_list = {{3,5},{9,10}};</yellow>
<pink>int</pink> get_value(<pink>int</pink> i){
  <pink>for</pink>(auto [idx,val] : sparse_list){
    <pink>if</pink>(idx == i) <pink>return</pink> val;
  }
  <pink>return</pink> 0;
}
â€¢ Pros: Minimal memory overhead
â€¢ Cons: Access time O(n) if unsorted, O(log n) if sorted + binary search
ð–¦¹ Compressed Storage Techniques
â€¢ Compressed Row Storage (CRS) / Compressed Column Storage (CCS)
â€¢ Store non-zero values, row/column indices, pointers to start of each row/column
â€¢ Efficient for matrix operations in scientific computing or graph algorithms

5. Advantages
ð–¦¹ Saves memory drastically for large arrays with few non-zero elements
ð–¦¹ Faster iteration over only meaningful elements
ð–¦¹ Can handle datasets too large for memory in dense form

6. Applications
ð–¦¹ Graph adjacency matrices: Most graphs are sparse
â€¢ Example: Social network with millions of users â†’ most pairs not connected
ð–¦¹ Scientific computations: Matrices in physics, chemistry, engineering
ð–¦¹ Machine learning: Sparse feature vectors in NLP, recommendation systems

7. Memory Comparison
ð–¦¹ Dense Array: 1M elements â†’ memory wasted = 1M Ã— size_of(int)
ð–¦¹ Sparse Dict: 10 non-zero â†’ memory used = 10 Ã— (index + value) + hash overhead
ð–¦¹ Huge saving when non-zero elements << total size

8. Key Takeaways
ð–¦¹ Sparse arrays are memory-efficient
ð–¦¹ Storage choice depends on lookup vs iteration needs
â€¢ Dictionary â†’ fast random access
â€¢ List of tuples â†’ less memory, slower access
â€¢ CRS / CCS â†’ optimized for matrix operations

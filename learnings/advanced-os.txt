--BEGIN--12/03/2025--OPERATING SYSTEM--
1. What OS does?
ğ–¦¹ Hardware, operating system, application programs, and users
ğ–¦¹ Hardware gives raw power
ğ–¦¹ Applications do the userâ€™s tasks
ğ–¦¹ OS manages hardware so all apps can use it smoothly
ğ–¦¹ Hardware, software, and data
ğ–¦¹ OS gives a good place for everything to work well
ğ–¦¹ OS is like a government
â€¢ It does not do the actual work
â€¢ It allows others to work safely and fast

2. User view of an operating system
ğ–¦¹ What the user sees changes with the device
ğ–¦¹ Personal computers or laptops
â€¢ One user often uses the whole system
â€¢ OS is made for easy use
â€¢ Less focus on sharing resources
ğ–¦¹ Mobile phones or tablets
â€¢ Touch, gestures, voice helpers
â€¢ Apps run with more limits
ğ–¦¹ Embedded systems (cars, appliances)
â€¢ Very small or no user interface
â€¢ OS runs by itself with little user control

3. System view of an operating system
ğ–¦¹ OS is a resource allocator
â€¢ Manages CPU time, memory, I/O devices, and storage
â€¢ Must give resources fairly and efficiently
ğ–¦¹ OS is also a control program
â€¢ Controls running of user programs
â€¢ Controls I/O operations
â€¢ Stops errors and misuse

4. Defining an operating system
ğ–¦¹ No single perfect definition
â€¢ Computers are used everywhere
â€¢ Different devices have different needs
â€¢ OS designs are very different
ğ–¦¹ What is part of the OS?
â€¢ One idea: everything that comes when you install an OS
â€¢ More accepted idea: OS = kernel + system programs (not apps)

5. Kernel, system programs, and application programs
ğ–¦¹ Kernel
â€¢ Main part that is always running
ğ–¦¹ System programs
â€¢ Tools like file managers, shells, editors
ğ–¦¹ Application programs
â€¢ Things like browsers, games, IDEs

6. Modern operating systems
ğ–¦¹ Include kernel and middleware
â€¢ Middleware = extra frameworks like graphics and multimedia
--END--
--BEGIN--12/03/2025--INTERRUPTS--
1. Interrupts
ğ–¦¹ Interrupt is a signal that tells the CPU to stop and handle something important
ğ–¦¹ Example: you press a key â†’ keyboard sends interrupt â†’ CPU stops current work â†’ reads the key
ğ–¦¹ Normal I/O flow
â€¢ OS driver tells controller to start I/O
â€¢ Controller works and fills its buffer
â€¢ When done, controller sends interrupt
â€¢ CPU runs the interrupt service routine (ISR) and then returns to old work
ğ–¦¹ Interrupt can mean work finished or an error happened

2. Overview of how interrupts work
ğ–¦¹ Interrupt can happen anytime
ğ–¦¹ When CPU gets an interrupt, it pauses the program and jumps to a fixed place in memory
ğ–¦¹ That place stores the address of the interrupt handler
ğ–¦¹ Handler runs and CPU returns to the paused point
ğ–¦¹ Interrupt vector table helps CPU find the correct handler
â€¢ Table in low memory with addresses of all handlers
â€¢ Example: 0 for divide error, 14 for page fault, 32+ for device interrupts
ğ–¦¹ CPU must save program counter, registers, and flags so it can restore them later

3. Implementation of interrupts
ğ–¦¹ CPU checks the interrupt-request line after each instruction
ğ–¦¹ If device raises interrupt, CPU reads interrupt number and finds handler in vector table
ğ–¦¹ CPU saves current state, runs the handler, restores state, and returns
ğ–¦¹ Simple steps: raise â†’ catch â†’ handle â†’ clear â†’ resume
ğ–¦¹ OS needs extra features
â€¢ Ability to disable interrupts for short time to avoid data issues
â€¢ Fast way to find correct handler (vectored interrupts)
â€¢ Priority levels so urgent interrupts stop less urgent ones
- Example: memory error is high priority, mouse movement is low priority

4. Maskable and non-maskable interrupts
ğ–¦¹ Non-maskable interrupt (NMI)
â€¢ CPU cannot ignore it
â€¢ Used for serious problems like memory errors
ğ–¦¹ Maskable interrupt
â€¢ CPU can disable it when needed
â€¢ Used for normal devices like disk and keyboard

5. Interrupt chaining
ğ–¦¹ Sometimes there are more devices than vector-table entries
ğ–¦¹ One entry may point to a list of handlers
ğ–¦¹ CPU runs handlers in order until one handles the device interrupt

6. Interrupt vector numbers and priority
ğ–¦¹ Vector range 0â€“31 is for CPU errors
ğ–¦¹ Vector range 32â€“255 is for device interrupts
ğ–¦¹ High-priority interrupts can interrupt low-priority ones
ğ–¦¹ This makes sure urgent tasks happen first
--END--
--BEGIN--12/03/2025--STORAGE STRUCTURE--
1. Storage structure
ğ–¦¹ Computer needs memory to run programs
ğ–¦¹ CPU can run instructions only from memory
ğ–¦¹ So every program must be loaded into memory before running

2. Main memory (RAM)
ğ–¦¹ RAM is fast, readable, and writable
ğ–¦¹ Stores programs while they run
ğ–¦¹ Built using DRAM
ğ–¦¹ RAM is volatile
â€¢ Loses all data when power goes off

3. Bootstrap programs
ğ–¦¹ When system starts, RAM is empty
ğ–¦¹ First program (bootstrap) cannot be inside RAM
ğ–¦¹ Stored in non-volatile memory like EEPROM
â€¢ EEPROM is slow and cannot be erased often
â€¢ Keeps data even without power
ğ–¦¹ RAM is fast and temporary, EEPROM is slow and permanent

4. Storage building blocks
ğ–¦¹ Bit is the smallest unit (0 or 1)
ğ–¦¹ Byte is 8 bits and is the basic move unit for CPU
ğ–¦¹ Word is CPUâ€™s natural data size (like 32-bit or 64-bit)
ğ–¦¹ Memory sizes
â€¢ KB = 1024 bytes
â€¢ MB = 1024Â² bytes
â€¢ GB = 1024Â³ bytes
â€¢ TB = 1024â´ bytes
â€¢ PB = 1024âµ bytes
- Companies often round using 1000
- Networking counts in bits

5. How CPU uses memory
ğ–¦¹ Memory is an array of bytes, each with an address
ğ–¦¹ CPU uses load and store instructions
â€¢ load: memory â†’ register
â€¢ store: register â†’ memory
ğ–¦¹ CPU fetches instructions using program counter

6. Instruction cycle
ğ–¦¹ Fetch instruction
ğ–¦¹ Decode instruction
ğ–¦¹ Fetch operands if needed
ğ–¦¹ Execute
ğ–¦¹ Store result if needed
ğ–¦¹ Memory only receives addresses; it does not know if they are instructions or data

7. Need for secondary storage
ğ–¦¹ RAM is small and volatile
ğ–¦¹ So we need long-term storage like HDD and SSD
ğ–¦¹ Programs stay in secondary storage â†’ loaded into RAM â†’ run

8. Storage types in a system
ğ–¦¹ Registers: inside CPU, smallest and fastest
ğ–¦¹ Cache: between CPU and RAM, very fast (L1, L2, L3)
ğ–¦¹ RAM: fast and volatile
ğ–¦¹ Non-volatile memory (SSD, flash): slower than RAM, keeps data after power off
ğ–¦¹ Hard Disk: slower but large
ğ–¦¹ Optical disk, tape: very slow, used for backup

9. Storage hierarchy
ğ–¦¹ Rule: closer to CPU = faster, smaller, more costly
ğ–¦¹ Order:
â€¢ Registers
â€¢ Cache
â€¢ Main memory
â€¢ NVM (SSD, flash)
â€¢ HDD
â€¢ Optical disk
â€¢ Magnetic tapes
ğ–¦¹ Volatile: registers, cache, RAM
ğ–¦¹ Non-volatile: SSD, HDD, optical, tapes

10. Volatile vs non-volatile terms
ğ–¦¹ Memory = volatile storage (registers, cache, RAM)
ğ–¦¹ NVS = non-volatile storage (HDD, SSD, flash)
ğ–¦¹ Mechanical NVS: HDD, optical, tape
â€¢ Cheap, large, slow
ğ–¦¹ Electrical NVS: SSD, flash, FRAM, NRAM
â€¢ Fast, small, expensive

11. Why caches are used
ğ–¦¹ Large speed gap exists between levels like RAM and HDD
ğ–¦¹ Cache holds recently used data so CPU can access it faster
--END--
--BEGIN--12/03/2025--COMPUTER SYSTEM ARCH--
1. Computer-system architecture
ğ–¦¹ Computer can be built in many ways based on how many general-purpose processors it has
ğ–¦¹ Three types: single-processor, multiprocessor, clustered systems

2. Single-processor systems
ğ–¦¹ Have one main CPU core that runs programs and OS work
ğ–¦¹ System may also have small helper processors
â€¢ Disk, keyboard, graphics controllers
â€¢ These do small fixed tasks, not full programs
ğ–¦¹ Still called single-processor if there is only one main CPU core
ğ–¦¹ True single-processor systems are rare today

3. Multiprocessor systems
ğ–¦¹ Have two or more processors
ğ–¦¹ Earlier: many chips, each chip had one core
ğ–¦¹ All processors share bus, memory, and I/O
ğ–¦¹ Used to increase total work done
ğ–¦¹ Speed does not grow exactly N times for N processors

4. Symmetric multiprocessing (SMP)
ğ–¦¹ All processors are equal
ğ–¦¹ Any processor can run OS tasks or user processes
ğ–¦¹ Each CPU has its own registers and private cache
ğ–¦¹ All CPUs share main memory
ğ–¦¹ N processes can run in parallel on N CPUs
ğ–¦¹ OS must balance load so no CPU is idle

5. Multicore systems
ğ–¦¹ One chip contains multiple CPU cores
ğ–¦¹ Cores talk faster since they are on same chip
ğ–¦¹ Uses less power and space
ğ–¦¹ Example: dual-core has two cores with private L1 caches and shared L2
ğ–¦¹ OS sees a chip with N cores as N CPUs

6. NUMA systems
ğ–¦¹ Many CPUs can make one main bus too slow
ğ–¦¹ Fix: give each CPU or CPU group its own local memory
ğ–¦¹ CPUs linked by high-speed interconnect
ğ–¦¹ All share same address space
ğ–¦¹ Local memory is faster than remote memory (non-uniform access)
ğ–¦¹ OS must place tasks near their memory to avoid slowdowns

7. Blade servers
ğ–¦¹ Many small computer boards kept in one chassis
ğ–¦¹ Each blade has CPU, memory, and its own OS
ğ–¦¹ Some blades may also be multiprocessor systems
ğ–¦¹ Works like many independent computers inside one box

8. Clustered systems
ğ–¦¹ A cluster is many separate computers (nodes) connected together
ğ–¦¹ Different from multiprocessors: multiprocessor = many CPUs in one system; cluster = many systems connected by network
ğ–¦¹ Nodes are often multicore and share storage
ğ–¦¹ Connected through LAN or fast networks

9. High availability clusters
ğ–¦¹ Used when services must stay running
ğ–¦¹ Nodes watch each other
ğ–¦¹ If one fails, another node takes over quickly
ğ–¦¹ Users see only a short break
ğ–¦¹ System that keeps running even after failure is fault-tolerant

10. Types of clustering
ğ–¦¹ Asymmetric clustering
â€¢ One active node
â€¢ One standby node
â€¢ Standby becomes active if main fails
ğ–¦¹ Symmetric clustering
â€¢ Many active nodes
â€¢ All run applications
â€¢ All watch each other
â€¢ More efficient

11. High-performance clusters
ğ–¦¹ Used for scientific work, simulations, and big data
ğ–¦¹ Work must be split among nodes
ğ–¦¹ Each node solves a part and results are combined

12. Parallel clusters
ğ–¦¹ Many nodes access the same shared storage
ğ–¦¹ Needs special OS or software to avoid conflicts
ğ–¦¹ Uses lock managers to manage shared data

13. Modern clusters
ğ–¦¹ Can have thousands of nodes
ğ–¦¹ Nodes can be far apart
ğ–¦¹ Use shared storage systems like SAN
ğ–¦¹ Any node can run any app from SAN
ğ–¦¹ If one node fails, another takes over instantly
--END--

--BEGIN--24/11/2025--HEAPS--
1. Heaps
IMG_URL heaps.png
ð–¦¹ A heap is a tree where each parent is more important than its children
ð–¦¹ More important means smaller (min-heap) or larger (max-heap)
ð–¦¹ Two rules must always hold
â€¢ Shape rule: tree must be a complete binary tree (filled left to right)
â€¢ Order rule: parent must follow heap property (â‰¤ for min-heap, â‰¥ for max-heap)
- Explanation: if any rule breaks, the tree stops being a heap
ð–¦¹ A heap only checks parent-child order, not brother-brother order
ð–¦¹ Because of this, a heap is not a sorted tree

2. Max heap example
ð–¦¹ Parent is always â‰¥ children
ð–¦¹ Example tree
â€¢       100
        /   \
      50    90
     / \
    30 20

3. Min heap example
ð–¦¹ Parent is always â‰¤ children
ð–¦¹ Example tree
â€¢       5
      /   \
     7     9
    / \
   8  10
- Explanation: 5 â‰¤ 7, 5 â‰¤ 9, 7 â‰¤ 8, 7 â‰¤ 10

4. Heap as Array form
ð–¦¹ A min-heap stored in array form
â€¢ Index: 1 2 3 4 5 6 7
â€¢ Value: 2 5 6 8 9 10 11
ð–¦¹ Same tree shape using array positions
ROOT: FLOOR[(i-1)/2]

5. Pop operation idea (Extract-min)
ð–¦¹ Remove root (minimum element)
ð–¦¹ Move last element to root
ð–¦¹ Heapify down to fix heap property

6. First pop
        2
      /    \
     5      6
    / \    / \ 
   8  9  10   11
ð–¦¹ Remove 2 and move 11 to root
ð–¦¹ Heapify by swapping with smaller child until property holds
ð–¦¹ Tree after moving 11:
        11
      /    \
     5      6
    / \    / 
   8  9  10
ð–¦¹ After swaps:
        5
      /    \
     8      6
    / \    / 
   11 9  10
â€¢ Final array: 5 8 6 11 9 10

7. Second pop
ð–¦¹ Remove 5 and move 10 to root
ð–¦¹ Tree after moving 10:
        10
      /    \
     8      6
    / \    
   11 9  
ð–¦¹ Swap with smaller child 6:
        6
      /    \
     8      10
    / \    
   11 9  
â€¢ Final array: 6 8 10 11 9

8. Third pop
ð–¦¹ Remove 6 and move 9 to root
ð–¦¹ Tree:
        9
      /   \
     8     10
    /  
   11     
ð–¦¹ Swap with 8:
        8
      /   \
     9     10
    /      
   11     
â€¢ Final array: 8 9 10 11

9. Fourth pop
ð–¦¹ Remove 8 and move 11 to root
ð–¦¹ Tree:
        11
      /   \
     9     10
ð–¦¹ Swap with 9:
        9
      /   \
    11     10
â€¢ Final array: 9 11 10

10. Fifth pop
ð–¦¹ Remove 9 and move 10 to root
ð–¦¹ Tree:
      10
     /
    11
ð–¦¹ 10 already satisfies heap property
â€¢ Final array: 10 11

11. Sixth pop
ð–¦¹ Remove 10 and move 11 to root
ð–¦¹ Tree:
      11
ð–¦¹ No children, heap is fine
â€¢ Final array: 11

12. Seventh pop
ð–¦¹ Remove 11
ð–¦¹ Heap becomes empty

13. Final pop order
ð–¦¹ Values removed one by one in order
â€¢ 2, 5, 6, 8, 9, 10, 11
- Explanation: min-heap gives ascending order when popping

14. MinHeap
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/heaps/min_heap.cpp

15. MaxHeap code
--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/heaps/max_heap.cpp
--END--

--BEGIN--24/11/2025--TREES--
1. Trees
ð–¦¹ A tree organizes data in a hierarchy like a family tree or company structure
ð–¦¹ It has nodes (data points) and edges/arcs (connections between nodes)
ð–¦¹ The root is the top node and has no parent
ð–¦¹ Leaves are nodes with no children
ð–¦¹ A path is the sequence of edges from the root to a node
ð–¦¹ The level of a node is its distance from the root (root = level 1)
ð–¦¹ The height of a tree is the largest level in the tree
â€¢ Example:
- Root (level 1)
  â”œâ”€ Child 1 (level 2)
  â””â”€ Child 2 (level 2)

2. Why use trees instead of lists
ð–¦¹ In a linked list, finding an element may require checking every node
ð–¦¹ Trees can make searching faster if organized properly
â€¢ Especially ordered trees

3. Binary Trees
ð–¦¹ A binary tree is a tree where each node has at most two children: left and right
â€¢ Example:
-       10
        /  \
       5    15
ð–¦¹ Complete binary tree: all levels full except possibly last, nodes as far left as possible
ð–¦¹ Number of nodes at level i is at most 2^i

4. Binary Search Trees (BSTs)
ð–¦¹ A BST is a binary tree with an ordering rule:
â€¢ Left child < parent
â€¢ Right child > parent
ð–¦¹ Ordering makes searching, inserting, deleting faster
â€¢ Example:
-        10
         /  \
        5    20
       / \   / \
      2   7 15 25
ð–¦¹ Searching is efficient because at each step you choose left or right instead of checking all nodes

5. Tree Traversals
ð–¦¹ There are three main recursive traversals and one level-order traversal
â€¢ Preorder: visits root first, then recursively goes left and right
â€¢ Inorder: goes all the way left, backtracks to root, then goes right
â€¢ Postorder: goes all the way left and right, then backtracks to visit root
â€¢ Level-order: visits nodes level by level; uses BFS, useful for shortest path
ð–¦¹ Example tree:
          50
        /    \
      30      70
     /  \    /  \
   20   40  60   80
  /         \      \
10          65      90

ð–¦¹ Traversals for the tree:
â€¢ PREORDER: 50 â†’ 30 â†’ 20 â†’ 10 â†’ 40 â†’ 70 â†’ 60 â†’ 65 â†’ 80 â†’ 90
â€¢ INORDER: 10 â†’ 20 â†’ 30 â†’ 40 â†’ 50 â†’ 60 â†’ 65 â†’ 70 â†’ 80 â†’ 90
â€¢ POSTORDER: 10 â†’ 20 â†’ 40 â†’ 30 â†’ 65 â†’ 60 â†’ 80 â†’ 90 â†’ 70 â†’ 50
â€¢ LEVELORDER: 50 â†’ 30 â†’ 70 â†’ 20 â†’ 40 â†’ 60 â†’ 80 â†’ 10 â†’ 65 â†’ 90

ITERATIVE INORDER AND POSTORDER ROUTINES:
[pink]void[/pink] [yellow]iterativeInorder[/yellow]([blue]BSTNode*[/blue] [yellow]root[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink];
    [green]stack[/green]<[blue]BSTNode*[/blue]> [yellow]s[/yellow];
    [blue]BSTNode*[/blue] [yellow]curr[/yellow] = [yellow]root[/yellow];

    [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green] || ![yellow]s[/yellow].[green]empty[/green]()) {
        // Go as left as possible
        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [yellow]s[/yellow].[green]push[/green]([yellow]curr[/yellow]);
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]left[/yellow];
        }
        // Pop and visit
        [yellow]curr[/yellow] = [yellow]s[/yellow].[green]top[/green]();
        [yellow]s[/yellow].[green]pop[/green]();
        [green]cout[/green] << [yellow]curr[/yellow]->[yellow]key[/yellow] << " ";
        // Go right
        [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]right[/yellow];
    }
}

[pink]void[/pink] [yellow]iterativePostorder[/yellow]([blue]BSTNode*[/blue] [yellow]root[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink];
    [green]stack[/green]<[blue]BSTNode*[/blue]> [yellow]s[/yellow];
    [blue]BSTNode*[/blue] [yellow]curr[/yellow] = [yellow]root[/yellow];
    [blue]BSTNode*[/blue] [yellow]lastVisited[/yellow] = [green]nullptr[/green];

    [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green] || ![yellow]s[/yellow].[green]empty[/green]()) {
        [pink]while[/pink] ([yellow]curr[/yellow] != [green]nullptr[/green]) {
            [yellow]s[/yellow].[green]push[/green]([yellow]curr[/yellow]);
            [yellow]curr[/yellow] = [yellow]curr[/yellow]->[yellow]left[/yellow];
        }

        [blue]BSTNode*[/blue] [yellow]topNode[/yellow] = [yellow]s[/yellow].[green]top[/green]();

        [pink]if[/pink] ([yellow]topNode[/yellow]->[yellow]right[/yellow] != [green]nullptr[/green] && [yellow]lastVisited[/yellow] != [yellow]topNode[/yellow]->[yellow]right[/yellow]) {
            [yellow]curr[/yellow] = [yellow]topNode[/yellow]->[yellow]right[/yellow];
        } [pink]else[/pink] {
            [green]cout[/green] << [yellow]topNode[/yellow]->[yellow]key[/yellow] << " ";
            [yellow]lastVisited[/yellow] = [yellow]topNode[/yellow];
            [yellow]s[/yellow].[green]pop[/green]();
        }
    }
}
--END--
--BEGIN--24/11/2025--BINARY SEARCH TREE--
1. Binary Search Tree (BST)
ð–¦¹ A BST is a special binary tree where each node has at most two children
ð–¦¹ BST property:
â€¢ All keys in the left subtree of a node are less than the nodeâ€™s key
â€¢ All keys in the right subtree of a node are greater than the nodeâ€™s key
â€¢ This property holds recursively â€” left and right subtrees are also BSTs
ð–¦¹ Usually, BSTs do not allow duplicate values or handle them in a specific way

ð–¦¹ Why use a BST?
â€¢ Efficient search, insertion, and deletion: ordering property allows skipping large parts of the tree
â€¢ Sorted data: in-order traversal returns keys in sorted order
â€¢ Dynamic structure: nodes can be inserted or removed, tree grows or shrinks
â€¢ Used in symbol tables and associative arrays
          50
        /    \
      30      70
     /  \    /  \
   20   40  60   80
  /             /  \
10             75   90

ð–¦¹ Operations on a BST
â€¢ Search:
- Start at root
- Compare target key with current node
- If equal â†’ found
- If less â†’ go left
- If greater â†’ go right
- Repeat until found or null
â€¢ Insertion:
- Find correct leaf position comparing keys
- Insert new node while preserving BST property
â€¢ Deletion:
- No child (leaf): remove node
- One child: replace node with its child
- Two children: replace node with minimum in right subtree (successor) or maximum in left subtree (predecessor), then delete that node
â€¢ Traversal:
- Can traverse in inorder, preorder, postorder
- Inorder is useful because it returns sorted keys

ð–¦¹ Time & Space Complexity
â€¢ Search / Insert / Delete (average case): O(h), where h = height of BST
â€¢ Balanced BST: height h â‰ˆ O(log n), average complexity O(log n)
â€¢ Worst case (skewed BST): height h = n, operations O(n)
â€¢ Space for recursion: O(n) in worst case due to call stack

ð–¦¹ Limitations / Disadvantages
â€¢ Unbalanced BSTs degrade performance (search, insert, delete â†’ O(n))
â€¢ Managing duplicates can be tricky
â€¢ Guaranteed performance may require self-balancing BSTs like AVL trees or Red-Black trees

2. BST Operations: Insert, Search, Delete
ð–¦¹ Example BST:
          50
        /    \
      30      70
     /  \    /  \
   20   40  60   80
	         \      \
	          65      90

ð–¦¹ Delete
â€¢ Three cases:
- Node is a leaf â†’ delete it
- Node has one child â†’ replace node with child
- Node has two children â†’ replace node with inorder successor (smallest in right subtree) or predecessor (largest in left subtree), then delete that node

--EMBED-GIT--
https://github.com/arihara-sudhan/dsa/blob/main/data-structures/trees/bst.cpp
3. BST Complexity
ð–¦¹ Search
â€¢ Can be done recursively or iteratively
â€¢ Logic: start at [yellow]root[/yellow], go left if key is smaller, right if key is larger
â€¢ Time Complexity
  - Best/Average (balanced BST): O(log n)
  - Worst (skewed tree): O(n)
ð–¦¹ Insertion
â€¢ Find correct place according to BST property and insert new node
â€¢ Can be recursive or iterative
â€¢ Time Complexity
  - Best/Average (balanced BST): O(log n)
  - Worst (skewed tree): O(n)
ð–¦¹ Deletion
â€¢ Handle 3 cases
  â€¢ Node is leaf â†’ delete directly
  â€¢ Node has one child â†’ replace node with its child
  â€¢ Node has two children â†’ replace with inorder successor or predecessor, then delete that node
â€¢ Time Complexity
  - Best/Average (balanced BST): O(log n)
  - Worst (skewed tree): O(n)
ð–¦¹ Traversals
â€¢ Preorder ([pink]Root[/pink] â†’ [pink]Left[/pink] â†’ [pink]Right[/pink])
  - Visit all nodes recursively
  - Time Complexity: O(n)
â€¢ Inorder ([pink]Left[/pink] â†’ [pink]Root[/pink] â†’ [pink]Right[/pink])
  - Visit all nodes recursively
  - Time Complexity: O(n)
â€¢ Postorder ([pink]Left[/pink] â†’ [pink]Right[/pink] â†’ [pink]Root[/pink])
  - Visit all nodes recursively
  - Time Complexity: O(n)
â€¢ Level-order (Breadth-first using [green]queue[/green])
  - Visit all nodes level by level
  - Time Complexity: O(n)
ð–¦¹ Space Complexity
â€¢ Preorder/Inorder/Postorder (recursive): O(h), h = tree height
â€¢ Level-order (using [green]queue[/green]): O(width), width = max nodes at any level
ð–¦¹ TL;DR
â€¢ Search: Best/Average O(log n), Worst O(n)
â€¢ Insert: Best/Average O(log n), Worst O(n)
â€¢ Delete: Best/Average O(log n), Worst O(n)
â€¢ Preorder: O(n), O(n)
â€¢ Inorder: O(n), O(n)
â€¢ Postorder: O(n), O(n)
â€¢ Level-order: O(n), O(n)
--END--
--BEGIN--24/11/2025--BALANCING TREES--
1. Why Balance a Tree
ð–¦¹ Trees make searching faster than linked lists
ð–¦¹ Lopsided trees act like linked lists â†’ searching becomes slow
â€¢ Example: inserting elements in ascending order â†’ tree becomes long chain
ð–¦¹ Balanced tree
â€¢ Keeps height difference between left and right subtrees â‰¤ 1
â€¢ Perfectly balanced tree: all levels fully filled except maybe last
â€¢ Searching is fast because tree height is minimal
â€¢ Formula: Max nodes in tree of height h â†’ 2^h - 1
â€¢ Example: 10,000 elements â†’ balanced tree height â‰ˆ 14 â†’ only 14 comparisons needed
â€¢ Linked list â†’ worst case 10,000 comparisons
ð–¦¹ How to build a balanced tree
â€¢ Sort data first (if not already sorted)
â€¢ Pick middle element â†’ root
â€¢ Divide array into left half and right half
â€¢ Middle of left â†’ left child
â€¢ Middle of right â†’ right child
â€¢ Repeat recursively for all subarrays until all elements inserted
ð–¦¹ Balancing BST: Code Example
[green]#include[/green] <iostream>
[green]using namespace[/green] std;
// Node of BST
[pink]struct[/pink] [yellow]BSTNode[/yellow] {
    [pink]int[/pink] [yellow]key[/yellow];
    [blue]BSTNode*[/blue] [yellow]left[/yellow];
    [blue]BSTNode*[/blue] [yellow]right[/yellow];
    [yellow]BSTNode[/yellow]([pink]int[/pink] [yellow]k[/yellow]) : [yellow]key[/yellow]([yellow]k[/yellow]), [yellow]left[/yellow]([green]nullptr[/green]), [yellow]right[/yellow]([green]nullptr[/green]) {}
};
// BST root
[blue]BSTNode*[/blue] [yellow]root[/yellow] = [green]nullptr[/green];
// Insert function for BST
[blue]BSTNode*[/blue] [yellow]insert[/yellow]([blue]BSTNode*[/blue] [yellow]node[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink]([yellow]node[/yellow] == [green]nullptr[/green]) {
        [pink]return[/pink] [pink]new[/pink] [yellow]BSTNode[/yellow]([yellow]key[/yellow]); // create new node
    }
    [pink]if[/pink]([yellow]key[/yellow] < [yellow]node[/yellow]->key) {
        [yellow]node[/yellow]->left = [yellow]insert[/yellow]([yellow]node[/yellow]->left, [yellow]key[/yellow]);
    } [pink]else if[/pink]([yellow]key[/yellow] > [yellow]node[/yellow]->key) {
        [yellow]node[/yellow]->right = [yellow]insert[/yellow]([yellow]node[/yellow]->right, [yellow]key[/yellow]);
    }
    [pink]return[/pink] [yellow]node[/yellow];
}
// Wrapper insert to use global root
[pink]void[/pink] [yellow]insert[/yellow]([pink]int[/pink] [yellow]key[/yellow]) {
    [yellow]root[/yellow] = [yellow]insert[/yellow]([yellow]root[/yellow], [yellow]key[/yellow]);
}
// Build balanced BST from sorted array
[pink]void[/pink] [yellow]balance[/yellow]([pink]int[/pink] [yellow]data[/yellow][], [pink]int[/pink] [yellow]first[/yellow], [pink]int[/pink] [yellow]last[/yellow]) {
    [pink]if[/pink]([yellow]first[/yellow] <= [yellow]last[/yellow]) {
        [pink]int[/pink] [yellow]middle[/yellow] = ([yellow]first[/yellow] + [yellow]last[/yellow]) / 2;
        [yellow]insert[/yellow]([yellow]data[/yellow][[yellow]middle[/yellow]]);             // insert middle as root/subroot
        [yellow]balance[/yellow]([yellow]data[/yellow], [yellow]first[/yellow], [yellow]middle[/yellow] - 1);  // left subtree
        [yellow]balance[/yellow]([yellow]data[/yellow], [yellow]middle[/yellow] + 1, [yellow]last[/yellow]);   // right subtree
    }
}
// Inorder traversal to verify BST
[pink]void[/pink] [yellow]inorder[/yellow]([blue]BSTNode*[/blue] [yellow]node[/yellow]) {
    [pink]if[/pink](![yellow]node[/yellow]) [pink]return[/pink];
    [yellow]inorder[/yellow]([yellow]node[/yellow]->left);
    [green]cout[/green] << [yellow]node[/yellow]->key << " ";
    [yellow]inorder[/yellow]([yellow]node[/yellow]->right);
}
[pink]int[/pink] [pink]main[/pink]() {
    [pink]int[/pink] [yellow]data[/yellow][] = {0,1,2,3,4,5,6,7,8,9}; // sorted array
    [pink]int[/pink] [yellow]n[/yellow] = sizeof([yellow]data[/yellow]) / sizeof([yellow]data[/yellow][0]);

    [yellow]balance[/yellow]([yellow]data[/yellow], 0, [yellow]n[/yellow] - 1);  // build balanced BST

    [green]cout[/green] << "Inorder of balanced BST: ";
    [yellow]inorder[/yellow]([yellow]root[/yellow]);
    [green]cout[/green] << endl;

    [pink]return[/pink] 0;
}
--END--
--BEGIN--24/11/2025--AVL TREES--
1. AVL Tree Basics
ð–¦¹ An AVL tree is a binary search tree that keeps itself balanced.
ð–¦¹ Balance is important because a long, skinny tree makes searching slow.
â€¢ Balanced trees keep search fast: O(log n) time.
ð–¦¹ AVL trees fix themselves after inserting or deleting nodes.

2. AVL Tree Rules
ð–¦¹ AVL = BST + height rule
ð–¦¹ Must satisfy BST ordering.
ð–¦¹ Balance rule: For every node, |height(left) â€“ height(right)| â‰¤ 1
â€¢ Difference is called balance factor: balance factor = height(right) â€“ height(left)
â€¢ Allowed values: â€“1, 0, +1
ð–¦¹ If balance factor becomes â€“2 or +2 â†’ tree is unbalanced and must be fixed.

3. When AVL Tree Needs Fixing
ð–¦¹ Tree becomes unbalanced after inserting or deleting a node.
ð–¦¹ There are 4 rotation cases (2 main + 2 mirror images).

4. LL Rotation (Left-Left)
ð–¦¹ Happens when insertion is in left subtree of left child.
â€¢ Fix: Right rotation on P
BEFORE
      P
     /
    Q
   /
  R
AFTER
      Q
     / \
    R   P

5. RR Rotation (Right-Right)
ð–¦¹ Happens when insertion is in right subtree of right child.
â€¢ Fix: Left rotation on P
BEFORE
  P
   \
    Q
     \
      R
AFTER
      Q
     / \
    P   R

6. LR Rotation (Left-Right)
ð–¦¹ Happens when insertion is in right subtree of left child.
â€¢ Fix: Double rotation â†’ Left rotation on Q, Right rotation on P
BEFORE
      P
     /
    Q
     \
      R
AFTER
      R
     / \
    Q   P

7. RL Rotation (Right-Left)
ð–¦¹ Happens when insertion is in left subtree of right child.
â€¢ Fix: Double rotation â†’ Right rotation on Q, Left rotation on P
BEFORE
    P
     \
      Q
     /
    R
AFTER
      R
     / \
    P   Q

8. Rotation Summary
ð–¦¹ LL: Right rotate P â†’ Root becomes Q
ð–¦¹ RR: Left rotate P â†’ Root becomes Q
ð–¦¹ LR: Rotate Q â†’ Rotate P â†’ Root becomes R
ð–¦¹ RL: Rotate Q â†’ Rotate P â†’ Root becomes R

9. Node Definition in C++
ð–¦¹ [pink]struct[/pink] [yellow]Node[/yellow] {
  [pink]int[/pink] [yellow]key[/yellow];
  [pink]Node*[/pink] [yellow]left[/yellow];
  [pink]Node*[/pink] [yellow]right[/yellow];
  [pink]int[/pink] [yellow]height[/yellow];
  [pink]Node[/pink]([pink]int[/pink] [yellow]k[/yellow]) {
    [yellow]key[/yellow] = [yellow]k[/yellow];
    [yellow]left[/yellow] = [yellow]right[/yellow] = [green]nullptr[/green];
    [yellow]height[/yellow] = 1;
  }
};

10. Helper Functions
ð–¦¹ [pink]int[/pink] [yellow]height[/yellow]([pink]Node*[/pink] [yellow]n[/yellow]) { if (![yellow]n[/yellow]) return 0; return [yellow]n[/yellow]->height; }
ð–¦¹ [pink]int[/pink] [yellow]getBalance[/yellow]([pink]Node*[/pink] [yellow]n[/yellow]) { if (![yellow]n[/yellow]) return 0; return height([yellow]n[/yellow]->right) - height([yellow]n[/yellow]->left); }
ð–¦¹ void [yellow]updateHeight[/yellow]([pink]Node*[/pink] [yellow]n[/yellow]) { [yellow]n[/yellow]->height = 1 + [green]max[/green](height([yellow]n[/yellow]->left), height([yellow]n[/yellow]->right)); }

11. Rotations
ð–¦¹ Right rotation (LL)
[pink]Node*[/pink] [yellow]rightRotate[/yellow]([pink]Node*[/pink] [yellow]y[/yellow]) {
  [pink]Node*[/pink] [yellow]x[/yellow] = [yellow]y[/yellow]->left;
  [pink]Node*[/pink] [yellow]T2[/yellow] = [yellow]x[/yellow]->right;
  [yellow]x[/yellow]->right = [yellow]y[/yellow];
  [yellow]y[/yellow]->left = [yellow]T2[/yellow];
  updateHeight([yellow]y[/yellow]); updateHeight([yellow]x[/yellow]);
  return [yellow]x[/yellow];
}
ð–¦¹ Left rotation (RR)
[pink]Node*[/pink] [yellow]leftRotate[/yellow]([pink]Node*[/pink] [yellow]x[/yellow]) {
  [pink]Node*[/pink] [yellow]y[/yellow] = [yellow]x[/yellow]->right;
  [pink]Node*[/pink] [yellow]T2[/yellow] = [yellow]y[/yellow]->left;
  [yellow]y[/yellow]->left = [yellow]x[/yellow];
  [yellow]x[/yellow]->right = [yellow]T2[/yellow];
  updateHeight([yellow]x[/yellow]); updateHeight([yellow]y[/yellow]);
  return [yellow]y[/yellow];
}

12. Insertion with AVL Balancing
ð–¦¹ [pink]Node*[/pink] [yellow]insert[/yellow]([pink]Node*[/pink] [yellow]node[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
  if (![yellow]node[/yellow]) return new [yellow]Node[/yellow]([yellow]key[/yellow]);
  if ([yellow]key[/yellow] < [yellow]node[/yellow]->key) [yellow]node[/yellow]->left = insert([yellow]node[/yellow]->left, [yellow]key[/yellow]);
  else [yellow]node[/yellow]->right = insert([yellow]node[/yellow]->right, [yellow]key[/yellow]);
  updateHeight([yellow]node[/yellow]);
  [pink]int[/pink] [yellow]balance[/yellow] = getBalance([yellow]node[/yellow]);
  if ([yellow]balance[/yellow] < -1 && [yellow]key[/yellow] < [yellow]node[/yellow]->left->key) return rightRotate([yellow]node[/yellow]);
  if ([yellow]balance[/yellow] > 1 && [yellow]key[/yellow] > [yellow]node[/yellow]->right->key) return leftRotate([yellow]node[/yellow]);
  if ([yellow]balance[/yellow] < -1 && [yellow]key[/yellow] > [yellow]node[/yellow]->left->key) { [yellow]node[/yellow]->left = leftRotate([yellow]node[/yellow]->left); return rightRotate([yellow]node[/yellow]); }
  if ([yellow]balance[/yellow] > 1 && [yellow]key[/yellow] < [yellow]node[/yellow]->right->key) { [yellow]node[/yellow]->right = rightRotate([yellow]node[/yellow]->right); return leftRotate([yellow]node[/yellow]); }
  return [yellow]node[/yellow];
}

13. Utility: Inorder Traversal
ð–¦¹ void [yellow]inorder[/yellow]([pink]Node*[/pink] [yellow]root[/yellow]) { if (![yellow]root[/yellow]) return; inorder([yellow]root[/yellow]->left); [green]cout[/green] << [yellow]root[/yellow]->key << " "; inorder([yellow]root[/yellow]->right); }

14. Example Usage
ð–¦¹ [pink]int[/pink] [yellow]main[/yellow]() {
  [pink]Node*[/pink] [yellow]root[/yellow] = [green]nullptr[/green];
  [pink]int[/pink] [yellow]nums[/yellow][] = {10, 20, 30, 40, 50, 25};
  for ([pink]int[/pink] [yellow]key[/yellow] : [yellow]nums[/yellow]) [yellow]root[/yellow] = insert([yellow]root[/yellow], [yellow]key[/yellow]);
  [green]cout[/green] << "Inorder traversal of AVL tree: ";
  inorder([yellow]root[/yellow]);
  [green]cout[/green] << [green]endl[/green];
  return 0;
}

15. Example 1: Inserting Nodes in Ascending Order
ð–¦¹ Insert nodes: 10, 20, 30, 40, 50, 25
â€¢ Step 1: Insert 10, 20, 30
- Insert 10 â†’ tree: 10
- Insert 20 â†’ tree: 10 â†’ 20
- Insert 30 â†’ tree becomes unbalanced (RR case at 10)
- Fix RR rotation at 10 â†’ new root = 20
      20
     /  \
   10    30
âœ… Now balanced
â€¢ Step 2: Insert 40, 50
- Insert 40 â†’ tree:
      20
     /  \
   10    30
           \
            40
- Insert 50 â†’ tree unbalanced (RR case at 30)
- Fix RR rotation at 30 â†’ 40 becomes new subtree root
      20
     /  \
   10    40
        /  \
      30    50
âœ… Still AVL balanced
â€¢ Step 3: Insert 25
- Insert 25 under 30:
      20
     /  \
   10    40
        /  \
      30    50
     /
   25
- Check balance:
  â€¢ Node 30: left height 1, right height 0 â†’ balance = -1 â†’ fine
  â€¢ Node 40: left height 2, right height 1 â†’ balance = +1 â†’ fine
  â€¢ Node 20: left height 1, right height 3 â†’ balance = +2 â†’ unbalanced
- This is RL case at 20:
  â€¢ Step 1: Right rotate on 40's left child (30)
  â€¢ Step 2: Left rotate on 20
- After rotations:
        30
       /  \
     20    40
    / \      \
  10   25    50
âœ… Balanced AVL tree

16. Example 2: Complex LR Case
ð–¦¹ Insert nodes: 50, 30, 70, 20, 40, 35
â€¢ Step 1: Build initial tree
    50
   /
  30
 /
20
- LL case at 50 â†’ right rotate 50
    30
   /  \
 20    50
â€¢ Step 2: Insert 40, then 35
      30
     /  \
   20    50
        /
      40
     /
   35
- Check balance:
  â€¢ Node 50: left height 2, right height 0 â†’ balance = -2 â†’ unbalanced
- This is LR case at 50 (left-right heavy):
  â€¢ Step 1: Left rotate on 40 â†’ 35 becomes left child of 50
      30
     /  \
   20    50
        /
      35
        \
        40
  â€¢ Step 2: Right rotate on 50 â†’ 35 becomes new subtree root
      30
     /  \
   20    35
           \
            50
           /
         40
âœ… Balanced AVL tree again
--END--
--BEGIN--24/11/2025--RED BLACK TREES--
1. Red Black Tree
ð–¦¹ It is a special binary search tree that keeps its height small.
ð–¦¹ Every node has a color: red or black.
ð–¦¹ The color rules keep the tree almost balanced.
â€¢ Rule: Every node is either red or black.
â€¢ Rule: The root is always black.
â€¢ Rule: Red node cannot have a red child.
â€¢ Rule: Every path from a node to its leaf-null has the same number of black nodes.
ð–¦¹ Because of these rules, the longest path is at most twice the shortest path.
ð–¦¹ So the height h â‰¤ 2 Ã— logâ‚‚(n+1).
ð–¦¹ It supports fast search, insert, and delete in O(log n).

2. Red black tree worries removed
ð–¦¹ You do not need to arrange colors or rotations by yourself.
ð–¦¹ The rules will always fix the tree to keep height low.
ð–¦¹ The operations are always near log time.
ð–¦¹ You just use insert and delete; balancing happens inside.

3. Operations needed
ð–¦¹ You need: left rotate, right rotate.
ð–¦¹ You need: color flip or recolor.
ð–¦¹ Insert and delete use these to fix problems automatically.
ð–¦¹ The property â€œno two reds in a rowâ€ is always checked and repaired.
ð–¦¹ The black-height rule is also kept.

4. C++ code: Node structure
ð–¦¹ Here is the simple node structure.
<blue>struct</blue> Node {
    <green>int</green> data;
    <blue>bool</blue> <orange>color</orange>; <grey>// 0 = black, 1 = red</grey>
    Node* left;
    Node* right;
    Node* parent;
};

5. C++ code: Left rotate
ð–¦¹ This rotation moves a child up and shifts nodes to the side.
<blue>void</blue> leftRotate(Node* <purple>&root</purple>, Node* <purple>x</purple>) {
    Node* y = x->right;
    x->right = y->left;
    <yellow>if</yellow> (y->left != <red>nullptr</red>)
        y->left->parent = x;
    y->parent = x->parent;
    <yellow>if</yellow> (x->parent == <red>nullptr</red>)
        root = y;
    <yellow>else if</yellow> (x == x->parent->left)
        x->parent->left = y;
    <yellow>else</yellow>
        x->parent->right = y;
    y->left = x;
    x->parent = y;
}

6. C++ code: Right rotate
ð–¦¹ This rotation is the mirror of left rotate.
<blue>void</blue> rightRotate(Node* <purple>&root</purple>, Node* <purple>y</purple>) {
    Node* x = y->left;
    y->left = x->right;
    <yellow>if</yellow> (x->right != <red>nullptr</red>)
        x->right->parent = y;
    x->parent = y->parent;
    <yellow>if</yellow> (y->parent == <red>nullptr</red>)
        root = x;
    <yellow>else if</yellow> (y == y->parent->right)
        y->parent->right = x;
    <yellow>else</yellow>
        y->parent->left = x;
    x->right = y;
    y->parent = x;
}

7. C++ code: Fix insert
ð–¦¹ When a new node is inserted, it may break red-black rules.
ð–¦¹ This function repairs it.
<blue>void</blue> fixInsert(Node* <purple>&root</purple>, Node* <purple>z</purple>) {
    <yellow>while</yellow> (z->parent != <red>nullptr</red> && z->parent->color == <brown>1</brown>) {
        <yellow>if</yellow> (z->parent == z->parent->parent->left) {
            Node* y = z->parent->parent->right;
            <yellow>if</yellow> (y != <red>nullptr</red> && y->color == <brown>1</brown>) {
                z->parent->color = <brown>0</brown>;
                y->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                z = z->parent->parent;
            } <yellow>else</yellow> {
                <yellow>if</yellow> (z == z->parent->right) {
                    z = z->parent;
                    leftRotate(root, z);
                }
                z->parent->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                rightRotate(root, z->parent->parent);
            }
        } <yellow>else</yellow> {
            Node* y = z->parent->parent->left;
            <yellow>if</yellow> (y != <red>nullptr</red> && y->color == <brown>1</brown>) {
                z->parent->color = <brown>0</brown>;
                y->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                z = z->parent->parent;
            } <yellow>else</yellow> {
                <yellow>if</yellow> (z == z->parent->left) {
                    z = z->parent;
                    rightRotate(root, z);
                }
                z->parent->color = <brown>0</brown>;
                z->parent->parent->color = <brown>1</brown>;
                leftRotate(root, z->parent->parent);
            }
        }
    }
    root->color = <brown>0</brown>;
}

8. C++ code: Insert function
ð–¦¹ This inserts normally like a BST.
ð–¦¹ Then fixInsert() repairs the tree.
<blue>void</blue> insert(Node* <purple>&root</purple>, <green>int</green> data) {
    Node* z = <blue>new</blue> Node{data, <brown>1</brown>, <red>nullptr</red>, <red>nullptr</red>, <red>nullptr</red>};
    Node* y = <red>nullptr</red>;
    Node* x = root;
    <yellow>while</yellow> (x != <red>nullptr</red>) {
        y = x;
        <yellow>if</yellow> (z->data < x->data)
            x = x->left;
        <yellow>else</yellow>
            x = x->right;
    }
    z->parent = y;
    <yellow>if</yellow> (y == <red>nullptr</red>)
        root = z;
    <yellow>else if</yellow> (z->data < y->data)
        y->left = z;
    <yellow>else</yellow>
        y->right = z;
    fixInsert(root, z);
}
--END--
--BEGIN--24/11/2025--SELF ADJUSTING TREES--
1. Self-Adjusting Trees
ð–¦¹ When a node is accessed, move it closer to the root.
ð–¦¹ Frequently accessed nodes stay near the top; rarely used nodes stay deeper.
ð–¦¹ This makes searches faster for important elements.

2. Deciding which nodes to move
ð–¦¹ Two ways:
â€¢ Using counters: each node tracks access count; nodes with high count move toward root.
â€¢ Simple assumption: move accessed node up immediately, assuming it will be used again.
ð–¦¹ The tree acts like a priority tree with most used nodes near the root.

3. Single Rotation
ð–¦¹ Move a node up by one step.
ð–¦¹ Example: accessing node 2 in this tree:
      10
     /  \
    5    20
   / \
  2   7
ð–¦¹ Rotate 2 with its parent 5:
      10
     /  \
    2    20
     \
      5
       \
        7
ð–¦¹ Node 2 moved closer to root. Repeated accesses can move it further.

4. Move-to-Root
ð–¦¹ Move a node all the way to root in one access.
ð–¦¹ Example: accessing node 2:
Step 1: rotate 2 with 5
      10
     /  \
    2    20
     \
      5
       \
        7
Step 2: rotate 2 with 10
      2
       \
        10
       /  \
      5    20
       \
        7
ð–¦¹ Node 2 becomes root immediately; next access is very fast.
--END--
--BEGIN--24/11/2025--SPLAYING TREES--
1. Splaying
ð–¦¹ A smarter move-to-root method using pairs of rotations.
ð–¦¹ Rotations depend on the node's parent and grandparent.
ð–¦¹ This flattens the tree and makes frequently accessed nodes easier to reach.

2. Splay Case 1: Parent is root
ð–¦¹ Node R with parent Q:
Initial:
   Q
  /
 R
ð–¦¹ Rotate R with Q:
   R
    \
     Q
ð–¦¹ Node R becomes root.

3. Splay Case 2: Homogeneous (zig-zig)
ð–¦¹ Left-left example: node R under Q under P
Initial:
     P
    /
   Q
  /
 R
Step 1: Rotate Q with P
   Q
  / \
 R   P
Step 2: Rotate R with Q
     R
      \
       Q
        \
         P
ð–¦¹ Node R moves up two levels; tree is flatter.
ð–¦¹ Right-right is symmetric.

4. Splay Case 3: Heterogeneous (zig-zag)
ð–¦¹ Left-right example: node R under Q under P
Initial:
     P
    /
   Q
    \
     R
Step 1: Rotate R with Q
     P
    /
   R
  /
 Q
Step 2: Rotate R with P
    R
   / \
  Q   P
ð–¦¹ Node R is closer to root; tree is flatter.
TO LEARN: DELETION BY COPYING, MERGING AND POLISH AND REVERSE POLISH NOTATIONS
--END--
--BEGIN--25/11/2025--TREAPS--
1. Treap
IMG_URL treap.gif
ð–¦¹ A treap is a data structure that mixes a binary search tree idea (sorted by key) and a heap idea (ordered by priority).
ð–¦¹ Each node has a key for searching and a priority for balancing.
ð–¦¹ The tree stays balanced on average because priorities are random.
â€¢ A treap follows two rules:
  - Binary search tree rule: left child key < node key < right child key.
  - Heap rule: parent priority is smaller than children.
â€¢ Insert, delete, and search take O(log n) on average.
â€¢ Insert first follows BST rule, then rotations fix the heap rule.
â€¢ Random priorities keep the shape balanced without complex rules.

2. How a treap works
ð–¦¹ Sorted by key decides left or right child.
ð–¦¹ Ordered by priority decides how high or low the node sits.
ð–¦¹ After inserting by key, rotations fix any heap-rule break.
â€¢ Random priorities:
  - Make the tree balanced on average.
  - Avoid complex rules used in other balanced BSTs.

3. Node information
ð–¦¹ Each node has (key, priority).
ð–¦¹ Smaller priority means the node should be higher in the tree.
â€¢ Example keys:
  - 42, 7, 55, 13, 90, 31
â€¢ Example priorities:
  - (42,80), (7,10), (55,60), (13,30), (90,90), (31,40)

4. BST insertion step
ð–¦¹ Insert based on key as in a binary search tree.
ð–¦¹ Example order: 42 â†’ 7 â†’ 55 â†’ 13 â†’ 90 â†’ 31
ð–¦¹ The BST shape forms by key only.

5. Heap fixing step
ð–¦¹ Smaller priority means better position.
ð–¦¹ Each node rotates upward if its priority is smaller than the parent.
ð–¦¹ Final treap shape follows both BST and heap rules.
â€¢ Example final shape:
  - (7,10) â†’ (13,30) â†’ (31,40) â†’ (42,80) â†’ (55,60) â†’ (90,90)
â€¢ This forms a chain because keys and priorities increased in similar order by chance.

6. Use of a treap
ð–¦¹ Gives all BST operations (search, insert, delete).
ð–¦¹ Maintains O(log n) expected time.
ð–¦¹ Simpler code compared to AVL or Red-Black trees.
â€¢ It stays balanced automatically because priorities are random.
  - Height stays close to log n.
  - Makes operations fast.
  - Long chains are rare on average.

7. Main operations
ð–¦¹ Fast search
â€¢ Works using keys like a normal BST.
ð–¦¹ Fast insert
  - Random priority + rotations keep balance.
ð–¦¹ Fast delete
  - Rotate the node down until it becomes a leaf, then remove.
ð–¦¹ Split and merge
  - Split makes two treaps: keys < x, and keys â‰¥ x.
  - Merge joins two treaps if all keys in the first are < all keys in the second.
  - Both operations take O(log n).
  - Other balanced trees cannot do this easily.

8. What you can build with treaps
ð–¦¹ Ordered sets or maps
â€¢ Similar to C++ set/map but simpler to code.
ð–¦¹ Range queries
  - You can store subtree sum, max, count, lazy flags, etc.
ð–¦¹ Interval trees
  - Useful for overlapping intervals, scheduling, compilers.
ð–¦¹ Rope structure
  - Used in editors, versioning, undo/redo, and long strings.
ð–¦¹ Randomized balanced BST
  - Common in competitive programming.
ð–¦¹ Implicit treap
  - Index acts like the key.
  - Helps with cutting arrays, reversing ranges, inserting in the middle, splitting strings, merging strings in O(log n).

9. Implementation in C++
[pink]#include[/pink] <bits/stdc++.h>
[pink]using[/pink] [pink]namespace[/pink] std;

[pink]struct[/pink] [blue]Treap[/blue] {
    [pink]int[/pink] [yellow]key[/yellow], [yellow]priority[/yellow];
    [blue]Treap[/blue] *[yellow]left[/yellow], *[yellow]right[/yellow];

    [blue]Treap[/blue]([pink]int[/pink] [yellow]k[/yellow]) {
        [yellow]key[/yellow] = [yellow]k[/yellow];
        [yellow]priority[/yellow] = [green]rand[/green]();  [gray]// random priority[/gray]
        [yellow]left[/yellow] = [yellow]right[/yellow] = [green]NULL[/green];
    }
};

[gray]// Right rotation[/gray]
[blue]Treap[/blue]* rotateRight([blue]Treap[/blue]* [yellow]y[/yellow]) {
    [blue]Treap[/blue]* [yellow]x[/yellow] = [yellow]y[/yellow]->left;
    [blue]Treap[/blue]* [yellow]T[/yellow] = [yellow]x[/yellow]->right;

    [yellow]x[/yellow]->right = [yellow]y[/yellow];
    [yellow]y[/yellow]->left = [yellow]T[/yellow];
    [pink]return[/pink] [yellow]x[/yellow];
}

[gray]// Left rotation[/gray]
[blue]Treap[/blue]* rotateLeft([blue]Treap[/blue]* [yellow]x[/yellow]) {
    [blue]Treap[/blue]* [yellow]y[/yellow] = [yellow]x[/yellow]->right;
    [blue]Treap[/blue]* [yellow]T[/yellow] = [yellow]y[/yellow]->left;

    [yellow]y[/yellow]->left = [yellow]x[/yellow];
    [yellow]x[/yellow]->right = [yellow]T[/yellow];
    [pink]return[/pink] [yellow]y[/yellow];
}

[gray]// Insert key into treap[/gray]
[blue]Treap[/blue]* insert([blue]Treap[/blue]* [yellow]root[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink] [pink]new[/pink] [blue]Treap[/blue]([yellow]key[/yellow]);

    [pink]if[/pink] ([yellow]key[/yellow] < [yellow]root[/yellow]->key) {
        [yellow]root[/yellow]->left = insert([yellow]root[/yellow]->left, [yellow]key[/yellow]);

        [pink]if[/pink] ([yellow]root[/yellow]->left->priority > [yellow]root[/yellow]->priority)
            [yellow]root[/yellow] = rotateRight([yellow]root[/yellow]);

    } [pink]else[/pink] {
        [yellow]root[/yellow]->right = insert([yellow]root[/yellow]->right, [yellow]key[/yellow]);

        [pink]if[/pink] ([yellow]root[/yellow]->right->priority > [yellow]root[/yellow]->priority)
            [yellow]root[/yellow] = rotateLeft([yellow]root[/yellow]);
    }

    [pink]return[/pink] [yellow]root[/yellow];
}

[gray]// Delete a key from treap[/gray]
[blue]Treap[/blue]* remove([blue]Treap[/blue]* [yellow]root[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink] [yellow]root[/yellow];

    [pink]if[/pink] ([yellow]key[/yellow] < [yellow]root[/yellow]->key) {
        [yellow]root[/yellow]->left = remove([yellow]root[/yellow]->left, [yellow]key[/yellow]);

    } [pink]else if[/pink] ([yellow]key[/yellow] > [yellow]root[/yellow]->key) {
        [yellow]root[/yellow]->right = remove([yellow]root[/yellow]->right, [yellow]key[/yellow]);

    } [pink]else[/pink] { 
        [pink]if[/pink] (![yellow]root[/yellow]->left) {
            [blue]Treap[/blue]* [yellow]r[/yellow] = [yellow]root[/yellow]->right;
            [pink]delete[/pink] [yellow]root[/yellow];
            [pink]return[/pink] [yellow]r[/yellow];

        } [pink]else if[/pink] (![yellow]root[/yellow]->right) {
            [blue]Treap[/blue]* [yellow]l[/yellow] = [yellow]root[/yellow]->left;
            [pink]delete[/pink] [yellow]root[/yellow];
            [pink]return[/pink] [yellow]l[/yellow];

        } [pink]else[/pink] {
            [pink]if[/pink] ([yellow]root[/yellow]->left->priority > [yellow]root[/yellow]->right->priority) {
                [yellow]root[/yellow] = rotateRight([yellow]root[/yellow]);
                [yellow]root[/yellow]->right = remove([yellow]root[/yellow]->right, [yellow]key[/yellow]);
            } [pink]else[/pink] {
                [yellow]root[/yellow] = rotateLeft([yellow]root[/yellow]);
                [yellow]root[/yellow]->left = remove([yellow]root[/yellow]->left, [yellow]key[/yellow]);
            }
        }
    }
    [pink]return[/pink] [yellow]root[/yellow];
}

[gray]// Search a key[/gray]
[pink]bool[/pink] search([blue]Treap[/blue]* [yellow]root[/yellow], [pink]int[/pink] [yellow]key[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return false[/pink];
    [pink]if[/pink] ([yellow]root[/yellow]->key == [yellow]key[/yellow]) [pink]return true[/pink];
    [pink]if[/pink] ([yellow]key[/yellow] < [yellow]root[/yellow]->key) [pink]return[/pink] search([yellow]root[/yellow]->left, [yellow]key[/yellow]);
    [pink]return[/pink] search([yellow]root[/yellow]->right, [yellow]key[/yellow]);
}

[gray]// Inorder traversal[/gray]
[pink]void[/pink] inorder([blue]Treap[/blue]* [yellow]root[/yellow]) {
    [pink]if[/pink] (![yellow]root[/yellow]) [pink]return[/pink];
    inorder([yellow]root[/yellow]->left);
    [green]cout[/green] << "(" << [yellow]root[/yellow]->key << ", p=" << [yellow]root[/yellow]->priority << ") ";
    inorder([yellow]root[/yellow]->right);
}

[pink]int[/pink] main() {
    [green]srand[/green]([green]time[/green]([green]NULL[/green]));

    [blue]Treap[/blue]* [yellow]root[/yellow] = [green]NULL[/green];

    [yellow]root[/yellow] = insert([yellow]root[/yellow], 5);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 2);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 8);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 1);
    [yellow]root[/yellow] = insert([yellow]root[/yellow], 3);

    [green]cout[/green] << "Treap inorder: ";
    inorder([yellow]root[/yellow]);
    [green]cout[/green] << "\n";

    [green]cout[/green] << "Search 3: " << search([yellow]root[/yellow], 3) << "\n";
    [green]cout[/green] << "Search 10: " << search([yellow]root[/yellow], 10) << "\n";

    [yellow]root[/yellow] = remove([yellow]root[/yellow], 2);

    [green]cout[/green] << "After deleting 2: ";
    inorder([yellow]root[/yellow]);
    [green]cout[/green] << "\n";
}
--END--
--BEGIN--25/11/2025--MULTIWAY TREES--
1. Multiway tree
IMG_URL mway-tree.png
ð–¦¹ A multiway tree is a tree where one node can have many children.
ð–¦¹ If a node can have m children, it is called an m-way tree.
â€¢ Example:
  - A 4-way tree means each node can have up to 4 children.
- A multiway tree becomes shorter because more keys fit in one node.

2. Why use multiway trees
ð–¦¹ Binary trees may become very tall when unbalanced.
ð–¦¹ Multiway trees are shorter because many keys are stored in one node.
â€¢ Shorter height means faster search, which is important for disks and large databases.

3. m-way search tree
ð–¦¹ It is a multiway tree with ordering rules for fast search.
ð–¦¹ Each node stores m â€“ 1 keys and m children.
- Searching works like a BST but with more children.

4. Rules of an m-way search tree
ð–¦¹ Rule 1: Each node has m children and m â€“ 1 keys.
â€¢ Example for m = 4:
  - Node has 3 keys and 4 children.
ð–¦¹ Rule 2: Keys in a node are sorted in ascending order.
â€¢ Example: [30, 50, 80]
ð–¦¹ Rule 3: Keys in the first i children are smaller than the i-th key.
â€¢ Example:
  - Keys: 30  50  80
  - Children: C1 C2 C3 C4
  - All keys in C1 < 30
  - All keys in C2 are between 30 and 50
  - All keys in C3 are between 50 and 80
ð–¦¹ Rule 4: Keys in the last m â€“ i children are larger than the i-th key.
â€¢ Example:
  - All keys in C4 > 80

5. Why we need m-way search trees
ð–¦¹ Binary search trees often become unbalanced.
ð–¦¹ If unbalanced, some elements take many steps to find.
â€¢ This makes the height large and slows search on disk.
ð–¦¹ Better balanced multiway trees fix this for large data.
â€¢ Examples:
  - B-trees
  - B+-trees
  - 2-3 trees
  - 2-3-4 trees
--END--
--BEGIN--25/11/2025--WHY B TREES?--
1. How disks work
IMG_URL seek-rotation-transfer.png
ð–¦¹ Disks are divided into blocks for reading and writing data.
ð–¦¹ When accessing data, the whole block is read into memory.
ð–¦¹ When storing data, the entire block is written to disk.

2. Disk access is slow
ð–¦¹ Disk access is slower than memory because disks have mechanical parts.
ð–¦¹ Total access time = seek time + rotational delay + transfer time.
â€¢ Seek time: moving disk head to correct track.
â€¢ Rotational delay (latency): waiting for correct block to spin under head.
â€¢ Transfer time: moving data to memory.
â€¢ Example:
  - Seek time = 40 ms
  - Latency = 10 ms
  - Transfer 5KB = 5 ms
  - Total access time = 55 ms

3. Memory vs disk
ð–¦¹ CPU works in microseconds or nanoseconds, much faster than disk.
ð–¦¹ Disk works in milliseconds.
ð–¦¹ Accessing data from disk is 1,000 to 1,000,000 times slower than memory operations.

4. Problem with binary search trees on disk
ð–¦¹ Each BST node may be in a different disk block.
ð–¦¹ Searching, inserting, or deleting may need many block reads.
ð–¦¹ Result: BSTs fast in memory become slow on disk.

5. Accessing large chunks is faster
ð–¦¹ Reading more data at once reduces disk access overhead.
â€¢ Example:
  - 10KB at once â†’ 40 + 10 + 10 = 60 ms
  - Two 5KB pieces â†’ 2 Ã— (40 + 10 + 5) = 110 ms
ð–¦¹ Key idea: Minimize the number of disk accesses in data structures.
ð–¦¹ B-trees and multiway trees store many keys in one node/block.
ð–¦¹ This reduces block reads and improves performance on large datasets.
--END--
--BEGIN--25/11/2025--B TREES--
1. B-tree = Multiway search tree
ð–¦¹ A B-tree is a multiway tree where each node can have more than 2 children.
ð–¦¹ In a B-tree of order m:
â€¢ Each node can have at most m children.
â€¢ Each node can have at most m-1 keys.
- Keys divide the children. Example: a node with 3 keys can have 4 children.

2. Whatâ€™s in a node
ð–¦¹ Each node contains:
â€¢ Array of keys â†’ up to m-1 keys
â€¢ Array of children references â†’ up to m children
â€¢ Leaf flag â†’ true if node is a leaf
â€¢ Key count â†’ number of keys actually present
ð–¦¹ Example for order m = 4:
[pink]Node[/pink]:
  keys = [yellow]10, 20, 30[/yellow]      // 3 keys
  children = [yellow]C0, C1, C2, C3[/yellow]  // 4 children
  leaf = false
  keyCount = 3
â€¢ C0 contains keys < 10
â€¢ C1 contains keys 10â€“19
â€¢ C2 contains keys 20â€“29
â€¢ C3 contains keys â‰¥ 30

3. Root node
ð–¦¹ The root can have fewer than m-1 keys (even 1 key if not a leaf).
ð–¦¹ Every node except root must have at least ceil(m/2) â€“ 1 keys.
- Root may have fewer keys than other nodes.

4. Leaf vs internal nodes
ð–¦¹ Leaf node: no children, only keys.
ð–¦¹ Internal node: has children references + keys.
ð–¦¹ Leaf flag helps the algorithm know whether to stop or go deeper.

5. Visualization (order 4, root example)
ð–¦¹ Example tree:
          [20]
        /      \
   [5, 10]   [25, 30]
ð–¦¹ Root has 1 key â†’ 2 children
ð–¦¹ Left child has 2 keys â†’ 3 children (if not leaf)
ð–¦¹ Right child has 2 keys â†’ 3 children
ð–¦¹ Keys in children are less than, between, or greater than parent keys.

6. In Essence
ð–¦¹ Each node can hold multiple keys.
ð–¦¹ Keys divide the range of children.
ð–¦¹ Root can have fewer keys than other nodes.
ð–¦¹ Leaf flag + children pointers help traverse tree efficiently.

6. Search in a B-tree
ð–¦¹ Start at root and go down the tree until key is found or leaf reached.
ð–¦¹ Look at keys in the node (sorted).
â€¢ If key matches â†’ found
â€¢ If key < first key â†’ go to first child
â€¢ If key between keys â†’ go to corresponding child
â€¢ If key > last key â†’ go to last child
ð–¦¹ Repeat until key is found or leaf reached.
ð–¦¹ Example (order 4):
         [20]
       /     \
   [5, 10]   [25, 30]
â€¢ Search 10 â†’ 10 < 20 â†’ go left â†’ [5, 10] â†’ 10 found
ð–¦¹ Cost proportional to height â†’ few disk reads if node size matches block size.

7. Insertion in a B-tree
ð–¦¹ Always insert in a leaf. If leaf is full, split and push middle key to parent.
ð–¦¹ Steps:
â€¢ Find the leaf where new key should go.
â€¢ Insert key in leaf in sorted order.
â€¢ If leaf has more than m-1 keys â†’ split node into two.
â€¢ Middle key moves up to parent.
â€¢ If parent full â†’ repeat split up to root.
â€¢ If root splits â†’ create new root â†’ height increases by 1.
ð–¦¹ Example (order 4):
â€¢ Insert 15 into leaf [5,10,12] â†’ leaf full â†’ split â†’ [5,10] and [15,12], middle 12 goes up.

8. Deletion in a B-tree
ð–¦¹ Remove key. If node less than half full â†’ borrow from sibling or merge nodes.
ð–¦¹ Steps:
â€¢ Find key to delete.
â€¢ If key in leaf:
  - Delete it.
  - If node still has enough keys â†’ done.
  - If node < minimum keys â†’ borrow from sibling or merge with sibling and move separator from parent.
â€¢ If key in internal node:
  - Replace with predecessor (max in left subtree) or successor (min in right subtree).
  - Delete that key from leaf using leaf deletion rules.
ð–¦¹ Example:
â€¢ Delete 10 from leaf [5,10,12] â†’ node still enough â†’ [5,12]
â€¢ If underflow occurs â†’ borrow or merge happens.

9. NOTES
ð–¦¹ Search: follow keys â†’ O(log n)
ð–¦¹ Insert: insert in leaf â†’ split if needed â†’ propagate up â†’ keeps tree balanced
ð–¦¹ Delete: remove from leaf or internal node â†’ borrow/merge â†’ tree stays balanced
--END--
--BEGIN--25/11/2025--B+ TREES--
IMG_URL bplustree.png
1. Structure of a B+-tree
ð–¦¹ A B+-tree is a multiway search tree like a B-tree.
ð–¦¹ Internal nodes (non-leaves) store only keys, no actual data.
â€¢ They serve as an index to guide searches.
ð–¦¹ Leaf nodes store actual keys and references to records.
â€¢ Leaves are linked sequentially â†’ makes range queries or ordered scanning fast.
ð–¦¹ Visual example (order 4):

          [20 | 40]
         /    |    \
    [5,10]  [25,30]   [45,50]

â€¢ Internal node [20|40] â†’ guides search
â€¢ Leaves [5,10], [25,30], [45,50] â†’ store actual data
â€¢ Leaves linked: [5,10] â†’ [25,30] â†’ [45,50]
ð–¦¹ Difference from B-tree: data only in leaves.

2. Searching in a B+-tree
ð–¦¹ Start at root, follow keys to correct child.
ð–¦¹ Repeat until leaf reached.
ð–¦¹ Look in leaf for the key.
ð–¦¹ Benefit: searching is fast and predictable since data only at leaves.

3. Insertion in a B+-tree
ð–¦¹ Step 1: Find the leaf where key should go.
ð–¦¹ Step 2:
â€¢ If leaf has room â†’ insert in sorted order.
â€¢ If leaf full â†’ split leaf:
  - Create new leaf
  - Divide keys evenly between old and new leaf
  - Copy first key of new leaf to parent (separator)
â€¢ If parent full â†’ split parent recursively
ð–¦¹ Important: Only leaves hold data; internal nodes are indexes.

4. Deletion in a B+-tree
ð–¦¹ Step 1: Find the leaf containing key.
ð–¦¹ Step 2: Remove key from leaf.
â€¢ If leaf â‰¥ half full â†’ done
â€¢ If leaf underflows â†’ borrow from sibling or merge with sibling
â€¢ Update parent separator keys if needed
ð–¦¹ Step 3: Fix internal nodes recursively if affected (like B-tree)
ð–¦¹ Example:
â€¢ Leaves: [2,6] [8,10]
â€¢ Delete 2 â†’ underflow â†’ merge â†’ [6,8,10]
â€¢ Remove separator in parent â†’ fix parent keys

5. Why B+-trees are useful
ð–¦¹ All data in leaves â†’ sequential scan fast.
ð–¦¹ Internal nodes are indexes â†’ fewer disk accesses for search.
ð–¦¹ Leaves linked â†’ easy iteration and range queries.
ð–¦¹ Better for databases and file systems than B-trees.
ð–¦¹ Comparison:
â€¢ Data storage: B-tree â†’ any node, B+-tree â†’ leaves only
â€¢ Internal nodes: B-tree â†’ keys + data references, B+-tree â†’ keys only
â€¢ Leaves: B-tree â†’ not linked, B+-tree â†’ linked sequentially
â€¢ Range scan: B-tree â†’ slower, B+-tree â†’ fast
--END--
--BEGIN--25/11/2025--B* TREES--
1. B*-tree
ð–¦¹ A B*-tree is a better form of a normal B-tree.
ð–¦¹ The idea is to use node space well so we do not create many nodes.
ð–¦¹ Fewer nodes are good because each node is on disk, and disk reading is slow.
ð–¦¹ To reduce nodes, each node should hold more keys.

2. Need for fewer nodes
ð–¦¹ Each B-tree node is stored in secondary memory.
ð–¦¹ Accessing secondary memory is slow.
ð–¦¹ So we want nodes to be more full, which reduces the number of nodes.

3. Difference between B-tree and B*-tree
ð–¦¹ Normal B-tree: Every non-root node must be at least half full.
ð–¦¹ B*-tree: Every non-root node must be at least two-thirds full.
ð–¦¹ This means B*-tree nodes hold more keys on average.
ð–¦¹ So the number of created nodes becomes less.

4. Example of minimum keys
ð–¦¹ If order m = 9:
â€¢ Normal B-tree non-root node minimum keys = 4
â€¢ B*-tree non-root node minimum keys = 6

5. Insertion in a B*-tree
ð–¦¹ When inserting, if a node is full, try redistribution first.
â€¢ Instead of splitting at once, borrow or share keys with sibling.

6. Redistribution example
ð–¦¹ Suppose you insert 6 into a left node that is full.
ð–¦¹ Check the right sibling:
â€¢ If sibling has space, take keys from both nodes, sort them, divide evenly.
â€¢ Push the middle key to the parent.
ð–¦¹ This fixes overflow without splitting.

7. Three-way split
ð–¦¹ If both the node and sibling are full:
â€¢ Combine node keys, sibling keys, and parent separator key.
â€¢ Sort them.
â€¢ Split them into 3 nodes.
â€¢ Insert 2 separator keys into the parent.
ð–¦¹ This keeps all new nodes at least two-thirds full.
ð–¦¹ This reduces splits and improves disk usage.

8. Fill factor
ð–¦¹ B*-tree average node fullness is about 81%.
ð–¦¹ Some systems allow different fill levels.
â€¢ Example: 75% full is called a B**-tree.
ð–¦¹ General form: A Bâ¿-tree uses fill rule n / (n + 1).
--END--
--BEGIN--26/11/2025--BIT TREES--
1. Bit-tree
ð–¦¹ A Bit-tree is like a Bâº-tree but compares keys more deeply.
ð–¦¹ Bâº-trees compare full keys or prefixes, but Bit-trees compare the exact bit where two keys differ.
ð–¦¹ Instead of comparing full values like K or N, it compares bits.

2. D-bit (Distinction Bit)
ð–¦¹ A D-bit shows the first bit position where two keys differ.
â€¢ Example: ASCII of K = 01001011, ASCII of N = 01001110
â€¢ The first difference is at bit position 5
â€¢ So D(K, N) = 5
ð–¦¹ Bit-trees store these D-bits at the leaves.

3. Data storage in Bit-trees
ð–¦¹ Leaves do not store keys directly.
ð–¦¹ Each leaf stores:
â€¢ Keys in sorted order in a connected data file
â€¢ D-bit between each pair of neighbor keys
ð–¦¹ This reduces space and speeds up searching.

4. Example leaf structure
ð–¦¹ Sorted keys: K, N, O, R, V
â€¢ K = 01001011
â€¢ N = 01001110
â€¢ O = 01001111
â€¢ R = 01010010
â€¢ V = 01010110
ð–¦¹ D-bits:
â€¢ K â†’ N = 5
â€¢ N â†’ O = 7
â€¢ O â†’ R = 3
â€¢ R â†’ V = 5

5. Searching in a Bit-tree
ð–¦¹ Searching uses bits of the given key plus the leafâ€™s D-bits.
ð–¦¹ Steps:
â€¢ Start with record Râ‚€.
â€¢ For each D-bit:
  - Check that bit in the search key.
  - If the bit is 1, move to that record.
  - If the bit is 0, skip to the next smaller D-bit.
â€¢ After the loop, you reach some record R.
â€¢ Finally compare Râ€™s key with the search key.
ð–¦¹ If equal â†’ found, else â†’ not found.

6. Search example for key â€œVâ€
ð–¦¹ V = 01010110
ð–¦¹ Leaf D-bits: 5, 7, 3, 5
â€¢ Dâ‚ = 5 â†’ V bit 5 = 1 â†’ pick Râ‚
â€¢ Dâ‚‚ = 7 â†’ V bit 7 = 0 â†’ skip until smaller D-bit
â€¢ Dâ‚ƒ = 3 â†’ V bit 3 = 1 â†’ pick Râ‚ƒ
â€¢ Dâ‚„ = 5 â†’ V bit 5 = 1 â†’ pick Râ‚…
ð–¦¹ End reached â†’ result is Râ‚… â†’ correct record for V.

7. If the key is not present
ð–¦¹ Example: S = 01010011
ð–¦¹ The D-bit steps may land on some record like Râ‚ƒ even if S is absent.
ð–¦¹ Final check:
â€¢ If record key = S â†’ found
â€¢ Else â†’ not found
ð–¦¹ This avoids wrong answers.
--END--
--BEGIN--26/11/2025--R TREES--
1. R-trees
ð–¦¹ R-trees store spatial data such as maps, buildings, roads, CAD models, and VLSI designs.
ð–¦¹ They help answer questions like â€œfind all buildings in this areaâ€ or â€œfind all objects within this distanceâ€.
ð–¦¹ B-trees cannot store this because spatial objects are rectangles, not single numeric keys.

2. How R-trees store data in leaf nodes
ð–¦¹ A leaf stores entries of the form (rectangle, id).
â€¢ A rectangle can be ([x1, x2], [y1, y2]) in 2-D or ([c1, c2], â€¦) in n-D.
ð–¦¹ The rectangle is the minimum bounding box (MBB) of the object.
â€¢ Example: Object X lies in [10,100] Ã— [5,52], so a leaf stores (([10,100], [5,52]), X).

3. How R-trees store data in non-leaf nodes
ð–¦¹ A non-leaf node stores (enclosing_rectangle, child_pointer).
ð–¦¹ The enclosing rectangle fully covers all rectangles stored inside its child node.
ð–¦¹ The tree becomes a hierarchy: small rectangles â†’ bigger rectangles â†’ even bigger rectangles â†’ root.

4. Insertion in R-trees
ð–¦¹ Start at root and choose the child whose rectangle needs the smallest expansion to include the new object.
ð–¦¹ Go down until a leaf and insert the new rectangle.
ð–¦¹ If a leaf becomes full, split it into two nodes.
ð–¦¹ After splitting, parent rectangles are updated to tightly cover their children.
â€¢ Main difficulty: finding a good split so overlap is low, area is small, and future searches are efficient.

5. Overlap problem in R-trees
ð–¦¹ Rectangles in non-leaf nodes may overlap.
ð–¦¹ A search may enter many paths because the search rectangle intersects multiple parent rectangles.
â€¢ Example: R3 lies inside both R10 and R11, so the search may follow a wrong path.
ð–¦¹ In large R-trees, this overlap can cause slow searches.

6. R+-trees
ð–¦¹ R+-trees remove overlap between parent rectangles.
ð–¦¹ Parent rectangles are not allowed to overlap.
ð–¦¹ If a data rectangle crosses two parent rectangles, it is stored in both leaves.
â€¢ Example: Rectangle R8 is stored in two leaves in the R+-tree.

7. R+-tree advantages and drawbacks
ð–¦¹ Advantages:
â€¢ No overlap means no confusion during search.
â€¢ Search follows one correct path.
ð–¦¹ Drawbacks:
â€¢ Node utilization is harder to maintain.
â€¢ One object may appear in multiple leaves.

8. Summary
ð–¦¹ Parent rectangles overlap: R-tree = Yes, R+-tree = No
ð–¦¹ Speed: R-tree = Slower, R+-tree = Faster
ð–¦¹ Object stored in: R-tree = One leaf, R+-tree = Many leaves possible
ð–¦¹ Node utilization: R-tree = Easier, R+-tree = Harder
ð–¦¹ Search paths: R-tree = May branch wrongly, R+-tree = Single correct path
ð–¦¹ R-tree: Tree for spatial objects using bounding rectangles; overlap allowed.
ð–¦¹ R+-tree: R-tree without overlap in internal nodes; objects may appear many times.
--END--
--BEGIN--26/11/2025--2-4 TREES--
1. 2â€“4 tree
ð–¦¹ A 2â€“4 tree has nodes that can hold 1, 2, or 3 keys.
ð–¦¹ A node with 1 key has 2 children; 2 keys â†’ 3 children; 3 keys â†’ 4 children.
ð–¦¹ Although B-trees are for disk storage, 2â€“4 trees are also used in main memory.

2. Reason for converting a 2â€“4 tree to a binary tree
ð–¦¹ A 2â€“4 node holds 3 keys and 4 pointers, which wastes space in memory.
ð–¦¹ So it is changed into a binary tree where each node holds only one key.
ð–¦¹ Special link types (horizontal or vertical, or red/black links) help recreate the original 2â€“4 structure.
â€¢ This binary form is called a vh-tree or a red-black tree.

3. Vertical and horizontal links
ð–¦¹ Vertical links show parentâ€“child connections.
ð–¦¹ Horizontal links show keys that belong to the same 2â€“4 node.
ð–¦¹ Horizontal links mean â€œthese keys came from the same original nodeâ€.

4. Properties of vh-trees
ð–¦¹ All root-to-leaf paths have the same number of vertical links, so the tree stays balanced.
ð–¦¹ No path may have two horizontal links in a row.
â€¢ This stops wrong merging of nodes.
ð–¦¹ Search is like BST search because we ignore link types while searching.

5. vh-tree height
ð–¦¹ We check how tall a vh-tree can be.
ð–¦¹ Height lower bound: log2(n + 1)
ð–¦¹ Height upper bound: 2 log2(n + 2) â€“ 2
â€¢ Means vh-tree height is at most twice that of a balanced binary tree.
â€¢ This is similar to red-black tree height bounds.

6. Splitting a 4-node
ð–¦¹ A 4-node has 3 keys and must be split during insertion.
ð–¦¹ In a 2â€“4 tree, splitting creates two nodes and pushes the middle key upward.
ð–¦¹ In a vh-tree, splitting is done by flipping 3 link flags:
â€¢ Two child links become vertical.
â€¢ Parent link becomes horizontal.
ð–¦¹ If flipping causes two horizontal links in a row, rotations are needed.
â€¢ There are around 8 main split patterns.
â€¢ Only some need 1 or 2 rotations.

7. Why rotations are needed
ð–¦¹ Sometimes the structure becomes: node â†’ horizontal â†’ child â†’ horizontal â†’ grandchild.
ð–¦¹ This pattern is not allowed and must be fixed.
ð–¦¹ Fixing uses:
â€¢ Rotations (like in BSTs)
â€¢ A few link flips
ð–¦¹ Rotations do not increase the height.
--END--
--BEGIN--26/11/2025--SEGMENT TREES--
1. Segment Tree
ð–¦¹ A segment tree is a binary tree used to answer range-based questions fast.
ð–¦¹ It helps with tasks like range sum, range min/max, counting in a range, and fast updates.
ð–¦¹ It keeps both query and update time as O(log n).

2. Reason for using segment trees
ð–¦¹ Normal array gives slow range queries (O(n)) but fast updates.
ð–¦¹ Prefix sums give fast range sums (O(1)) but slow updates (O(n)).
ð–¦¹ Segment tree gives both query and update in O(log n).

3. Basic idea
ð–¦¹ The array is divided into segments.
â€¢ Example: whole â†’ [0,5], left â†’ [0,2], right â†’ [3,5].
ð–¦¹ Each segment stores chosen information such as sum, min, max, gcd, xor, etc.
ð–¦¹ Leaves store single element values; internal nodes store the combined value of their children.

4. Example of building a sum segment tree
ð–¦¹ For A = [2, 5, 1, 4], the tree stores sums of segments.
ð–¦¹ Example layout:
â€¢ [0,3] = 12
â€¢ [0,1] = 7, [2,3] = 5
â€¢ [0,0] = 2, [1,1] = 5, [2,2] = 1, [3,3] = 4
ð–¦¹ Each parent value is the sum of its two child values.

5. Range query example (sum of [1,3])
ð–¦¹ Fully inside segments â†’ add value.
ð–¦¹ Fully outside segments â†’ ignore.
ð–¦¹ Partially inside â†’ go deeper.
ð–¦¹ Final answer: 5 + 1 + 4 = 10 in O(log n).

6. Update example (A[2] = 10)
ð–¦¹ Go to leaf [2,2] and change 1 â†’ 10.
ð–¦¹ Move upward and fix parent values.
â€¢ [2,3] changes.
â€¢ [0,3] changes.
ð–¦¹ The tree adjusts in O(log n).

7. Size of a segment tree
ð–¦¹ Maximum size is about 4n nodes.
ð–¦¹ Using an array of size 4n is safe.

8. Types of segment trees
ð–¦¹ Sum segment tree.
ð–¦¹ Min or max segment tree.
ð–¦¹ GCD segment tree.
ð–¦¹ Lazy segment tree.
â€¢ Used for range updates like adding +5 to all elements in a range.
â€¢ Normal range update is O(n); lazy update becomes O(log n).

9. Time complexity
ð–¦¹ Build: O(n)
ð–¦¹ Query: O(log n)
ð–¦¹ Update: O(log n)
ð–¦¹ Lazy propagation update: O(log n)

10. When to use a segment tree
ð–¦¹ Use when both fast range queries and fast updates are needed.
ð–¦¹ Common uses:
â€¢ Range sum
â€¢ Range minimum or maximum
â€¢ Range GCD
â€¢ Range XOR
â€¢ Range addition or increment updates
--END--